{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "# TODO: hacky, shouldn't be necessary\n",
    "os.chdir(\"/lustre_scratch/orlando-code/coralshift/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nctoolkit as nc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import haversine\n",
    "import xarray as xa\n",
    "import pandas as pd\n",
    "# from haversine import haversine, Units, inverse_haversine\n",
    "\n",
    "from coralshift.utils import directories, file_ops, utils\n",
    "from coralshift.processing import spatial_data\n",
    "from coralshift.dataloading import climate_data\n",
    "\n",
    "import cdsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_data(\n",
    "    download_dest_dir, weather_params, years, \n",
    "    months: list[int] | int = np.arange(1,13), \n",
    "    days: list[int] | int = np.arange(1,32), \n",
    "    hours: list[int] | int = np.arange(0,24),\n",
    "    lat_lims=(-10,-17), lon_lims=(142,147), \n",
    "    dataset_tag: str=\"reanalysis-era5-single-levels\", format: str=\"grib\"):\n",
    "    c = cdsapi.Client()\n",
    "\n",
    "    area = [max(lat_lims), min(lon_lims), min(lat_lims), max(lon_lims)]\n",
    "\n",
    "    for param in weather_params:\n",
    "        param_download_dest = file_ops.guarantee_existence(\n",
    "            Path(download_dest_dir) / param)\n",
    "        for year in years:\n",
    "            filename = climate_data.generate_spatiotemporal_var_filename_from_dict({\n",
    "                \"var\": param,\n",
    "                \"lats\": lat_lims,\n",
    "                \"lons\": lon_lims,\n",
    "                \"year\": str(year)\n",
    "            })\n",
    "            # filename = str(file_ops.generate_filepath(param_download_dest, filename, format))\n",
    "            filepath = str(generate_filepath(param_download_dest, filename, format))\n",
    "            \n",
    "            if not Path(filepath).is_file():\n",
    "                time_info_dict = return_times_info(year, months, days)\n",
    "                # filename = str(file_ops.generate_filepath(param_download_dest, f\"{param}_{year}\", format))\n",
    "                # filename = str((param_download_dest / param / str(year)).with_suffix(format))\n",
    "                ecmwf_api_call(c, filepath, param, time_info_dict, area, dataset_tag, format)\n",
    "            else:\n",
    "                print(f\"Filepath already exists: {filepath}\")\n",
    "        #Â TODO: more descriptive filename\n",
    "\n",
    "\n",
    "def pad_suffix(suffix: str) -> str:\n",
    "    \"\"\"Pads the given file suffix with a leading period if necessary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        suffix (str): file suffix to pad.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        str: The padded file suffix.\n",
    "    \"\"\"\n",
    "    if \".\" not in suffix:\n",
    "        suffix = \".\" + suffix\n",
    "    return suffix\n",
    "\n",
    "\n",
    "def generate_filepath(\n",
    "    dir_path: str | Path, filename: str = None, suffix: str = None\n",
    ") -> Path:\n",
    "    \"\"\"Generates directory path if non-existant; if filename provided, generates filepath, adding suffix if\n",
    "    necessary.\"\"\"\n",
    "    # if generating/ensuring directory path\n",
    "    if not filename:\n",
    "        return guarantee_existence(dir_path)\n",
    "    # if filename provided, seemingly with suffix included\n",
    "    elif not suffix:\n",
    "        return Path(dir_path) / filename\n",
    "    # if filename and suffix provided\n",
    "    else:\n",
    "        return (Path(dir_path) / filename).with_suffix(pad_suffix(suffix))\n",
    "\n",
    "\n",
    "def generate_ecmwf_api_dict(\n",
    "    weather_params: list[str], time_info_dict: dict, area: list[float], format: str\n",
    ") -> dict:\n",
    "    \"\"\"Generate api dictionary format for single month of event\"\"\"\n",
    "\n",
    "    # if weather_params\n",
    "\n",
    "    api_call_dict = {\n",
    "        \"product_type\": \"reanalysis\",\n",
    "        \"variable\": [weather_params],\n",
    "        \"area\": area,\n",
    "        \"format\": format,\n",
    "    } | time_info_dict\n",
    "\n",
    "    return api_call_dict\n",
    "\n",
    "\n",
    "def generate_month_day_hour_list(items_range):\n",
    "    items = []\n",
    "    \n",
    "    if isinstance(items_range, (int, np.integer)):\n",
    "        items_range = [items_range]\n",
    "    elif isinstance(items_range, np.ndarray):\n",
    "        items_range = items_range.tolist()\n",
    "    elif not isinstance(items_range, list):\n",
    "        raise ValueError(\"Invalid input format. Please provide an integer, a list, or a NumPy array.\")\n",
    "    \n",
    "    for item in items_range:\n",
    "        if isinstance(item, (int, np.integer)):\n",
    "            if item < 0 or item > 31:\n",
    "                raise ValueError(\"Invalid items value: {}.\".format(item))\n",
    "            items.append(item)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input format. Please provide an integer, a list, or a NumPy array.\")\n",
    "    \n",
    "    return items\n",
    "\n",
    "\n",
    "def return_times_info(year: int, \n",
    "    months: list[int] | int = np.arange(1,13), \n",
    "    days: list[int] | int = np.arange(1,32), \n",
    "    hours: list[int] | int = np.arange(0,24)):\n",
    "\n",
    "    year = str(year)\n",
    "    months = [utils.pad_number_with_zeros(month) for month in generate_month_day_hour_list(months)]\n",
    "    days = [utils.pad_number_with_zeros(day) for day in generate_month_day_hour_list(days)]\n",
    "    \n",
    "    hours = [utils.pad_number_with_zeros(hour) for hour in generate_month_day_hour_list(hours)]\n",
    "    for h, hour in enumerate(hours):\n",
    "        hours[h] = f\"{hour}:00\"\n",
    "\n",
    "    return {\"year\": year, \"month\": months, \"day\": days, \"time\": hours}\n",
    "\n",
    "\n",
    "def ecmwf_api_call(\n",
    "    c,\n",
    "    # download_dest_dir: Path | str,\n",
    "    filepath: str,\n",
    "    parameter: str,\n",
    "    time_info_dict: dict,\n",
    "    area: list[tuple[float]],\n",
    "    dataset_tag: str = \"reanalysis-era5-single-levels\",\n",
    "    format: str = \"grib\",\n",
    "):\n",
    "    api_call_dict = generate_ecmwf_api_dict(parameter, time_info_dict, area, format)\n",
    "    # make api call\n",
    "    try:\n",
    "        c.retrieve(dataset_tag, api_call_dict, filepath)\n",
    "    # if error in fetching, limit the parameter\n",
    "    except ConnectionAbortedError():\n",
    "        print(f\"API call failed for {parameter}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def hourly_means_to_daily(hourly_dir: Path | str, suffix: str=\"netcdf\"):\n",
    "    filepaths = file_ops.return_list_filepaths(hourly_dir, suffix, incl_subdirs=True)\n",
    "    # create subdirectory to store averaged files\n",
    "    daily_means_dir = file_ops.guarantee_existence(Path(hourly_dir) / \"daily_means\")\n",
    "    for filepath in tqdm(filepaths, desc=\"Converting hourly means to daily means\"):\n",
    "        filename = \"_\".join((str(filepath.stem), \"daily\"))\n",
    "        save_path = (daily_means_dir / filename).with_suffix(file_ops.pad_suffix(suffix))\n",
    "        # open dataset\n",
    "        hourly = xa.open_dataset(filepath, chunks = {\"time\": 100})\n",
    "        daily = hourly.resample(time=\"1D\").mean()\n",
    "        # take average means\n",
    "        daily.to_netcdf(save_path)\n",
    "\n",
    "def merge_files_in_dir(dir: Path | str, suffix: str=\"netcdf\", concat_dim: str=\"time\"):\n",
    "    filepaths = file_ops.return_list_filepaths(dir, suffix, incl_subdirs=False)\n",
    "    dir = Path(dir)\n",
    "    merged_name = f\"{str(dir.stem)}_time_merged.nc\"\n",
    "    merged_path = dir / merged_name\n",
    "    if not merged_path.is_file():\n",
    "        print(f\"Merging .nc files into {merged_path}\")\n",
    "\n",
    "        merged_ds = xa.open_mfdataset(filepaths, chunks={\"time\": 100},\n",
    "            concat_dim=concat_dim, combine=\"nested\").sortby(\"time\", ascending=True)\n",
    "        merged_ds.to_netcdf(merged_path)\n",
    "        return merged_ds\n",
    "    else:\n",
    "        print(f\"{merged_path} already exists.\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_files_in_dir(\"lustre_scratch/datasets/era5/surface_net_solar_radiation/daily_means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_means_to_daily(\"lustre_scratch/datasets/era5/surface_net_solar_radiation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa.open_dataset(\"/Users/orlandotimmerman/Downloads/19930101022011-NCEI-L3C_GHRSST-SSTskin-AVHRR_Pathfinder-PFV5.3_NOAA11_G_1993001_night-v02.0-fv01.0.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = xa.open_dataset(\"lustre_scratch/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_1993.netcdf\", \n",
    "    # chunks={\"latitude\": 10, \"longitude\": 10}\n",
    "    chunks = {\"time\": 100}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file.resample(time=\"1D\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1993,2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_1993.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_1994.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_1995.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_1996.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_1997.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_1998.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_1999.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2000.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2001.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2002.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2003.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2004.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2005.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2006.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2007.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2008.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2009.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2010.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2011.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2012.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2013.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2014.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2015.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2016.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2017.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2018.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2019.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/evaporation/VAR_evaporation_LATS_-10_-17_LONS_142_147_YEAR_2020.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_1993.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_1994.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_1995.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_1996.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_1997.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_1998.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_1999.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2000.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2001.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2002.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2003.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2004.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2005.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2006.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2007.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2008.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2009.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2010.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2011.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2012.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2013.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2014.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2015.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2016.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2017.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2018.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2019.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/significant_height_of_combined_wind_waves_and_swell/VAR_significant_height_of_combined_wind_waves_and_swell_LATS_-10_-17_LONS_142_147_YEAR_2020.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_1993.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_1994.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_1995.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_1996.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_1997.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_1998.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_1999.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2000.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2001.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2002.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2003.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2004.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2005.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2006.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2007.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2008.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2009.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2010.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2011.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2012.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2013.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2014.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2015.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2016.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2017.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2018.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2019.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_net_solar_radiation/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_2020.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_pressure/VAR_surface_pressure_LATS_-10_-17_LONS_142_147_YEAR_1993.netcdf\n",
      "Filepath already exists: /lustre_scratch/orlando-code/datasets/era5/surface_pressure/VAR_surface_pressure_LATS_-10_-17_LONS_142_147_YEAR_1994.netcdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 17:07:29,165 INFO Welcome to the CDS\n",
      "2023-06-09 17:07:29,167 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-06-09 17:07:29,451 INFO Request is completed\n",
      "2023-06-09 17:07:29,452 INFO Downloading https://download-0006-clone.copernicus-climate.eu/cache-compute-0006/cache/data3/adaptor.mars.internal-1686314405.472787-20106-4-594420a8-d78b-43f1-9ec7-0142107c7534.nc to /lustre_scratch/orlando-code/datasets/era5/surface_pressure/VAR_surface_pressure_LATS_-10_-17_LONS_142_147_YEAR_1995.netcdf (10.2M)\n",
      "2023-06-09 17:07:30,249 INFO Download rate 12.8M/s  \n",
      "2023-06-09 17:07:30,348 INFO Welcome to the CDS\n",
      "2023-06-09 17:07:30,349 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-06-09 17:07:30,446 INFO Request is queued\n",
      "2023-06-09 17:07:31,496 INFO Request is running\n",
      "2023-06-09 17:26:09,621 INFO Request is completed\n",
      "2023-06-09 17:26:09,623 INFO Downloading https://download-0008-clone.copernicus-climate.eu/cache-compute-0008/cache/data9/adaptor.mars.internal-1686331431.6950119-27379-2-931675d7-5f41-498b-a77d-d0df28b9002b.nc to /lustre_scratch/orlando-code/datasets/era5/surface_pressure/VAR_surface_pressure_LATS_-10_-17_LONS_142_147_YEAR_1997.netcdf (10.2M)\n",
      "2023-06-09 17:26:11,078 INFO Download rate 7M/s     \n",
      "2023-06-09 17:26:11,169 INFO Welcome to the CDS\n",
      "2023-06-09 17:26:11,170 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-06-09 17:26:11,278 INFO Request is queued\n",
      "2023-06-09 17:26:12,327 INFO Request is running\n",
      "2023-06-09 17:36:30,534 INFO Request is completed\n",
      "2023-06-09 17:36:30,563 INFO Downloading https://download-0001-clone.copernicus-climate.eu/cache-compute-0001/cache/data3/adaptor.mars.internal-1686332061.496073-29729-18-b02a9717-290e-4e18-a175-c725523bf91f.nc to /lustre_scratch/orlando-code/datasets/era5/surface_pressure/VAR_surface_pressure_LATS_-10_-17_LONS_142_147_YEAR_1998.netcdf (10.2M)\n",
      "2023-06-09 17:36:31,258 INFO Download rate 14.7M/s  \n",
      "2023-06-09 17:36:31,357 INFO Welcome to the CDS\n",
      "2023-06-09 17:36:31,358 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-06-09 17:36:31,414 INFO Request is queued\n",
      "2023-06-09 17:36:32,466 INFO Request is running\n",
      "2023-06-09 17:44:50,464 INFO Request is completed\n",
      "2023-06-09 17:44:50,466 INFO Downloading https://download-0004-clone.copernicus-climate.eu/cache-compute-0004/cache/data9/adaptor.mars.internal-1686332637.2891448-11939-1-074ab392-cdb4-4c1e-8836-470ede152b12.nc to /lustre_scratch/orlando-code/datasets/era5/surface_pressure/VAR_surface_pressure_LATS_-10_-17_LONS_142_147_YEAR_1999.netcdf (10.2M)\n",
      "2023-06-09 17:44:51,260 INFO Download rate 12.9M/s  \n",
      "2023-06-09 17:44:51,345 INFO Welcome to the CDS\n",
      "2023-06-09 17:44:51,347 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-06-09 17:44:51,428 INFO Request is queued\n",
      "2023-06-09 17:44:52,474 INFO Request is running\n",
      "2023-06-09 17:55:10,798 INFO Request is completed\n",
      "2023-06-09 17:55:10,875 INFO Downloading https://download-0010-clone.copernicus-climate.eu/cache-compute-0010/cache/data8/adaptor.mars.internal-1686333167.63042-29649-5-0f1678e3-5592-40dd-a609-26f38250d15a.nc to /lustre_scratch/orlando-code/datasets/era5/surface_pressure/VAR_surface_pressure_LATS_-10_-17_LONS_142_147_YEAR_2000.netcdf (10.2M)\n",
      "2023-06-09 17:55:11,759 INFO Download rate 11.6M/s  \n",
      "2023-06-09 17:55:11,853 INFO Welcome to the CDS\n",
      "2023-06-09 17:55:11,855 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-06-09 17:55:11,907 INFO Request is queued\n",
      "2023-06-09 17:55:12,958 INFO Request is running\n",
      "2023-06-09 18:05:31,326 INFO Request is completed\n",
      "2023-06-09 18:05:31,344 INFO Downloading https://download-0008-clone.copernicus-climate.eu/cache-compute-0008/cache/data8/adaptor.mars.internal-1686333788.609793-13047-7-c4fcc730-6800-403f-9792-32038554a563.nc to /lustre_scratch/orlando-code/datasets/era5/surface_pressure/VAR_surface_pressure_LATS_-10_-17_LONS_142_147_YEAR_2001.netcdf (10.2M)\n",
      "2023-06-09 18:05:32,211 INFO Download rate 11.8M/s  \n",
      "2023-06-09 18:05:32,308 INFO Welcome to the CDS\n",
      "2023-06-09 18:05:32,309 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-06-09 18:05:32,381 INFO Request is queued\n",
      "2023-06-09 18:05:33,429 INFO Request is running\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(os.path.expanduser(\"lustre_scratch/datasets/era5test\"))\n",
    "\n",
    "os.chdir(os.path.expanduser(\"~\"))\n",
    "\n",
    "\n",
    "fetch_weather_data(\n",
    "    \"lustre_scratch/datasets/era5\",\n",
    "    ['evaporation', 'significant_height_of_combined_wind_waves_and_swell', \n",
    "    'surface_net_solar_radiation', 'surface_pressure'], \n",
    "    np.arange(1993,2021), format=\"netcdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lustre_scratch/datasets/era5test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa.open_dataset(\"/Users/orlandotimmerman/Desktop/test2/air_density_over_the_oceans/air_density_over_the_oceans_1993.netcdf\", engine=\"netcdf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/Users/orlandotimmerman/Desktop/test2/air_density_over_the_oceans\"\n",
    "files = file_ops.return_list_filepaths(dir, \"netcdf\")\n",
    "# files\n",
    "xa.open_mfdataset(files, chunks={\"time\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(lat_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lims=(-10,-17)\n",
    "lon_lims=(142,147)\n",
    "\n",
    "area = [max(lat_lims), min(lon_lims), min(lat_lims), max(lon_lims)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.pad_number_with_zeros(np.arange(0,24)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a 3D NumPy array with NaN values\n",
    "arr = np.array([\n",
    "    [[1, 2, 3], [4, 5, 2]],\n",
    "    [[np.nan, 7, 8], [np.nan, 3, 11]]\n",
    "])\n",
    "\n",
    "# Check for NaN values along all dimensions (s, v, and t)\n",
    "is_nan = np.isnan(arr).all(axis=(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column (v+1) with binary values based on the NaN check\n",
    "new_col = np.where(is_nan, 1, 0)\n",
    "new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr_with_new_col = np.concatenate((arr, new_col[:, np.newaxis, np.newaxis]), axis=1)\n",
    "\n",
    "# Print the original array and the array with the new column\n",
    "print(\"Original Array:\")\n",
    "print(arr)\n",
    "print(\"\\nArray with New Column:\")\n",
    "print(arr_with_new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE: https://nctoolkit.readthedocs.io/en/latest/interpolation.html\n",
    "ds1 = nc.open_thredds(\"https://psl.noaa.gov/thredds/dodsC/Datasets/COBE2/sst.mon.mean.nc\")\n",
    "ds1.subset(timestep = 0)\n",
    "ds1.subset(lat = [0, 90])\n",
    "\n",
    "ds2 = nc.open_thredds(\"https://psl.noaa.gov/thredds/dodsC/Datasets/COBE2/sst.mon.mean.nc\")\n",
    "ds2.subset(timestep = 0)\n",
    "ds2.regrid(ds1, recycle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset:\n",
    "    \"\"\"Handle the variety of datasets required to test and train model\"\"\"\n",
    "    # TODO: add in declaration of filepath root\n",
    "    def __init__(self):\n",
    "        self.datasets = {}\n",
    "        self.files_location = Path()\n",
    "        # fetching external functions\n",
    "\n",
    "    def set_location(self, location=\"remote\"):\n",
    "        if location == \"remote\":\n",
    "            # change directory to home. TODO: make less hacky\n",
    "            os.chdir(\"/home/jovyan\")\n",
    "            self.files_location = Path(\"lustre_scratch/datasets/\")\n",
    "        elif location == \"local\":\n",
    "            self.files_location = directories.get_volume_dir()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    def get_location(self):\n",
    "        return self.files_location\n",
    "\n",
    "    def add_dataset(self, name, data):\n",
    "        self.datasets[name] = data\n",
    "\n",
    "    def get_dataset(self, name):\n",
    "        return self.datasets.get(name, None)\n",
    "\n",
    "    def remove_dataset(self, name):\n",
    "        if name in self.datasets:\n",
    "            del self.datasets[name]\n",
    "\n",
    "    def list_datasets(self):\n",
    "        return list(self.datasets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_man = MyDataset()\n",
    "\n",
    "# add datasets\n",
    "ds_man.set_location(\"remote\")\n",
    "\n",
    "ds_man.add_dataset(\n",
    "    \"monthly_climate_1_12\", xa.open_dataset(\n",
    "        ds_man.get_location() / \"global_ocean_reanalysis/monthly_means/coral_climate_1_12.nc\")\n",
    ")\n",
    "\n",
    "coral_climate_feature_vars = list(\n",
    "    set(ds_man.get_dataset(\"monthly_climate_1_12\").data_vars) - {'spatial_ref', 'coral_algae_1-12_degree', 'output'})\n",
    "ds_man.add_dataset(\n",
    "    \"monthly_climate_features\", ds_man.get_dataset(\"monthly_climate_1_12\")[coral_climate_feature_vars]\n",
    ")\n",
    "\n",
    "# ds_man.add_dataset(\n",
    "#     \"monthly_climate_1_12_y_np\", np.array(ds_man.get_dataset(\"monthly_climate_1_12\")[\"coral_algae_1-12_degree\"].isel(time=-1)).reshape(-1, 1)\n",
    "# )\n",
    "\n",
    "ds_man.add_dataset(\n",
    "    \"monthly_climate_1_12_X_y_np\", filter_out_nans(\n",
    "        spatial_data.xa_ds_to_3d_numpy(ds_man.get_dataset(\"monthly_climate_1_12\")), \n",
    "        np.array(ds_man.get_dataset(\"monthly_climate_1_12\")[\"coral_algae_1-12_degree\"].isel(time=-1)).reshape(-1, 1))\n",
    ")\n",
    "\n",
    "ds_man.add_dataset(\n",
    "    \"monthly_climate_1_12_X_np\", ds_man.get_dataset(\"monthly_climate_1_12_X_y_np\")[0]\n",
    ")\n",
    "\n",
    "ds_man.add_dataset(\n",
    "    \"monthly_climate_1_12_y_np\", ds_man.get_dataset(\"monthly_climate_1_12_X_y_np\")[1]\n",
    ")\n",
    "\n",
    "ds_man.add_dataset(\n",
    "    \"daily_climate_1_12\", xa.open_dataset(\n",
    "        Path(ds_man.get_location() / \"global_ocean_reanalysis/daily_means/dailies_combined.nc\"))\n",
    ")\n",
    "\n",
    "# same target as monthly\n",
    "ds_man.add_dataset(\n",
    "    \"daily_climate_1_12_y_np\", ds_man.get_dataset(\"monthly_climate_1_12_y_np\")\n",
    ")\n",
    "\n",
    "ds_man.add_dataset(\n",
    "    \"bathymetry_A\", rio.open_rasterio(\n",
    "        rasterio.open(ds_man.get_location() / \"bathymetry/GBR_30m/Great_Barrier_Reef_A_2020_30m_MSL_cog.tif\"),\n",
    "        ).rename(\"bathymetry_A\").rename({\"x\": \"longitude\", \"y\": \"latitude\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_spatial_batch(xa_ds: xa.Dataset, lat_lon_starts: tuple=(0,0), window_dims: tuple[int,int] = (6,6), \n",
    "    coord_range: tuple[float]=None, variables: list[str] = None) -> np.ndarray:\n",
    "    \"\"\"Sample a spatial batch from an xarray Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        xa_ds (xa.Dataset): The input xarray Dataset.\n",
    "        lat_lon_starts (tuple): Tuple specifying the starting latitude and longitude indices of the batch.\n",
    "        window_dims (tuple[int, int]): Tuple specifying the dimensions (number of cells) of the spatial window.\n",
    "        coord_range (tuple[float]): Tuple specifying the latitude and longitude range (in degrees) of the spatial \n",
    "            window. If provided, it overrides the window_dims parameter.\n",
    "        variables (list[str]): List of variable names to include in the spatial batch. If None, includes all variables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        np.ndarray: The sampled spatial batch as a NumPy array.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "        - The function selects a subset of the input dataset based on the provided latitude, longitude indices, and window dimensions.\n",
    "        - If a coord_range is provided, it is used to compute the latitude and longitude indices of the spatial window.\n",
    "        - The function returns the selected subset as a NumPy array.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "        # Sample a spatial batch from an xarray Dataset\n",
    "        dataset = ...\n",
    "        lat_lon_starts = (2, 3)\n",
    "        window_dims = (6, 6)\n",
    "        coord_range = (2.5, 3.5)\n",
    "        variables = ['var1', 'var2', 'var3']\n",
    "        spatial_batch = sample_spatial_batch(dataset, lat_lon_starts, window_dims, coord_range, variables)\n",
    "    \"\"\"\n",
    "    # N.B. have to be careful when providing coordinate ranges for areas with negative coords. TODO: make universal\n",
    "    lat_start, lon_start = lat_lon_starts[0], lat_lon_starts[1]\n",
    "    if not coord_range:\n",
    "        subset = xa_ds.isel({\"latitude\": slice(lat_start,window_dims[0]), \n",
    "                            \"longitude\": slice(lon_start,window_dims[1])})\n",
    "    else:\n",
    "        lat_cells, lon_cells = coord_range[0], coord_range[1]\n",
    "        subset = xa_ds.sel({\"latitude\": slice(lat_start,lat_start+lat_cells), \n",
    "                            \"longitude\": slice(lon_start,lon_start+lon_cells)})\n",
    "\n",
    "    lat_slice = subset[\"latitude\"].values\n",
    "    lon_slice = subset[\"longitude\"].values\n",
    "    time_slice = subset[\"time\"].values\n",
    "\n",
    "    return subset, {\"latitude\": lat_slice, \"longitude\": lon_slice, \"time\": time_slice}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bathymetry\n",
    "bath_A = ds_man.get_dataset(\"bathymetry_A\")\n",
    "bath_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrees_to_distances(\n",
    "    target_lat_res: float,\n",
    "    target_lon_res: float = None,\n",
    "    approx_lat: float = -18,\n",
    "    approx_lon: float = 145,\n",
    ") -> tuple[float]:\n",
    "    \"\"\"TODO: docstring\"\"\"\n",
    "    start_coord = (approx_lat, approx_lon)\n",
    "    lat_end_coord = (approx_lat + target_lat_res, approx_lon)\n",
    "    # if both lat and lon resolutions specified\n",
    "    if target_lon_res:\n",
    "        lon_end_coord = (approx_lat, approx_lon + target_lon_res)\n",
    "    else:\n",
    "        lon_end_coord = (approx_lat, approx_lon + target_lat_res)\n",
    "\n",
    "    return (haversine.haversine(start_coord, lat_end_coord, unit=haversine.Unit.METERS), \n",
    "        haversine.haversine(start_coord, lon_end_coord, unit=haversine.Unit.METERS))\n",
    "\n",
    "\n",
    "def distance_to_degrees(\n",
    "    distance_lat: float, distance_lon: float = None, approx_lat: float = -18, approx_lon: float = 145\n",
    ") -> tuple[float, float, float]:\n",
    "    # TODO: enable specification of distance in different orthogonal directions\n",
    "    \"\"\"Converts a distance in meters to the corresponding distance in degrees, given an approximate location on Earth.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    distance (float): The distance in meters.\n",
    "    approx_lat (float, optional): The approximate latitude of the location in degrees. Defaults to -18.0.\n",
    "    approx_lon (float, optional): The approximate longitude of the location in degrees. Defaults to 145.0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float: The corresponding distance in degrees.\n",
    "    \"\"\"\n",
    "    # if distance_lon not provided, assume the same as distance_lat\n",
    "    if not distance_lon:\n",
    "        distance_lon = distance_lat\n",
    "\n",
    "    degrees_lat = haversine.inverse_haversine(\n",
    "        (approx_lat, approx_lon),\n",
    "        distance_lat,\n",
    "        haversine.Direction.SOUTH,\n",
    "        unit=haversine.Unit.METERS)\n",
    "    \n",
    "    degrees_lon = haversine.inverse_haversine(\n",
    "        (approx_lat, approx_lon),\n",
    "        distance_lon,\n",
    "        haversine.Direction.WEST,\n",
    "        unit=haversine.Unit.METERS)\n",
    "\n",
    "    # calculate the coordinates 'distance' meters to the southwest (chosen to give measure of both lat and lon)\n",
    "    av_distance = (distance_lat+distance_lon)/2\n",
    "    (lat_deg, lon_deg) = haversine.inverse_haversine(\n",
    "        (approx_lat, approx_lon),\n",
    "        av_distance,\n",
    "        haversine.Direction.SOUTHWEST,\n",
    "        unit=haversine.Unit.METERS,\n",
    "    )\n",
    "    delta_lat, delta_lon = abs(lat_deg - approx_lat), abs(lon_deg - approx_lon)\n",
    "    # return hypotenuse (encapsulates difference in both lat and lon)\n",
    "    return (np.subtract((approx_lat, approx_lon), degrees_lat)[0], np.subtract((approx_lat, approx_lon), degrees_lon)[1],\n",
    "        np.hypot(delta_lat, delta_lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degrees_to_distances(0.00898315)\n",
    "distance_to_degrees(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 km. Struggles displaying/processing 100m, but have yet to try saving to this/inferring\n",
    "_,_,av_degrees = distance_to_degrees(1000)\n",
    "coarsened_bath_A = spatial_data.upsample_xarray_to_target(bath_A, av_degrees)\n",
    "# im = coarsened_bath_A.plot(ax=ax)\n",
    "\n",
    "spatial_plots.plot_DEM(coarsened_bath_A, f\" DEM upsampled to {target_resolution} degrees\", vmin=-100, vmax=0)\n",
    "# spatial_plots.format_spatial_plot(im, fig, ax, f\"Upsampled to {target_resolution} degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carving off small slice\n",
    "\n",
    "# 1km upscale ground truth, bathymetry\n",
    "\n",
    "# regrid ground truth, bathymetry, climate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_man.add_dataset(\n",
    "    \"bathymetry_A\", rio.open_rasterio(\n",
    "        rasterio.open(ds_man.get_location() / \"bathymetry/GBR_30m/test_A.nc\"),\n",
    "        ).rename(\"bathymetry_A\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_A = ds_man.get_dataset(\"bathymetry_A\")\n",
    "bath_A = bath_A.rename({\"x\": \"longitude\", \"y\": \"latitude\"})\n",
    "bath_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climate_monthly_1_12 = ds_man.get_dataset(\"monthly_climate_1_12\")\n",
    "ds_climate_monthly_1_12_small = ds_climate_monthly_1_12.sel(latitude=slice(-10,-10.1), longitude=slice(142,142.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_var_list = list(ds_climate_monthly_1_12_small.data_vars)\n",
    "variables = out + data_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climate_monthly_1_12_small = ds_climate_monthly_1_12_small[variables]\n",
    "ds_climate_monthly_1_12_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_path = str(ds_man.get_location() / \"global_ocean_reanalysis/daily_means/dailies_combined.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_xa = xa.open_dataset(climate_path)\n",
    "climate_xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restrict_xa = climate_xa.isel(time=slice(0,10), latitude=slice(0,2), longitude=slice(0,2), depth=0)\n",
    "restrict_xa.to_netcdf(\"lustre_scratch/datasets/global_ocean_reanalysis/daily_means/restrict_xa.nc\")\n",
    "restrict_nc = nc.open_data(\"lustre_scratch/datasets/global_ocean_reanalysis/daily_means/restrict_xa.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = nc.open_data(climate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_static.times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restrict_nc.regrid(restrict_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climate_monthly_1_12_small.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bath.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climate = nc.from_xarray(ds_climate_monthly_1_12_small)\n",
    "ds_bath = nc.from_xarray(bath_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climate.months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bath.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climate.regrid(ds_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.example_fields(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_A.to_netcdf(ds_man.get_location() / \"bathymetry/GBR_30m/test_A.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cf.read(ds_man.get_location() / \"bathymetry/GBR_30m/test_A.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst.select_by_ncvar(\"bathymetry_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srces = cf.read(ds_man.get_location() / \"global_ocean_reanalysis/monthly_means/coral_climate_1_12.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srces[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = cf.DimensionCoordinate(data = cf.Data(np.arange(-17, -10, 0.01), \"lats\"))\n",
    "lon = cf.DimensionCoordinate(data = cf.Data(np.arange(142, 147, 0.01), \"lons\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = srces[5].regrids(dst, method='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_A = ds_man.get_dataset(\"bathymetry_A\")\n",
    "bath_A = bath_A.rename({\"x\": \"longitude\", \"y\": \"latitude\"})\n",
    "bath_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_A.values[:, None, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climate_monthly_1_12 = ds_man.get_dataset(\"monthly_climate_1_12\")\n",
    "ds_climate_monthly_1_12_A = ds_climate_monthly_1_12.sel(latitude=slice(-10,-17), longitude=slice(142,147))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climate_monthly_1_12_A[\"mlotst\"].isel(time=-1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing interp_like\n",
    "climate_m_small = ds_climate_monthly_1_12_A.sel(latitude=slice(-10,-10.2), longitude=slice(142,142.2))\n",
    "bath_A_small = bath_A.sel(latitude=slice(-10,-10.2), longitude=slice(145,145.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = climate_m_small.interp_like(bath_A_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check[\"mlotst\"].isel(time=-1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climate_monthly_1_12_A, bath_A = xa.broadcast(ds_climate_monthly_1_12_A, bath_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the high-resolution and low-resolution xarray datasets named 'bath_A' and 'ds_climate_monthly_1_12_A'\n",
    "\n",
    "# Extract the latitude and longitude coordinates from the high-resolution dataset\n",
    "lat_hr = bath_A['latitude'].values\n",
    "lon_hr = bath_A['longitude'].values\n",
    "\n",
    "# Extract the latitude and longitude coordinates from the low-resolution dataset\n",
    "lat_lr = ds_climate_monthly_1_12_A['latitude'].values\n",
    "lon_lr = ds_climate_monthly_1_12_A['longitude'].values\n",
    "\n",
    "# Get the values of the low-resolution array\n",
    "ds_climate_monthly_1_12_A_values = ds_climate_monthly_1_12_A['bottomT'].values\n",
    "\n",
    "# Create a new high-resolution array with the same values for each time step\n",
    "bath_A_values = np.broadcast_to(bath_A.values[:, None, :], ds_climate_monthly_1_12_A_values.shape)\n",
    "\n",
    "\n",
    "# # Create a 2D meshgrid for the high-resolution coordinates\n",
    "# lon_hr_mesh, lat_hr_mesh = np.meshgrid(lon_hr, lat_hr)\n",
    "\n",
    "# # Create a 2D meshgrid for the low-resolution coordinates\n",
    "# lon_lr_mesh, lat_lr_mesh = np.meshgrid(lon_lr, lat_lr)\n",
    "\n",
    "# # Get the values of the low-resolution array\n",
    "# low_res_values = ds_climate_monthly_1_12_A['bottomT'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate the low-resolution values onto the high-resolution grid\n",
    "interp_func = interp2d(lon_lr_mesh, lat_lr_mesh, low_res_values, kind='linear')\n",
    "high_res_values = interp_func(lon_hr, lat_hr)\n",
    "\n",
    "# # Create a new xarray dataset with the interpolated values\n",
    "# combined_ds = xa.Dataset(\n",
    "#     {\n",
    "#         'data_variable': (('lat', 'lon'), high_res_values),\n",
    "#     },\n",
    "#     coords={'lat': lat_hr, 'lon': lon_hr}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will need to try with GEE or do in smaller chunks\n",
    "# cut out nan vars before this. Huge memory consumption and not even the daily...\n",
    "climate_m_small = ds_climate_monthly_1_12_A.sel(latitude=slice(-10,-10.2), longitude=slice(142,142.2))\n",
    "bath_A_small = bath_A.sel(latitude=slice(-10,-10.2), longitude=slice(142,142.2))\n",
    "climate_resolution_monthly_reindexed = climate_m_small.reindex_like(bath_A_small, method='nearest')\n",
    "# takes ~ 40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_climate_daily_1_12 = ds_man.get_dataset(\"daily_climate_1_12\")\n",
    "ds_climate_daily_1_12_A = ds_climate_daily_1_12.sel(latitude=slice(-10,-17), longitude=slice(142,147))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completely destroys kernel memory usage\n",
    "climate_d_small = ds_climate_daily_1_12_A.sel(latitude=slice(-10,-10.2), longitude=slice(142,142.2))\n",
    "climate_resolution_daily_reindexed = climate_d_small.reindex_like(bath_A_small, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = climate_resolution_monthly_reindexed.merge(bath_A_small)\n",
    "# climate_resolution_daily_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_resolution_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_resolution_reindexed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_resolution_broadcasted = climate_resolution_reindexed.broadcast_like(test)\n",
    "climate_resolution_broadcasted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CORALSHIFT",
   "language": "python",
   "name": "coralshift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

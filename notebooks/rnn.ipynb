{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "location = \"remote\"\n",
    "if location == \"remote\":\n",
    "    # TODO: hacky, shouldn't be necessary\n",
    "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"lustre_scratch/coralshift/notebooks/rnn.ipynb\"\n",
    "    os.chdir(\"/lustre_scratch/orlando-code/coralshift/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import xarray as xa\n",
    "import numpy as np\n",
    "import math as m\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.interpolate import interp2d\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import xbatcher\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import rioxarray as rio\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "#issues with numpy deprecation in pytorch_env\n",
    "from coralshift.processing import spatial_data\n",
    "from coralshift.utils import file_ops, directories\n",
    "from coralshift.plotting import spatial_plots, model_results\n",
    "from coralshift.dataloading import data_structure, climate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser(\"~\"))\n",
    "\n",
    "# out = xa.open_dataset(\"lustre_scratch/datasets/1993010102201/1-NCEI-L3C_GHRSST-SSTskin-AVHRR_Pathfinder-PFV5.3_NOAA11_G_1993001_night-v02.0-fv01.0.nc\")\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:                    (time: 1, nv: 2, lat: 168, lon: 8640)\n",
       "Coordinates:\n",
       "  * time                       (time) datetime64[ns] 1992-12-31T22:02:56\n",
       "  * lat                        (lat) float32 -10.02 -10.06 ... -16.94 -16.98\n",
       "  * lon                        (lon) float32 -180.0 -179.9 ... 179.9 180.0\n",
       "Dimensions without coordinates: nv\n",
       "Data variables: (12/15)\n",
       "    time_bounds                (time, nv) datetime64[ns] ...\n",
       "    lat_bounds                 (lat, nv) float32 ...\n",
       "    lon_bounds                 (lon, nv) float32 ...\n",
       "    crs                        int32 ...\n",
       "    sea_surface_temperature    (time, lat, lon) float32 ...\n",
       "    sst_dtime                  (time, lat, lon) timedelta64[ns] ...\n",
       "    ...                         ...\n",
       "    wind_speed                 (time, lat, lon) float32 ...\n",
       "    sea_ice_fraction           (time, lat, lon) float32 ...\n",
       "    aerosol_dynamic_indicator  (time, lat, lon) float32 ...\n",
       "    quality_level              (time, lat, lon) float32 ...\n",
       "    pathfinder_quality_level   (time, lat, lon) float32 ...\n",
       "    l2p_flags                  (time, lat, lon) float64 ...\n",
       "Attributes: (12/74)\n",
       "    Conventions:                             CF-1.6, ACDD-1.3\n",
       "    title:                                   AVHRR Pathfinder Version 5.3 L3-...\n",
       "    summary:                                 This netCDF-4 file contains sea ...\n",
       "    references:                              http://pathfinder.nodc.noaa.gov ...\n",
       "    institution:                             NCEI\n",
       "    history:                                 smigen_both ifile=1993001.b4kd1-...\n",
       "    ...                                      ...\n",
       "    platform_vocabulary:                     NASA Global Change Master Direct...\n",
       "    instrument_vocabulary:                   NASA Global Change Master Direct...\n",
       "    metadata_link:                           http://data.nodc.noaa.gov/cgi-bi...\n",
       "    program:                                 NOAA Climate Data Record (CDR) P...\n",
       "    cdr_program:                             NOAA Climate Data Record Program...\n",
       "    cdr_id:                                  gov.noaa.ncdc:C00983</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-85532dd6-ad3f-43bf-a328-c90d2e426c87' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-85532dd6-ad3f-43bf-a328-c90d2e426c87' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 1</li><li><span>nv</span>: 2</li><li><span class='xr-has-index'>lat</span>: 168</li><li><span class='xr-has-index'>lon</span>: 8640</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-55d4c0b2-43d6-402c-9d0d-888f7ccb5e68' class='xr-section-summary-in' type='checkbox'  checked><label for='section-55d4c0b2-43d6-402c-9d0d-888f7ccb5e68' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1992-12-31T22:02:56</div><input id='attrs-b42281a2-748e-4715-be3d-91c8e962449f' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b42281a2-748e-4715-be3d-91c8e962449f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1ecaed05-5c1d-4eb2-9902-684eda8157eb' class='xr-var-data-in' type='checkbox'><label for='data-1ecaed05-5c1d-4eb2-9902-684eda8157eb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>long_name :</span></dt><dd>reference time of SST file</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>comment :</span></dt><dd>This is the reference time of the SST file. Add sst_dtime to this value to get pixel-by-pixel times.</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1992-12-31T22:02:56.000000000&#x27;], dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-10.02 -10.06 ... -16.94 -16.98</div><input id='attrs-91031b6f-7aef-4d64-a602-a9c24d6d9042' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-91031b6f-7aef-4d64-a602-a9c24d6d9042' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-656a1039-d904-4cd6-9d76-b1ecd5f4a8de' class='xr-var-data-in' type='checkbox'><label for='data-656a1039-d904-4cd6-9d76-b1ecd5f4a8de' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>reference_datum :</span></dt><dd>Geographical coordinates, WGS84 datum</dd><dt><span>axis :</span></dt><dd>Y</dd><dt><span>valid_min :</span></dt><dd>-90.0</dd><dt><span>valid_max :</span></dt><dd>90.0</dd></dl></div><div class='xr-var-data'><pre>array([-10.020831, -10.062497, -10.104164, -10.145831, -10.187497, -10.229164,\n",
       "       -10.270831, -10.312497, -10.354164, -10.395831, -10.437497, -10.479164,\n",
       "       -10.520831, -10.562497, -10.604164, -10.645831, -10.687497, -10.729164,\n",
       "       -10.770831, -10.812497, -10.854164, -10.895831, -10.937497, -10.979164,\n",
       "       -11.020831, -11.062497, -11.104164, -11.145831, -11.187497, -11.229164,\n",
       "       -11.270831, -11.312497, -11.354164, -11.395831, -11.437497, -11.479164,\n",
       "       -11.520831, -11.562497, -11.604164, -11.645831, -11.687497, -11.729164,\n",
       "       -11.770831, -11.812497, -11.854164, -11.895831, -11.937497, -11.979164,\n",
       "       -12.020831, -12.062497, -12.104164, -12.145831, -12.187497, -12.229164,\n",
       "       -12.270831, -12.312497, -12.354164, -12.395831, -12.437497, -12.479164,\n",
       "       -12.520831, -12.562497, -12.604164, -12.645831, -12.687497, -12.729164,\n",
       "       -12.770831, -12.812497, -12.854164, -12.895831, -12.937497, -12.979164,\n",
       "       -13.020831, -13.062497, -13.104164, -13.145831, -13.187497, -13.229164,\n",
       "       -13.270831, -13.312497, -13.354164, -13.395831, -13.437497, -13.479164,\n",
       "       -13.520831, -13.562497, -13.604164, -13.645831, -13.687497, -13.729164,\n",
       "       -13.770831, -13.812497, -13.854164, -13.895831, -13.937497, -13.979164,\n",
       "       -14.020831, -14.062497, -14.104164, -14.145831, -14.187497, -14.229164,\n",
       "       -14.270831, -14.312497, -14.354164, -14.395831, -14.437497, -14.479164,\n",
       "       -14.520831, -14.562497, -14.604164, -14.645831, -14.687497, -14.729164,\n",
       "       -14.770831, -14.812497, -14.854164, -14.895831, -14.937497, -14.979164,\n",
       "       -15.020831, -15.062497, -15.104164, -15.145831, -15.187497, -15.229164,\n",
       "       -15.270831, -15.312497, -15.354164, -15.395831, -15.437497, -15.479164,\n",
       "       -15.520831, -15.562497, -15.604164, -15.645831, -15.687497, -15.729164,\n",
       "       -15.770831, -15.812497, -15.854164, -15.895831, -15.937497, -15.979164,\n",
       "       -16.02083 , -16.062498, -16.104164, -16.14583 , -16.187498, -16.229164,\n",
       "       -16.27083 , -16.312498, -16.354164, -16.39583 , -16.437498, -16.479164,\n",
       "       -16.52083 , -16.562498, -16.604164, -16.64583 , -16.687498, -16.729164,\n",
       "       -16.77083 , -16.812498, -16.854164, -16.89583 , -16.937498, -16.979164],\n",
       "      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-180.0 -179.9 ... 179.9 180.0</div><input id='attrs-19312cc0-f994-4a7b-8b2d-9fe2cb1b3b38' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-19312cc0-f994-4a7b-8b2d-9fe2cb1b3b38' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5d91fadc-628e-476a-8412-c495e0672f92' class='xr-var-data-in' type='checkbox'><label for='data-5d91fadc-628e-476a-8412-c495e0672f92' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>reference_datum :</span></dt><dd>Geographical coordinates, WGS84 datum</dd><dt><span>axis :</span></dt><dd>X</dd><dt><span>valid_min :</span></dt><dd>-180.0</dd><dt><span>valid_max :</span></dt><dd>180.0</dd></dl></div><div class='xr-var-data'><pre>array([-179.97917, -179.9375 , -179.89584, ...,  179.89583,  179.9375 ,\n",
       "        179.97916], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-45322515-b271-445e-8253-5f400c0ad4f4' class='xr-section-summary-in' type='checkbox'  ><label for='section-45322515-b271-445e-8253-5f400c0ad4f4' class='xr-section-summary' >Data variables: <span>(15)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>time_bounds</span></div><div class='xr-var-dims'>(time, nv)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-aedb487d-4cca-4659-9eee-47916fa5f625' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-aedb487d-4cca-4659-9eee-47916fa5f625' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4a688f78-c1ff-4502-96ad-38cb20ca88a9' class='xr-var-data-in' type='checkbox'><label for='data-4a688f78-c1ff-4502-96ad-38cb20ca88a9' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>time bounds</dd><dt><span>comment :</span></dt><dd>time bounds for each time value</dd></dl></div><div class='xr-var-data'><pre>[2 values with dtype=datetime64[ns]]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lat_bounds</span></div><div class='xr-var-dims'>(lat, nv)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-d90cd0f8-64a4-4417-9df6-2dad4e3dafbf' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d90cd0f8-64a4-4417-9df6-2dad4e3dafbf' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d0e3ee96-eadd-400f-b0f7-85fcccead41e' class='xr-var-data-in' type='checkbox'><label for='data-d0e3ee96-eadd-400f-b0f7-85fcccead41e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>latitude bounds</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>comment :</span></dt><dd>latitude values at the north and south bounds of each grid point</dd></dl></div><div class='xr-var-data'><pre>[336 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon_bounds</span></div><div class='xr-var-dims'>(lon, nv)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-ea7e46a4-233a-4872-9dd1-cad328428ae3' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-ea7e46a4-233a-4872-9dd1-cad328428ae3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8e504331-5981-44e2-9227-28d1ab85a555' class='xr-var-data-in' type='checkbox'><label for='data-8e504331-5981-44e2-9227-28d1ab85a555' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>longitude bounds</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>comment :</span></dt><dd>longitude values at the west and east bounds of each grid point</dd></dl></div><div class='xr-var-data'><pre>[17280 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>crs</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-60c215a3-4048-4fd9-83a5-b574bc6ef08b' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-60c215a3-4048-4fd9-83a5-b574bc6ef08b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d5b49523-be68-486e-8ad9-52b642a20c67' class='xr-var-data-in' type='checkbox'><label for='data-d5b49523-be68-486e-8ad9-52b642a20c67' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>coordinate reference system</dd><dt><span>grid_mapping_name :</span></dt><dd>latitude_longitude</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223563</dd><dt><span>epsg_code :</span></dt><dd>EPSG:4326</dd><dt><span>comment :</span></dt><dd>This is a container variable that describes the grid_mapping used by the data in this file. This variable does not contain any data; only information about the geographic coordinate system.</dd></dl></div><div class='xr-var-data'><pre>[1 values with dtype=int32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sea_surface_temperature</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-d743d69e-f67c-405d-91cb-0025fb6b1c65' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d743d69e-f67c-405d-91cb-0025fb6b1c65' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ceddefee-0577-4fea-a096-4adf7bfb98a6' class='xr-var-data-in' type='checkbox'><label for='data-ceddefee-0577-4fea-a096-4adf7bfb98a6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>sea_surface_skin_temperature</dd><dt><span>long_name :</span></dt><dd>NOAA Climate Data Record of sea surface skin temperature</dd><dt><span>coverage_content_type :</span></dt><dd>physicalMeasurement</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>kelvin</dd><dt><span>valid_min :</span></dt><dd>-180</dd><dt><span>valid_max :</span></dt><dd>4500</dd><dt><span>ancillary_variables :</span></dt><dd>quality_level pathfinder_quality_level l2p_flags</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>Skin temperature of the ocean</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sst_dtime</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>timedelta64[ns]</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-e8b82276-ddfa-4577-b2e8-6d1953134bdb' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e8b82276-ddfa-4577-b2e8-6d1953134bdb' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ecf9bb09-755e-4dc8-98d1-4d459225eb7a' class='xr-var-data-in' type='checkbox'><label for='data-ecf9bb09-755e-4dc8-98d1-4d459225eb7a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>time difference from reference time</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>valid_min :</span></dt><dd>-2147483647</dd><dt><span>valid_max :</span></dt><dd>2147483647</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>Time plus sst_dtime gives seconds after 1981-01-01 00:00:00. Note: in PFV5.3 this sst_dtime is empty. PFV6 will contain the correct sst_dtime values.</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=timedelta64[ns]]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sses_bias</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-a55661d7-4e98-42da-9225-858f4051f69b' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a55661d7-4e98-42da-9225-858f4051f69b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d1abde22-cad3-4653-84fd-f19e3ee22f13' class='xr-var-data-in' type='checkbox'><label for='data-d1abde22-cad3-4653-84fd-f19e3ee22f13' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>SSES bias estimate</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>kelvin</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>Bias estimate derived using the techniques described at https://www.ghrsst.org/ghrsst/tags-and-wgs/stval-wg/sses-description-of-schemes/. Note: in PFV5.3 this sses_bias is empty. PFV6 will contain the correct sses_bias values.</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sses_standard_deviation</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-93310f27-e920-4c74-8f97-422c9ccb1692' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-93310f27-e920-4c74-8f97-422c9ccb1692' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8986752f-b197-4738-98b5-84ebc5b239a5' class='xr-var-data-in' type='checkbox'><label for='data-8986752f-b197-4738-98b5-84ebc5b239a5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>SSES standard deviation</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>kelvin</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>Standard deviation estimate derived using the techniques described at https://www.ghrsst.org/ghrsst/tags-and-wgs/stval-wg/sses-description-of-schemes/. Note: in PFV5.3 this sses_standard_deviation is empty. PFV6 will contain the correct sses_standard_deviation values.</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>dt_analysis</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-bc2ff59f-acd7-4f1c-a41d-ba886664a065' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-bc2ff59f-acd7-4f1c-a41d-ba886664a065' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ee2637a9-45ef-4421-8139-5d6839ca95d4' class='xr-var-data-in' type='checkbox'><label for='data-ee2637a9-45ef-4421-8139-5d6839ca95d4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>deviation from last SST analysis</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>kelvin</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>source :</span></dt><dd>NOAA Daily 25km Global Optimally Interpolated Sea Surface Temperature (OISST)</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>reference :</span></dt><dd>AVHRR_OI, with inland values populated from AVHRR_Pathfinder daily climatological SST. For more information on this reference field see http://accession.nodc.noaa.gov/0071180.</dd><dt><span>comment :</span></dt><dd>The difference between this SST and the previous day&#x27;s SST.</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>wind_speed</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-a65de6c1-f904-4f79-af9a-4a9929a1e6e9' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a65de6c1-f904-4f79-af9a-4a9929a1e6e9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-faffb7f4-ca9c-4018-8635-f03293dd5532' class='xr-var-data-in' type='checkbox'><label for='data-faffb7f4-ca9c-4018-8635-f03293dd5532' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>wind_speed</dd><dt><span>long_name :</span></dt><dd>10m wind speed</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>m s-1</dd><dt><span>height :</span></dt><dd>10 m</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>time_offset :</span></dt><dd>2.2011</dd><dt><span>source :</span></dt><dd>NCEP/DOE AMIP-II Reanalysis (Reanalysis-2): u_wind.10m.gauss.1993.nc, v_wind.10m.gauss.1993.nc</dd><dt><span>comment :</span></dt><dd>These wind speeds were created by NCEP-DOE Atmospheric Model Intercomparison Project (AMIP-II) reanalysis (R-2) and represent winds at 10 metres above the sea surface.</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sea_ice_fraction</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-baf5722a-0fd3-4ff5-8209-4571297db08c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-baf5722a-0fd3-4ff5-8209-4571297db08c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-394a0089-908c-4957-b481-4723f949ad2e' class='xr-var-data-in' type='checkbox'><label for='data-394a0089-908c-4957-b481-4723f949ad2e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>sea_ice_area_fraction</dd><dt><span>long_name :</span></dt><dd>sea ice fraction</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>percent</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>time_offset :</span></dt><dd>10.0</dd><dt><span>source :</span></dt><dd>NOAA/NESDIS/NCDC Daily optimum interpolation(OI) SST on 1/4-degree grid: 19930101-NCDC-L4LRblend-GLOB-v01-fv02_0-AVHRR_OI.nc.gz</dd><dt><span>comment :</span></dt><dd>Sea ice concentration data are taken from the EUMETSAT Ocean and Sea Ice Satellite Application Facility (OSISAF) Global Daily Sea Ice Concentration Reprocessing Data Set (http://accession.nodc.noaa.gov/0068294) when these data are available. The data are reprojected and interpolated from their original polar stereographic projection at 10km spatial resolution to the 4km Pathfinder Version 5.3 grid. When the OSISAF data are not available for both hemispheres on a given day, the sea ice concentration data are taken from the sea_ice_fraction variable found in the L4 GHRSST DailyOI SST product from NOAA/NCDC, and are interpolated from the 25km DailyOI grid to the 4km Pathfinder Version 5.3 grid.</dd><dt><span>reference :</span></dt><dd>Reynolds, et al.(2006) Daily High-resolution Blended Analyses. Available at http://doi.org/10.7289/V5SQ8XB5</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>aerosol_dynamic_indicator</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-73d83453-f9e9-4ff6-b87d-2180de54a6ef' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-73d83453-f9e9-4ff6-b87d-2180de54a6ef' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e167de82-d5cb-4f9f-a81e-1c430bb02632' class='xr-var-data-in' type='checkbox'><label for='data-e167de82-d5cb-4f9f-a81e-1c430bb02632' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>aerosol dynamic indicator</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>percent</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>time_offset :</span></dt><dd>360.0</dd><dt><span>source :</span></dt><dd>CLASS_AVHRRPF_AOT</dd><dt><span>reference :</span></dt><dd>http://www.class.ncdc.noaa.gov/saa/products/search?sub_id=0&amp;datatype_family=AVHRRPF</dd><dt><span>comment :</span></dt><dd>Aerosol optical thickness (AOT) data are taken from the CLASS Pathfinder (from AVHRR) (AVHRRPF). The aerosol optical thickness/depth (AOT/AOD) measurements are extracted from PATMOS-A2 monthly mean and reprojected and interpolated from their original 1 degree x 1 degree resolution to the 4km Pathfinder Version 5.3 grid.</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>quality_level</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-9c7b086d-d493-49d7-b2f1-d38ab2e8bead' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-9c7b086d-d493-49d7-b2f1-d38ab2e8bead' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fd8a3897-1625-444f-8c97-415234cec330' class='xr-var-data-in' type='checkbox'><label for='data-fd8a3897-1625-444f-8c97-415234cec330' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>quality level of SST pixel</dd><dt><span>coverage_content_type :</span></dt><dd>qualityInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>1</dd><dt><span>valid_min :</span></dt><dd>1</dd><dt><span>valid_max :</span></dt><dd>5</dd><dt><span>flag_meanings :</span></dt><dd>no_data bad_data worst_quality low_quality acceptable_quality best_quality</dd><dt><span>flag_values :</span></dt><dd>[0 1 2 3 4 5]</dd><dt><span>ancillary_variables :</span></dt><dd>pathfinder_quality_level</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>These are the overall quality indicators and are used for all GHRSST SSTs. Note, the native Pathfinder processing system returns quality levels ranging from 0 to 7 (7 is best quality; -1 represents missing data) and has been converted to the extent possible into the six levels required by the GDS2 (ranging from 0 to 5, where 5 is best). Below is the conversion table: \n",
       " GDS2 required quality_level 5  =  native Pathfinder quality level 7 == best_quality \n",
       " GDS2 required quality_level 4  =  native Pathfinder quality level 4-6 == acceptable_quality \n",
       " GDS2 required quality_level 3  =  native Pathfinder quality level 2-3 == low_quality \n",
       " GDS2 required quality_level 2  =  native Pathfinder quality level 1 == worst_quality \n",
       " GDS2 required quality_level 1  =  native Pathfinder quality level 0 = bad_data \n",
       " GDS2 required quality_level 0  =  native Pathfinder quality level -1 = missing_data \n",
       " The original Pathfinder quality level is recorded in the optional variable pathfinder_quality_level.</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pathfinder_quality_level</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-203c255c-47bb-49e8-a392-47cf7a205fbe' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-203c255c-47bb-49e8-a392-47cf7a205fbe' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1586598f-34e0-4d24-b59a-68658b978982' class='xr-var-data-in' type='checkbox'><label for='data-1586598f-34e0-4d24-b59a-68658b978982' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Pathfinder SST quality flag</dd><dt><span>coverage_content_type :</span></dt><dd>qualityInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>1</dd><dt><span>valid_min :</span></dt><dd>0</dd><dt><span>valid_max :</span></dt><dd>7</dd><dt><span>flag_meanings :</span></dt><dd>bad_data worst_quality low_quality low_quality acceptable_quality acceptable_quality acceptable_quality best_quality</dd><dt><span>flag_values :</span></dt><dd>[0 1 2 3 4 5 6 7]</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>This variable contains the native Pathfinder processing system quality levels, ranging from 0 to 7, where 0 is worst and 7 is best. And value -1 represents missing data.</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>l2p_flags</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-7266ab3f-1d65-415d-957c-f5176a7c211b' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-7266ab3f-1d65-415d-957c-f5176a7c211b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2aff6e5d-0bd6-4a68-8373-3d62605f6ab6' class='xr-var-data-in' type='checkbox'><label for='data-2aff6e5d-0bd6-4a68-8373-3d62605f6ab6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>L2P flags</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>1</dd><dt><span>valid_min :</span></dt><dd>0</dd><dt><span>valid_max :</span></dt><dd>256</dd><dt><span>flag_meanings :</span></dt><dd>microwave land ice lake river reserved_for_future_use extreme_sst unused_currently unused_currently</dd><dt><span>flag_masks :</span></dt><dd>[  1   2   4   8  16  32  64 128 256]</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>Bit zero (0) is always set to zero to indicate infrared data. Bit one (1) is set to zero for any pixel over water (ocean, lakes and rivers). Land pixels were determined by rasterizing the Global Self-consistent Hierarchical High-resolution Shoreline (GSHHS) Database from the NOAA National Geophysical Data Center. Any 4 km Pathfinder pixel whose area is 50% or more covered by land has bit one (1) set to 1. Bit two (2) is set to 1 when the sea_ice_fraction is 0.15 or greater. Bits three (3) and four (4) indicate lake and river pixels, respectively, and were determined by rasterizing the US World Wildlife Fund&#x27;s Global Lakes and Wetlands Database. Any 4 km Pathfinder pixel whose area is 50% or more covered by lake has bit three (3) set to 1. Any 4 km Pathfinder pixel whose area is 50% or more covered by river has bit four (4) set to 1. Bits six (6) indicates the daytime unrealistic SST values (&gt;39.8°C) that remain in pf_quality_level 4 to 7. Users are recommended to avoid these values.</dd></dl></div><div class='xr-var-data'><pre>[1451520 values with dtype=float64]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-214aee30-3f26-4079-85d5-cc848d8a7d96' class='xr-section-summary-in' type='checkbox'  ><label for='section-214aee30-3f26-4079-85d5-cc848d8a7d96' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-bba8b7b8-b74a-4b77-a935-67dff0adb5f9' class='xr-index-data-in' type='checkbox'/><label for='index-bba8b7b8-b74a-4b77-a935-67dff0adb5f9' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;1992-12-31 22:02:56&#x27;], dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-dcdae221-3f1c-4a43-83d9-841ec8ac9ff4' class='xr-index-data-in' type='checkbox'/><label for='index-dcdae221-3f1c-4a43-83d9-841ec8ac9ff4' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-10.020831108093262,  -10.06249713897705, -10.104164123535156,\n",
       "       -10.145831108093262,  -10.18749713897705, -10.229164123535156,\n",
       "       -10.270831108093262,  -10.31249713897705, -10.354164123535156,\n",
       "       -10.395831108093262,\n",
       "       ...\n",
       "       -16.604164123535156, -16.645830154418945, -16.687498092651367,\n",
       "       -16.729164123535156, -16.770830154418945, -16.812498092651367,\n",
       "       -16.854164123535156, -16.895830154418945, -16.937498092651367,\n",
       "       -16.979164123535156],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;lat&#x27;, length=168))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-3f9743fd-0de2-470d-a57b-ccf1af88389a' class='xr-index-data-in' type='checkbox'/><label for='index-3f9743fd-0de2-470d-a57b-ccf1af88389a' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ -179.9791717529297,           -179.9375, -179.89584350585938,\n",
       "        -179.8541717529297,           -179.8125, -179.77084350585938,\n",
       "        -179.7291717529297,           -179.6875, -179.64584350585938,\n",
       "        -179.6041717529297,\n",
       "       ...\n",
       "        179.60415649414062,   179.6458282470703,            179.6875,\n",
       "        179.72915649414062,   179.7708282470703,            179.8125,\n",
       "        179.85415649414062,   179.8958282470703,            179.9375,\n",
       "        179.97915649414062],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;lon&#x27;, length=8640))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-8c35256e-f151-4b04-93f7-0fcb07dd666a' class='xr-section-summary-in' type='checkbox'  ><label for='section-8c35256e-f151-4b04-93f7-0fcb07dd666a' class='xr-section-summary' >Attributes: <span>(74)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Conventions :</span></dt><dd>CF-1.6, ACDD-1.3</dd><dt><span>title :</span></dt><dd>AVHRR Pathfinder Version 5.3 L3-Collated (L3C) sea surface temperature</dd><dt><span>summary :</span></dt><dd>This netCDF-4 file contains sea surface temperature (SST) data produced as part of the AVHRR Pathfinder SST Project. These data were created using Version 5.3 of the Pathfinder algorithm and the file is nearly but not completely compliant with the GHRSST Data Specifications V2.0 (GDS2). The sses_bias and sses_standard_deviation variables are empty. Full compliance with GDS2 specifications will be achieved in the future Pathfinder Version 6. These data were created by the NOAA National Centers for Environmental Information (NCEI).</dd><dt><span>references :</span></dt><dd>http://pathfinder.nodc.noaa.gov and Casey, K.S., T.B. Brandon, P. Cornillon, and R. Evans: The Past, Present and Future of the AVHRR Pathfinder SST Program, in Oceanography from Space: Revisited, eds. V. Barale, J.F.R. Gower, and L. Alberotanza, Springer, 2010. DOI: 10.1007/978-90-481-8681-5_16.</dd><dt><span>institution :</span></dt><dd>NCEI</dd><dt><span>history :</span></dt><dd>smigen_both ifile=1993001.b4kd1-pf53ap-n11-sst.hdf ofile=1993001.i4kd1-pf53ap-n11-sst.hdf prod=sst datamin=-3.0 datamax=40.0 precision=I projection=RECT resolution=4km gap_fill=2 ; /srv/disk1t/PFV5.3CONV/bin/Converter/hdf2nc_PFV53_L3C.x -v /srv/disk1t/PFV5.3CONV/Data_PFV53/PFV53_HDF_L3C/1993/1993001.i4kd1-pf53ap-n11-sst.hdf</dd><dt><span>comment :</span></dt><dd>SST from AVHRR Pathfinder</dd><dt><span>license :</span></dt><dd>These data are available for use without restriction.</dd><dt><span>id :</span></dt><dd>AVHRR_Pathfinder-NCEI-L3C-v5.3</dd><dt><span>naming_authority :</span></dt><dd>org.ghrsst</dd><dt><span>product_version :</span></dt><dd>PFV5.3</dd><dt><span>uuid :</span></dt><dd>4FE5A020-8CE5-4DB5-89D5-DD5A5DD4ACD2</dd><dt><span>gds_version_id :</span></dt><dd>2.0</dd><dt><span>netcdf_version_id :</span></dt><dd>4.1.2</dd><dt><span>date_created :</span></dt><dd>20160512T234134Z</dd><dt><span>date_modified :</span></dt><dd>20160512T234134Z</dd><dt><span>date_issued :</span></dt><dd>20160301T000000Z</dd><dt><span>date_metadata_modified :</span></dt><dd>20160125T000000Z</dd><dt><span>file_quality_level :</span></dt><dd>3</dd><dt><span>spatial_resolution :</span></dt><dd>0.0416667 degree</dd><dt><span>geospatial_lat_units :</span></dt><dd>degrees north</dd><dt><span>geospatial_lat_resolution :</span></dt><dd>0.0416667</dd><dt><span>geospatial_lon_units :</span></dt><dd>degrees east</dd><dt><span>geospatial_lon_resolution :</span></dt><dd>0.0416667</dd><dt><span>geospatial_bounds :</span></dt><dd>-180.0000 -90.0000, 180.0000 90.0000</dd><dt><span>geospatial_bounds_crs :</span></dt><dd>EPSG:4326</dd><dt><span>geospatial_lon_min :</span></dt><dd>-180.0</dd><dt><span>geospatial_lon_max :</span></dt><dd>180.0</dd><dt><span>geospatial_lat_min :</span></dt><dd>-90.0</dd><dt><span>geospatial_lat_max :</span></dt><dd>90.0</dd><dt><span>northernmost_latitude :</span></dt><dd>90.0</dd><dt><span>southernmost_latitude :</span></dt><dd>-90.0</dd><dt><span>easternmost_longitude :</span></dt><dd>180.0</dd><dt><span>westernmost_longitude :</span></dt><dd>-180.0</dd><dt><span>principal_year_day_for_collated_orbits :</span></dt><dd>1993001</dd><dt><span>time_coverage_duration :</span></dt><dd>P1D</dd><dt><span>time_coverage_resolution :</span></dt><dd>P1D</dd><dt><span>start_time :</span></dt><dd>19921231T100256Z</dd><dt><span>time_coverage_start :</span></dt><dd>19921231T100256Z</dd><dt><span>stop_time :</span></dt><dd>19930101T183727Z</dd><dt><span>time_coverage_end :</span></dt><dd>19930101T183727Z</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>instrument :</span></dt><dd>AVHRR-2</dd><dt><span>sensor :</span></dt><dd>AVHRR-2</dd><dt><span>sea_name :</span></dt><dd>World-Wide Distribution</dd><dt><span>day_or_night :</span></dt><dd>Night</dd><dt><span>orbit_node :</span></dt><dd>Descending</dd><dt><span>keywords :</span></dt><dd>Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature</dd><dt><span>acknowledgement :</span></dt><dd>Please acknowledge the use of these data with the following statement: These data were provided by GHRSST and the NOAA National Centers for Environmental Information (NCEI). This project was supported in part by a grant from the NOAA Climate Data Record (CDR) Program for satellites.</dd><dt><span>creator_name :</span></dt><dd>Kenneth S. Casey</dd><dt><span>creator_email :</span></dt><dd>Kenneth.Casey@noaa.gov</dd><dt><span>creator_url :</span></dt><dd>http://pathfinder.nodc.noaa.gov</dd><dt><span>creator_type :</span></dt><dd>person</dd><dt><span>creator_institution :</span></dt><dd>US DOC; NOAA; National Environmental Satellite Data and Information Service; National Centers for Environmental Information</dd><dt><span>contributor_name :</span></dt><dd>Robert Evans</dd><dt><span>contributor_role :</span></dt><dd>Principal Investigator</dd><dt><span>project :</span></dt><dd>Group for High Resolution Sea Surface Temperature</dd><dt><span>publisher_name :</span></dt><dd>GHRSST Project Office</dd><dt><span>publisher_email :</span></dt><dd>ghrsst-po@nceo.ac.uk</dd><dt><span>publisher_url :</span></dt><dd>http://www.ghrsst.org</dd><dt><span>publisher_type :</span></dt><dd>group</dd><dt><span>processing_level :</span></dt><dd>L3C</dd><dt><span>cdm_data_type :</span></dt><dd>Grid</dd><dt><span>ncei_template_version :</span></dt><dd>NCEI_NetCDF_Grid_Template_v2.0</dd><dt><span>cdr_variable :</span></dt><dd>sea_surface_temperature</dd><dt><span>keywords_vocabulary :</span></dt><dd>NASA/Global Change Master Directory (GCMD) Science Keywords v8.4</dd><dt><span>standard_name_vocabulary :</span></dt><dd>Climate and Forecast (CF) Standard Name Table (Version 29, 08 July 2015)</dd><dt><span>platform_vocabulary :</span></dt><dd>NASA Global Change Master Directory (GCMD) Science Keywords v8.4</dd><dt><span>instrument_vocabulary :</span></dt><dd>NASA Global Change Master Directory (GCMD) Science Keywords v8.4</dd><dt><span>metadata_link :</span></dt><dd>http://data.nodc.noaa.gov/cgi-bin/iso?id=gov.noaa.nodc:AVHRR_Pathfinder-NCEI-L3C-v5.3</dd><dt><span>program :</span></dt><dd>NOAA Climate Data Record (CDR) Program for satellites</dd><dt><span>cdr_program :</span></dt><dd>NOAA Climate Data Record Program for satellites</dd><dt><span>cdr_id :</span></dt><dd>gov.noaa.ncdc:C00983</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                    (time: 1, nv: 2, lat: 168, lon: 8640)\n",
       "Coordinates:\n",
       "  * time                       (time) datetime64[ns] 1992-12-31T22:02:56\n",
       "  * lat                        (lat) float32 -10.02 -10.06 ... -16.94 -16.98\n",
       "  * lon                        (lon) float32 -180.0 -179.9 ... 179.9 180.0\n",
       "Dimensions without coordinates: nv\n",
       "Data variables: (12/15)\n",
       "    time_bounds                (time, nv) datetime64[ns] ...\n",
       "    lat_bounds                 (lat, nv) float32 ...\n",
       "    lon_bounds                 (lon, nv) float32 ...\n",
       "    crs                        int32 ...\n",
       "    sea_surface_temperature    (time, lat, lon) float32 ...\n",
       "    sst_dtime                  (time, lat, lon) timedelta64[ns] ...\n",
       "    ...                         ...\n",
       "    wind_speed                 (time, lat, lon) float32 ...\n",
       "    sea_ice_fraction           (time, lat, lon) float32 ...\n",
       "    aerosol_dynamic_indicator  (time, lat, lon) float32 ...\n",
       "    quality_level              (time, lat, lon) float32 ...\n",
       "    pathfinder_quality_level   (time, lat, lon) float32 ...\n",
       "    l2p_flags                  (time, lat, lon) float64 ...\n",
       "Attributes: (12/74)\n",
       "    Conventions:                             CF-1.6, ACDD-1.3\n",
       "    title:                                   AVHRR Pathfinder Version 5.3 L3-...\n",
       "    summary:                                 This netCDF-4 file contains sea ...\n",
       "    references:                              http://pathfinder.nodc.noaa.gov ...\n",
       "    institution:                             NCEI\n",
       "    history:                                 smigen_both ifile=1993001.b4kd1-...\n",
       "    ...                                      ...\n",
       "    platform_vocabulary:                     NASA Global Change Master Direct...\n",
       "    instrument_vocabulary:                   NASA Global Change Master Direct...\n",
       "    metadata_link:                           http://data.nodc.noaa.gov/cgi-bi...\n",
       "    program:                                 NOAA Climate Data Record (CDR) P...\n",
       "    cdr_program:                             NOAA Climate Data Record Program...\n",
       "    cdr_id:                                  gov.noaa.ncdc:C00983"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sel({\"lat\":slice(-10,-17)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = process_xa_d(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:                    (time: 1, nv: 2, latitude: 120, longitude: 3168)\n",
       "Coordinates:\n",
       "  * time                       (time) datetime64[ns] 1992-12-31T22:02:56\n",
       "  * latitude                   (latitude) float32 -16.98 -16.94 ... -12.02\n",
       "  * longitude                  (longitude) float32 -142.0 -141.9 ... -10.02\n",
       "Dimensions without coordinates: nv\n",
       "Data variables: (12/15)\n",
       "    time_bounds                (time, nv) datetime64[ns] ...\n",
       "    lat_bounds                 (latitude, nv) float32 ...\n",
       "    lon_bounds                 (longitude, nv) float32 ...\n",
       "    crs                        int32 ...\n",
       "    sea_surface_temperature    (time, latitude, longitude) float32 ...\n",
       "    sst_dtime                  (time, latitude, longitude) timedelta64[ns] ...\n",
       "    ...                         ...\n",
       "    wind_speed                 (time, latitude, longitude) float32 ...\n",
       "    sea_ice_fraction           (time, latitude, longitude) float32 ...\n",
       "    aerosol_dynamic_indicator  (time, latitude, longitude) float32 ...\n",
       "    quality_level              (time, latitude, longitude) float32 ...\n",
       "    pathfinder_quality_level   (time, latitude, longitude) float32 ...\n",
       "    l2p_flags                  (time, latitude, longitude) float64 ...\n",
       "Attributes: (12/74)\n",
       "    Conventions:                             CF-1.6, ACDD-1.3\n",
       "    title:                                   AVHRR Pathfinder Version 5.3 L3-...\n",
       "    summary:                                 This netCDF-4 file contains sea ...\n",
       "    references:                              http://pathfinder.nodc.noaa.gov ...\n",
       "    institution:                             NCEI\n",
       "    history:                                 smigen_both ifile=1993001.b4kd1-...\n",
       "    ...                                      ...\n",
       "    platform_vocabulary:                     NASA Global Change Master Direct...\n",
       "    instrument_vocabulary:                   NASA Global Change Master Direct...\n",
       "    metadata_link:                           http://data.nodc.noaa.gov/cgi-bi...\n",
       "    program:                                 NOAA Climate Data Record (CDR) P...\n",
       "    cdr_program:                             NOAA Climate Data Record Program...\n",
       "    cdr_id:                                  gov.noaa.ncdc:C00983</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-5cc27084-1ff0-4d5d-9c87-375e109b1cf9' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-5cc27084-1ff0-4d5d-9c87-375e109b1cf9' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 1</li><li><span>nv</span>: 2</li><li><span class='xr-has-index'>latitude</span>: 120</li><li><span class='xr-has-index'>longitude</span>: 3168</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-0836d0e1-2e16-4037-a7f6-e66a74b38ae1' class='xr-section-summary-in' type='checkbox'  checked><label for='section-0836d0e1-2e16-4037-a7f6-e66a74b38ae1' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1992-12-31T22:02:56</div><input id='attrs-8bc014cb-af42-46a8-876e-0f9671aee341' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-8bc014cb-af42-46a8-876e-0f9671aee341' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d05dec7f-bb59-466c-bd30-538ccdaafcd3' class='xr-var-data-in' type='checkbox'><label for='data-d05dec7f-bb59-466c-bd30-538ccdaafcd3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>long_name :</span></dt><dd>reference time of SST file</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>comment :</span></dt><dd>This is the reference time of the SST file. Add sst_dtime to this value to get pixel-by-pixel times.</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1992-12-31T22:02:56.000000000&#x27;], dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-16.98 -16.94 ... -12.06 -12.02</div><input id='attrs-979f9b1c-de7b-439e-a95a-5d47c26feed1' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-979f9b1c-de7b-439e-a95a-5d47c26feed1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2a8676fb-0070-4497-836c-dbbb8dfab40b' class='xr-var-data-in' type='checkbox'><label for='data-2a8676fb-0070-4497-836c-dbbb8dfab40b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>reference_datum :</span></dt><dd>Geographical coordinates, WGS84 datum</dd><dt><span>axis :</span></dt><dd>Y</dd><dt><span>valid_min :</span></dt><dd>-90.0</dd><dt><span>valid_max :</span></dt><dd>90.0</dd></dl></div><div class='xr-var-data'><pre>array([-16.979164, -16.937498, -16.89583 , -16.854164, -16.812498, -16.77083 ,\n",
       "       -16.729164, -16.687498, -16.64583 , -16.604164, -16.562498, -16.52083 ,\n",
       "       -16.479164, -16.437498, -16.39583 , -16.354164, -16.312498, -16.27083 ,\n",
       "       -16.229164, -16.187498, -16.14583 , -16.104164, -16.062498, -16.02083 ,\n",
       "       -15.979164, -15.937497, -15.895831, -15.854164, -15.812497, -15.770831,\n",
       "       -15.729164, -15.687497, -15.645831, -15.604164, -15.562497, -15.520831,\n",
       "       -15.479164, -15.437497, -15.395831, -15.354164, -15.312497, -15.270831,\n",
       "       -15.229164, -15.187497, -15.145831, -15.104164, -15.062497, -15.020831,\n",
       "       -14.979164, -14.937497, -14.895831, -14.854164, -14.812497, -14.770831,\n",
       "       -14.729164, -14.687497, -14.645831, -14.604164, -14.562497, -14.520831,\n",
       "       -14.479164, -14.437497, -14.395831, -14.354164, -14.312497, -14.270831,\n",
       "       -14.229164, -14.187497, -14.145831, -14.104164, -14.062497, -14.020831,\n",
       "       -13.979164, -13.937497, -13.895831, -13.854164, -13.812497, -13.770831,\n",
       "       -13.729164, -13.687497, -13.645831, -13.604164, -13.562497, -13.520831,\n",
       "       -13.479164, -13.437497, -13.395831, -13.354164, -13.312497, -13.270831,\n",
       "       -13.229164, -13.187497, -13.145831, -13.104164, -13.062497, -13.020831,\n",
       "       -12.979164, -12.937497, -12.895831, -12.854164, -12.812497, -12.770831,\n",
       "       -12.729164, -12.687497, -12.645831, -12.604164, -12.562497, -12.520831,\n",
       "       -12.479164, -12.437497, -12.395831, -12.354164, -12.312497, -12.270831,\n",
       "       -12.229164, -12.187497, -12.145831, -12.104164, -12.062497, -12.020831],\n",
       "      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-142.0 -141.9 ... -10.06 -10.02</div><input id='attrs-ac86bc58-f065-486f-bdf1-7f47f1f3b687' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-ac86bc58-f065-486f-bdf1-7f47f1f3b687' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d423aa25-d608-4af9-87d5-e6b85fd12fdb' class='xr-var-data-in' type='checkbox'><label for='data-d423aa25-d608-4af9-87d5-e6b85fd12fdb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>reference_datum :</span></dt><dd>Geographical coordinates, WGS84 datum</dd><dt><span>axis :</span></dt><dd>X</dd><dt><span>valid_min :</span></dt><dd>-180.0</dd><dt><span>valid_max :</span></dt><dd>180.0</dd></dl></div><div class='xr-var-data'><pre>array([-141.97917 , -141.9375  , -141.89584 , ...,  -10.104172,  -10.062505,\n",
       "        -10.020839], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f24bd8d8-0d0a-40ff-b090-03bc5e6d30a2' class='xr-section-summary-in' type='checkbox'  ><label for='section-f24bd8d8-0d0a-40ff-b090-03bc5e6d30a2' class='xr-section-summary' >Data variables: <span>(15)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>time_bounds</span></div><div class='xr-var-dims'>(time, nv)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-1b339abd-ccf4-49ae-9cdb-ef15bd4960b9' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-1b339abd-ccf4-49ae-9cdb-ef15bd4960b9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-66c44919-e35d-4f06-aabd-5887326809c6' class='xr-var-data-in' type='checkbox'><label for='data-66c44919-e35d-4f06-aabd-5887326809c6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>time bounds</dd><dt><span>comment :</span></dt><dd>time bounds for each time value</dd></dl></div><div class='xr-var-data'><pre>[2 values with dtype=datetime64[ns]]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lat_bounds</span></div><div class='xr-var-dims'>(latitude, nv)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-e4e2f151-2134-42a7-a727-e131188e688d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e4e2f151-2134-42a7-a727-e131188e688d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a4a09534-07ef-4ec4-b6ca-f9fbd7bf9369' class='xr-var-data-in' type='checkbox'><label for='data-a4a09534-07ef-4ec4-b6ca-f9fbd7bf9369' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>latitude bounds</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>comment :</span></dt><dd>latitude values at the north and south bounds of each grid point</dd></dl></div><div class='xr-var-data'><pre>[240 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon_bounds</span></div><div class='xr-var-dims'>(longitude, nv)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-7152d373-c162-4ae3-8162-8284ce4cfb52' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-7152d373-c162-4ae3-8162-8284ce4cfb52' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6036262f-4e61-432d-91e5-1500ba043392' class='xr-var-data-in' type='checkbox'><label for='data-6036262f-4e61-432d-91e5-1500ba043392' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>longitude bounds</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>comment :</span></dt><dd>longitude values at the west and east bounds of each grid point</dd></dl></div><div class='xr-var-data'><pre>[6336 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>crs</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-503be0c0-7446-4981-9e80-5731ee53a518' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-503be0c0-7446-4981-9e80-5731ee53a518' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a1af7d1b-49ab-4201-bf35-6617341b453f' class='xr-var-data-in' type='checkbox'><label for='data-a1af7d1b-49ab-4201-bf35-6617341b453f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>coordinate reference system</dd><dt><span>grid_mapping_name :</span></dt><dd>latitude_longitude</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223563</dd><dt><span>epsg_code :</span></dt><dd>EPSG:4326</dd><dt><span>comment :</span></dt><dd>This is a container variable that describes the grid_mapping used by the data in this file. This variable does not contain any data; only information about the geographic coordinate system.</dd></dl></div><div class='xr-var-data'><pre>[1 values with dtype=int32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sea_surface_temperature</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-2de0c610-0652-4711-90fc-e6d46dc46a32' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2de0c610-0652-4711-90fc-e6d46dc46a32' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-38180651-cb9b-4eea-a220-10553d03b56f' class='xr-var-data-in' type='checkbox'><label for='data-38180651-cb9b-4eea-a220-10553d03b56f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>sea_surface_skin_temperature</dd><dt><span>long_name :</span></dt><dd>NOAA Climate Data Record of sea surface skin temperature</dd><dt><span>coverage_content_type :</span></dt><dd>physicalMeasurement</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>kelvin</dd><dt><span>valid_min :</span></dt><dd>-180</dd><dt><span>valid_max :</span></dt><dd>4500</dd><dt><span>ancillary_variables :</span></dt><dd>quality_level pathfinder_quality_level l2p_flags</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>Skin temperature of the ocean</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sst_dtime</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>timedelta64[ns]</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-9a957039-cc97-4a4f-b2c6-b3d3e3e160c7' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-9a957039-cc97-4a4f-b2c6-b3d3e3e160c7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-71ee3e89-f19c-4695-8def-c1fb7773514f' class='xr-var-data-in' type='checkbox'><label for='data-71ee3e89-f19c-4695-8def-c1fb7773514f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>time difference from reference time</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>valid_min :</span></dt><dd>-2147483647</dd><dt><span>valid_max :</span></dt><dd>2147483647</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>Time plus sst_dtime gives seconds after 1981-01-01 00:00:00. Note: in PFV5.3 this sst_dtime is empty. PFV6 will contain the correct sst_dtime values.</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=timedelta64[ns]]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sses_bias</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-10b75ad2-d8ce-4119-b9f2-521a6174db0e' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-10b75ad2-d8ce-4119-b9f2-521a6174db0e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8bb1d19e-c193-4591-94ea-a5596e80285b' class='xr-var-data-in' type='checkbox'><label for='data-8bb1d19e-c193-4591-94ea-a5596e80285b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>SSES bias estimate</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>kelvin</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>Bias estimate derived using the techniques described at https://www.ghrsst.org/ghrsst/tags-and-wgs/stval-wg/sses-description-of-schemes/. Note: in PFV5.3 this sses_bias is empty. PFV6 will contain the correct sses_bias values.</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sses_standard_deviation</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-19d7ec5a-72ec-4068-b34c-94172a9c2f78' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-19d7ec5a-72ec-4068-b34c-94172a9c2f78' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ae2ac8a1-9eef-4539-983b-db511de01577' class='xr-var-data-in' type='checkbox'><label for='data-ae2ac8a1-9eef-4539-983b-db511de01577' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>SSES standard deviation</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>kelvin</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>Standard deviation estimate derived using the techniques described at https://www.ghrsst.org/ghrsst/tags-and-wgs/stval-wg/sses-description-of-schemes/. Note: in PFV5.3 this sses_standard_deviation is empty. PFV6 will contain the correct sses_standard_deviation values.</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>dt_analysis</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-b997a20b-5906-4ecf-9111-3d8e2016aa5d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b997a20b-5906-4ecf-9111-3d8e2016aa5d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6bc72b2f-5c1f-4e92-998c-2e7b11c73879' class='xr-var-data-in' type='checkbox'><label for='data-6bc72b2f-5c1f-4e92-998c-2e7b11c73879' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>deviation from last SST analysis</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>kelvin</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>source :</span></dt><dd>NOAA Daily 25km Global Optimally Interpolated Sea Surface Temperature (OISST)</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>reference :</span></dt><dd>AVHRR_OI, with inland values populated from AVHRR_Pathfinder daily climatological SST. For more information on this reference field see http://accession.nodc.noaa.gov/0071180.</dd><dt><span>comment :</span></dt><dd>The difference between this SST and the previous day&#x27;s SST.</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>wind_speed</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-7aa87b14-3d92-4bf1-a970-90d652c8d96f' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-7aa87b14-3d92-4bf1-a970-90d652c8d96f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9dd34149-3df8-43fb-81a4-639e10760630' class='xr-var-data-in' type='checkbox'><label for='data-9dd34149-3df8-43fb-81a4-639e10760630' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>wind_speed</dd><dt><span>long_name :</span></dt><dd>10m wind speed</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>m s-1</dd><dt><span>height :</span></dt><dd>10 m</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>time_offset :</span></dt><dd>2.2011</dd><dt><span>source :</span></dt><dd>NCEP/DOE AMIP-II Reanalysis (Reanalysis-2): u_wind.10m.gauss.1993.nc, v_wind.10m.gauss.1993.nc</dd><dt><span>comment :</span></dt><dd>These wind speeds were created by NCEP-DOE Atmospheric Model Intercomparison Project (AMIP-II) reanalysis (R-2) and represent winds at 10 metres above the sea surface.</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sea_ice_fraction</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-c0816d8d-facc-4146-827e-8fd802d74cb8' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c0816d8d-facc-4146-827e-8fd802d74cb8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-263111f5-1848-4098-a0c1-c0f045a26323' class='xr-var-data-in' type='checkbox'><label for='data-263111f5-1848-4098-a0c1-c0f045a26323' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>sea_ice_area_fraction</dd><dt><span>long_name :</span></dt><dd>sea ice fraction</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>percent</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>time_offset :</span></dt><dd>10.0</dd><dt><span>source :</span></dt><dd>NOAA/NESDIS/NCDC Daily optimum interpolation(OI) SST on 1/4-degree grid: 19930101-NCDC-L4LRblend-GLOB-v01-fv02_0-AVHRR_OI.nc.gz</dd><dt><span>comment :</span></dt><dd>Sea ice concentration data are taken from the EUMETSAT Ocean and Sea Ice Satellite Application Facility (OSISAF) Global Daily Sea Ice Concentration Reprocessing Data Set (http://accession.nodc.noaa.gov/0068294) when these data are available. The data are reprojected and interpolated from their original polar stereographic projection at 10km spatial resolution to the 4km Pathfinder Version 5.3 grid. When the OSISAF data are not available for both hemispheres on a given day, the sea ice concentration data are taken from the sea_ice_fraction variable found in the L4 GHRSST DailyOI SST product from NOAA/NCDC, and are interpolated from the 25km DailyOI grid to the 4km Pathfinder Version 5.3 grid.</dd><dt><span>reference :</span></dt><dd>Reynolds, et al.(2006) Daily High-resolution Blended Analyses. Available at http://doi.org/10.7289/V5SQ8XB5</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>aerosol_dynamic_indicator</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-5dfe90e8-81e3-407a-9f5b-5324256bbd64' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-5dfe90e8-81e3-407a-9f5b-5324256bbd64' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d797d5d2-1bc4-4d55-b13f-62efde02a22c' class='xr-var-data-in' type='checkbox'><label for='data-d797d5d2-1bc4-4d55-b13f-62efde02a22c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>aerosol dynamic indicator</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>percent</dd><dt><span>valid_min :</span></dt><dd>-127</dd><dt><span>valid_max :</span></dt><dd>127</dd><dt><span>time_offset :</span></dt><dd>360.0</dd><dt><span>source :</span></dt><dd>CLASS_AVHRRPF_AOT</dd><dt><span>reference :</span></dt><dd>http://www.class.ncdc.noaa.gov/saa/products/search?sub_id=0&amp;datatype_family=AVHRRPF</dd><dt><span>comment :</span></dt><dd>Aerosol optical thickness (AOT) data are taken from the CLASS Pathfinder (from AVHRR) (AVHRRPF). The aerosol optical thickness/depth (AOT/AOD) measurements are extracted from PATMOS-A2 monthly mean and reprojected and interpolated from their original 1 degree x 1 degree resolution to the 4km Pathfinder Version 5.3 grid.</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>quality_level</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-2c3fac74-f3d3-4c89-9876-65e048d43036' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2c3fac74-f3d3-4c89-9876-65e048d43036' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-817a9443-e8d8-4874-ac63-9bada4d64144' class='xr-var-data-in' type='checkbox'><label for='data-817a9443-e8d8-4874-ac63-9bada4d64144' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>quality level of SST pixel</dd><dt><span>coverage_content_type :</span></dt><dd>qualityInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>1</dd><dt><span>valid_min :</span></dt><dd>1</dd><dt><span>valid_max :</span></dt><dd>5</dd><dt><span>flag_meanings :</span></dt><dd>no_data bad_data worst_quality low_quality acceptable_quality best_quality</dd><dt><span>flag_values :</span></dt><dd>[0 1 2 3 4 5]</dd><dt><span>ancillary_variables :</span></dt><dd>pathfinder_quality_level</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>These are the overall quality indicators and are used for all GHRSST SSTs. Note, the native Pathfinder processing system returns quality levels ranging from 0 to 7 (7 is best quality; -1 represents missing data) and has been converted to the extent possible into the six levels required by the GDS2 (ranging from 0 to 5, where 5 is best). Below is the conversion table: \n",
       " GDS2 required quality_level 5  =  native Pathfinder quality level 7 == best_quality \n",
       " GDS2 required quality_level 4  =  native Pathfinder quality level 4-6 == acceptable_quality \n",
       " GDS2 required quality_level 3  =  native Pathfinder quality level 2-3 == low_quality \n",
       " GDS2 required quality_level 2  =  native Pathfinder quality level 1 == worst_quality \n",
       " GDS2 required quality_level 1  =  native Pathfinder quality level 0 = bad_data \n",
       " GDS2 required quality_level 0  =  native Pathfinder quality level -1 = missing_data \n",
       " The original Pathfinder quality level is recorded in the optional variable pathfinder_quality_level.</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pathfinder_quality_level</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-9abf0679-b988-482b-ac76-8d8b6ce7da61' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-9abf0679-b988-482b-ac76-8d8b6ce7da61' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-319d329c-d332-4d03-b0a4-9d19c857be4e' class='xr-var-data-in' type='checkbox'><label for='data-319d329c-d332-4d03-b0a4-9d19c857be4e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Pathfinder SST quality flag</dd><dt><span>coverage_content_type :</span></dt><dd>qualityInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>1</dd><dt><span>valid_min :</span></dt><dd>0</dd><dt><span>valid_max :</span></dt><dd>7</dd><dt><span>flag_meanings :</span></dt><dd>bad_data worst_quality low_quality low_quality acceptable_quality acceptable_quality acceptable_quality best_quality</dd><dt><span>flag_values :</span></dt><dd>[0 1 2 3 4 5 6 7]</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>This variable contains the native Pathfinder processing system quality levels, ranging from 0 to 7, where 0 is worst and 7 is best. And value -1 represents missing data.</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>l2p_flags</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-a90ace04-832f-4c89-b265-56e0cdf14331' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a90ace04-832f-4c89-b265-56e0cdf14331' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-486e0d73-51d2-4d7f-8241-255db3357e80' class='xr-var-data-in' type='checkbox'><label for='data-486e0d73-51d2-4d7f-8241-255db3357e80' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>L2P flags</dd><dt><span>coverage_content_type :</span></dt><dd>auxiliaryInformation</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd><dt><span>units :</span></dt><dd>1</dd><dt><span>valid_min :</span></dt><dd>0</dd><dt><span>valid_max :</span></dt><dd>256</dd><dt><span>flag_meanings :</span></dt><dd>microwave land ice lake river reserved_for_future_use extreme_sst unused_currently unused_currently</dd><dt><span>flag_masks :</span></dt><dd>[  1   2   4   8  16  32  64 128 256]</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>comment :</span></dt><dd>Bit zero (0) is always set to zero to indicate infrared data. Bit one (1) is set to zero for any pixel over water (ocean, lakes and rivers). Land pixels were determined by rasterizing the Global Self-consistent Hierarchical High-resolution Shoreline (GSHHS) Database from the NOAA National Geophysical Data Center. Any 4 km Pathfinder pixel whose area is 50% or more covered by land has bit one (1) set to 1. Bit two (2) is set to 1 when the sea_ice_fraction is 0.15 or greater. Bits three (3) and four (4) indicate lake and river pixels, respectively, and were determined by rasterizing the US World Wildlife Fund&#x27;s Global Lakes and Wetlands Database. Any 4 km Pathfinder pixel whose area is 50% or more covered by lake has bit three (3) set to 1. Any 4 km Pathfinder pixel whose area is 50% or more covered by river has bit four (4) set to 1. Bits six (6) indicates the daytime unrealistic SST values (&gt;39.8°C) that remain in pf_quality_level 4 to 7. Users are recommended to avoid these values.</dd></dl></div><div class='xr-var-data'><pre>[380160 values with dtype=float64]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-3b57d857-b959-4cab-ba65-fe448ba672e7' class='xr-section-summary-in' type='checkbox'  ><label for='section-3b57d857-b959-4cab-ba65-fe448ba672e7' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-b0bcb5ad-f49d-40a2-babc-4426bb24f3b2' class='xr-index-data-in' type='checkbox'/><label for='index-b0bcb5ad-f49d-40a2-babc-4426bb24f3b2' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;1992-12-31 22:02:56&#x27;], dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-95bcc52f-c9ac-46c8-843f-26ed19733733' class='xr-index-data-in' type='checkbox'/><label for='index-95bcc52f-c9ac-46c8-843f-26ed19733733' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-16.979164123535156, -16.937498092651367, -16.895830154418945,\n",
       "       -16.854164123535156, -16.812498092651367, -16.770830154418945,\n",
       "       -16.729164123535156, -16.687498092651367, -16.645830154418945,\n",
       "       -16.604164123535156,\n",
       "       ...\n",
       "       -12.395831108093262, -12.354164123535156,  -12.31249713897705,\n",
       "       -12.270831108093262, -12.229164123535156,  -12.18749713897705,\n",
       "       -12.145831108093262, -12.104164123535156,  -12.06249713897705,\n",
       "       -12.020831108093262],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;latitude&#x27;, length=120))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-72ba09a4-ee48-4f74-957f-34c43c38ea7a' class='xr-index-data-in' type='checkbox'/><label for='index-72ba09a4-ee48-4f74-957f-34c43c38ea7a' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ -141.9791717529297,           -141.9375, -141.89584350585938,\n",
       "        -141.8541717529297,           -141.8125, -141.77084350585938,\n",
       "        -141.7291717529297,           -141.6875, -141.64584350585938,\n",
       "        -141.6041717529297,\n",
       "       ...\n",
       "       -10.395838737487793, -10.354171752929688, -10.312504768371582,\n",
       "       -10.270838737487793, -10.229171752929688, -10.187504768371582,\n",
       "       -10.145838737487793, -10.104171752929688, -10.062504768371582,\n",
       "       -10.020838737487793],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;longitude&#x27;, length=3168))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-9adff3b9-5977-4aae-994e-0eeaaa16b156' class='xr-section-summary-in' type='checkbox'  ><label for='section-9adff3b9-5977-4aae-994e-0eeaaa16b156' class='xr-section-summary' >Attributes: <span>(74)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Conventions :</span></dt><dd>CF-1.6, ACDD-1.3</dd><dt><span>title :</span></dt><dd>AVHRR Pathfinder Version 5.3 L3-Collated (L3C) sea surface temperature</dd><dt><span>summary :</span></dt><dd>This netCDF-4 file contains sea surface temperature (SST) data produced as part of the AVHRR Pathfinder SST Project. These data were created using Version 5.3 of the Pathfinder algorithm and the file is nearly but not completely compliant with the GHRSST Data Specifications V2.0 (GDS2). The sses_bias and sses_standard_deviation variables are empty. Full compliance with GDS2 specifications will be achieved in the future Pathfinder Version 6. These data were created by the NOAA National Centers for Environmental Information (NCEI).</dd><dt><span>references :</span></dt><dd>http://pathfinder.nodc.noaa.gov and Casey, K.S., T.B. Brandon, P. Cornillon, and R. Evans: The Past, Present and Future of the AVHRR Pathfinder SST Program, in Oceanography from Space: Revisited, eds. V. Barale, J.F.R. Gower, and L. Alberotanza, Springer, 2010. DOI: 10.1007/978-90-481-8681-5_16.</dd><dt><span>institution :</span></dt><dd>NCEI</dd><dt><span>history :</span></dt><dd>smigen_both ifile=1993001.b4kd1-pf53ap-n11-sst.hdf ofile=1993001.i4kd1-pf53ap-n11-sst.hdf prod=sst datamin=-3.0 datamax=40.0 precision=I projection=RECT resolution=4km gap_fill=2 ; /srv/disk1t/PFV5.3CONV/bin/Converter/hdf2nc_PFV53_L3C.x -v /srv/disk1t/PFV5.3CONV/Data_PFV53/PFV53_HDF_L3C/1993/1993001.i4kd1-pf53ap-n11-sst.hdf</dd><dt><span>comment :</span></dt><dd>SST from AVHRR Pathfinder</dd><dt><span>license :</span></dt><dd>These data are available for use without restriction.</dd><dt><span>id :</span></dt><dd>AVHRR_Pathfinder-NCEI-L3C-v5.3</dd><dt><span>naming_authority :</span></dt><dd>org.ghrsst</dd><dt><span>product_version :</span></dt><dd>PFV5.3</dd><dt><span>uuid :</span></dt><dd>4FE5A020-8CE5-4DB5-89D5-DD5A5DD4ACD2</dd><dt><span>gds_version_id :</span></dt><dd>2.0</dd><dt><span>netcdf_version_id :</span></dt><dd>4.1.2</dd><dt><span>date_created :</span></dt><dd>20160512T234134Z</dd><dt><span>date_modified :</span></dt><dd>20160512T234134Z</dd><dt><span>date_issued :</span></dt><dd>20160301T000000Z</dd><dt><span>date_metadata_modified :</span></dt><dd>20160125T000000Z</dd><dt><span>file_quality_level :</span></dt><dd>3</dd><dt><span>spatial_resolution :</span></dt><dd>0.0416667 degree</dd><dt><span>geospatial_lat_units :</span></dt><dd>degrees north</dd><dt><span>geospatial_lat_resolution :</span></dt><dd>0.0416667</dd><dt><span>geospatial_lon_units :</span></dt><dd>degrees east</dd><dt><span>geospatial_lon_resolution :</span></dt><dd>0.0416667</dd><dt><span>geospatial_bounds :</span></dt><dd>-180.0000 -90.0000, 180.0000 90.0000</dd><dt><span>geospatial_bounds_crs :</span></dt><dd>EPSG:4326</dd><dt><span>geospatial_lon_min :</span></dt><dd>-180.0</dd><dt><span>geospatial_lon_max :</span></dt><dd>180.0</dd><dt><span>geospatial_lat_min :</span></dt><dd>-90.0</dd><dt><span>geospatial_lat_max :</span></dt><dd>90.0</dd><dt><span>northernmost_latitude :</span></dt><dd>90.0</dd><dt><span>southernmost_latitude :</span></dt><dd>-90.0</dd><dt><span>easternmost_longitude :</span></dt><dd>180.0</dd><dt><span>westernmost_longitude :</span></dt><dd>-180.0</dd><dt><span>principal_year_day_for_collated_orbits :</span></dt><dd>1993001</dd><dt><span>time_coverage_duration :</span></dt><dd>P1D</dd><dt><span>time_coverage_resolution :</span></dt><dd>P1D</dd><dt><span>start_time :</span></dt><dd>19921231T100256Z</dd><dt><span>time_coverage_start :</span></dt><dd>19921231T100256Z</dd><dt><span>stop_time :</span></dt><dd>19930101T183727Z</dd><dt><span>time_coverage_end :</span></dt><dd>19930101T183727Z</dd><dt><span>source :</span></dt><dd>AVHRR_GAC-CLASS-L1B-NOAA_11-v1</dd><dt><span>platform :</span></dt><dd>NOAA-11</dd><dt><span>instrument :</span></dt><dd>AVHRR-2</dd><dt><span>sensor :</span></dt><dd>AVHRR-2</dd><dt><span>sea_name :</span></dt><dd>World-Wide Distribution</dd><dt><span>day_or_night :</span></dt><dd>Night</dd><dt><span>orbit_node :</span></dt><dd>Descending</dd><dt><span>keywords :</span></dt><dd>Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature</dd><dt><span>acknowledgement :</span></dt><dd>Please acknowledge the use of these data with the following statement: These data were provided by GHRSST and the NOAA National Centers for Environmental Information (NCEI). This project was supported in part by a grant from the NOAA Climate Data Record (CDR) Program for satellites.</dd><dt><span>creator_name :</span></dt><dd>Kenneth S. Casey</dd><dt><span>creator_email :</span></dt><dd>Kenneth.Casey@noaa.gov</dd><dt><span>creator_url :</span></dt><dd>http://pathfinder.nodc.noaa.gov</dd><dt><span>creator_type :</span></dt><dd>person</dd><dt><span>creator_institution :</span></dt><dd>US DOC; NOAA; National Environmental Satellite Data and Information Service; National Centers for Environmental Information</dd><dt><span>contributor_name :</span></dt><dd>Robert Evans</dd><dt><span>contributor_role :</span></dt><dd>Principal Investigator</dd><dt><span>project :</span></dt><dd>Group for High Resolution Sea Surface Temperature</dd><dt><span>publisher_name :</span></dt><dd>GHRSST Project Office</dd><dt><span>publisher_email :</span></dt><dd>ghrsst-po@nceo.ac.uk</dd><dt><span>publisher_url :</span></dt><dd>http://www.ghrsst.org</dd><dt><span>publisher_type :</span></dt><dd>group</dd><dt><span>processing_level :</span></dt><dd>L3C</dd><dt><span>cdm_data_type :</span></dt><dd>Grid</dd><dt><span>ncei_template_version :</span></dt><dd>NCEI_NetCDF_Grid_Template_v2.0</dd><dt><span>cdr_variable :</span></dt><dd>sea_surface_temperature</dd><dt><span>keywords_vocabulary :</span></dt><dd>NASA/Global Change Master Directory (GCMD) Science Keywords v8.4</dd><dt><span>standard_name_vocabulary :</span></dt><dd>Climate and Forecast (CF) Standard Name Table (Version 29, 08 July 2015)</dd><dt><span>platform_vocabulary :</span></dt><dd>NASA Global Change Master Directory (GCMD) Science Keywords v8.4</dd><dt><span>instrument_vocabulary :</span></dt><dd>NASA Global Change Master Directory (GCMD) Science Keywords v8.4</dd><dt><span>metadata_link :</span></dt><dd>http://data.nodc.noaa.gov/cgi-bin/iso?id=gov.noaa.nodc:AVHRR_Pathfinder-NCEI-L3C-v5.3</dd><dt><span>program :</span></dt><dd>NOAA Climate Data Record (CDR) Program for satellites</dd><dt><span>cdr_program :</span></dt><dd>NOAA Climate Data Record Program for satellites</dd><dt><span>cdr_id :</span></dt><dd>gov.noaa.ncdc:C00983</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                    (time: 1, nv: 2, latitude: 120, longitude: 3168)\n",
       "Coordinates:\n",
       "  * time                       (time) datetime64[ns] 1992-12-31T22:02:56\n",
       "  * latitude                   (latitude) float32 -16.98 -16.94 ... -12.02\n",
       "  * longitude                  (longitude) float32 -142.0 -141.9 ... -10.02\n",
       "Dimensions without coordinates: nv\n",
       "Data variables: (12/15)\n",
       "    time_bounds                (time, nv) datetime64[ns] ...\n",
       "    lat_bounds                 (latitude, nv) float32 ...\n",
       "    lon_bounds                 (longitude, nv) float32 ...\n",
       "    crs                        int32 ...\n",
       "    sea_surface_temperature    (time, latitude, longitude) float32 ...\n",
       "    sst_dtime                  (time, latitude, longitude) timedelta64[ns] ...\n",
       "    ...                         ...\n",
       "    wind_speed                 (time, latitude, longitude) float32 ...\n",
       "    sea_ice_fraction           (time, latitude, longitude) float32 ...\n",
       "    aerosol_dynamic_indicator  (time, latitude, longitude) float32 ...\n",
       "    quality_level              (time, latitude, longitude) float32 ...\n",
       "    pathfinder_quality_level   (time, latitude, longitude) float32 ...\n",
       "    l2p_flags                  (time, latitude, longitude) float64 ...\n",
       "Attributes: (12/74)\n",
       "    Conventions:                             CF-1.6, ACDD-1.3\n",
       "    title:                                   AVHRR Pathfinder Version 5.3 L3-...\n",
       "    summary:                                 This netCDF-4 file contains sea ...\n",
       "    references:                              http://pathfinder.nodc.noaa.gov ...\n",
       "    institution:                             NCEI\n",
       "    history:                                 smigen_both ifile=1993001.b4kd1-...\n",
       "    ...                                      ...\n",
       "    platform_vocabulary:                     NASA Global Change Master Direct...\n",
       "    instrument_vocabulary:                   NASA Global Change Master Direct...\n",
       "    metadata_link:                           http://data.nodc.noaa.gov/cgi-bi...\n",
       "    program:                                 NOAA Climate Data Record (CDR) P...\n",
       "    cdr_program:                             NOAA Climate Data Record Program...\n",
       "    cdr_id:                                  gov.noaa.ncdc:C00983"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xa_region_from_coord_bounds(out, {\"latitude\": (-17, -12), \"longitude\": (-142, -10)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xa_d(xa_d: xa.Dataset | xa.DataArray):\n",
    "    # standardise coordinate names\n",
    "    temp_xa_d = xa_d.rename({\"lat\": \"latitude\", \"lon\": \"longitude\"})\n",
    "    # order variables\n",
    "    return temp_xa_d.sortby(list(temp_xa_d.coords))\n",
    "\n",
    "def xa_region_from_coord_bounds(xa_d, coord_bounds_dict):\n",
    "    slice_dict = {}\n",
    "    for k, v in coord_bounds_dict.items():\n",
    "        slice_dict[k] = slice(min(v), max(v))\n",
    "\n",
    "    return xa_d.sel(slice_dict)\n",
    "\n",
    "def get_links_from_url(url, suffix: str=\".nc\"):\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "    hrefs = soup.find_all(\"a\", href=lambda href: href.endswith(\".nc\"))\n",
    "    links = [\"/\".join((url, hrefs[\"href\"])) for hrefs in hrefs]\n",
    "    return links\n",
    "\n",
    "\n",
    "def fetch_pathfinder_year_urls(year):\n",
    "    url_root = \"https://www.ncei.noaa.gov/data/oceans/pathfinder/Version5.3/L3C/\"\n",
    "    url_root_year_data = \"/\".join((str(url_root), str(year), \"data\"))\n",
    "    return get_links_from_url(url_root_year_data, \".nc\")\n",
    "\n",
    "\n",
    "def download_save_url_file_to_path(url, save_path):\n",
    "    r = requests.get(url)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "def download_and_sample_pathfinder(download_dest_dir, years: list[int], coord_bounds_dict):\n",
    "    for year in years:\n",
    "        # scrape filepaths from url\n",
    "        nc_urls = fetch_pathfinder_year_urls(year)\n",
    "\n",
    "        for url in tqdm(nc_urls, desc = f\"Processing urls for {year}\"):\n",
    "            save_path = Path(download_dest_dir) / Path(url).name\n",
    "            # download to specified path\n",
    "            # download_save_url_file_to_path(url, save_path)\n",
    "            check_exists_download_url(save_path, url)\n",
    "            # open file and extract region\n",
    "            xa_d = xa.open_dataset(save_path, chunks={\"time\": 100, \"latitude\": 10, \"longitude\": 10})\n",
    "            xa_d_subregion = xa_region_from_coord_bounds(process_xa_d(xa_d), coord_bounds_dict)\n",
    "            # save relevant area to .nc with same filepath (overwrite current file to save space)\n",
    "            # TODO: overcome file permissions\n",
    "            xa_d_subregion.to_netcdf(str(save_path))\n",
    "    print(f\"All urls downloaded and limited in extent: {str(coord_bounds_dict)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "\n",
    "def download_url(url, output_path, loading_bar: bool = True) -> None:\n",
    "    print(\"\\n\")\n",
    "    with DownloadProgressBar(\n",
    "        unit=\"B\", unit_scale=True, miniters=1, desc=url.split(\"/\")[-1]\n",
    "    ) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "    print(f\"Download to {output_path} complete.\")\n",
    "\n",
    "\n",
    "def check_exists_download_url(\n",
    "    filepath: Path | str, url: str, loading_bar: bool = True\n",
    ") -> None:\n",
    "    \"\"\"Download a file from a URL to a given filepath, with the option to display a loading bar.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        filepath (Path | str): future path at which the downloaded file will be stored\n",
    "        url (str): URL from which to download the file\n",
    "        loading_bar (bool, optional): Whether to display a loading bar to show download progress. Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    # if not downloaded\n",
    "    if not Path(filepath).is_file():\n",
    "        # download with loading bar\n",
    "        if loading_bar:\n",
    "            download_url(url, str(filepath))\n",
    "        # choose to download without loading bar\n",
    "        else:\n",
    "            urllib.request.urlretrieve(url, filename=filepath)\n",
    "    # if already downloaded\n",
    "    else:\n",
    "        print(f\"Already exists: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing urls for 1993:   0%|          | 0/730 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19930101022011-NCEI-L3C_GHRSST-SSTskin-AVHRR_Pathfinder-PFV5.3_NOAA11_G_1993001_night-v02.0-fv01.0.nc: 38.5MB [00:02, 13.1MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download to lustre_scratch/datasets/pathfinder_sst/19930101022011-NCEI-L3C_GHRSST-SSTskin-AVHRR_Pathfinder-PFV5.3_NOAA11_G_1993001_night-v02.0-fv01.0.nc complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing urls for 1993:   0%|          | 0/730 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/jovyan/lustre_scratch/datasets/pathfinder_sst/19930101022011-NCEI-L3C_GHRSST-SSTskin-AVHRR_Pathfinder-PFV5.3_NOAA11_G_1993001_night-v02.0-fv01.0.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/site-packages/xarray/backends/file_manager.py:210\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_key]\n\u001b[1;32m    211\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[key]\n\u001b[1;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/home/jovyan/lustre_scratch/datasets/pathfinder_sst/19930101022011-NCEI-L3C_GHRSST-SSTskin-AVHRR_Pathfinder-PFV5.3_NOAA11_G_1993001_night-v02.0-fv01.0.nc',), 'a', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '6e1b5d32-c85e-4c7d-9eba-1c199d0d6812']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m download_and_sample_pathfinder(\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mlustre_scratch/datasets/pathfinder_sst\u001b[39;49m\u001b[39m\"\u001b[39;49m, [\u001b[39m1993\u001b[39;49m], {\u001b[39m\"\u001b[39;49m\u001b[39mlatitude\u001b[39;49m\u001b[39m\"\u001b[39;49m: (\u001b[39m-\u001b[39;49m\u001b[39m17\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m12\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mlongitude\u001b[39;49m\u001b[39m\"\u001b[39;49m: (\u001b[39m-\u001b[39;49m\u001b[39m142\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m10\u001b[39;49m)}\n\u001b[1;32m      3\u001b[0m )\n",
      "Cell \u001b[0;32mIn[86], line 47\u001b[0m, in \u001b[0;36mdownload_and_sample_pathfinder\u001b[0;34m(download_dest_dir, years, coord_bounds_dict)\u001b[0m\n\u001b[1;32m     45\u001b[0m         xa_d_subregion \u001b[39m=\u001b[39m xa_region_from_coord_bounds(process_xa_d(xa_d), coord_bounds_dict)\n\u001b[1;32m     46\u001b[0m         \u001b[39m# save relevant area to .nc with same filepath (overwrite current file to save space)\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m         xa_d_subregion\u001b[39m.\u001b[39;49mto_netcdf(\u001b[39mstr\u001b[39;49m(save_path))\n\u001b[1;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAll urls downloaded and limited in extent: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(coord_bounds_dict)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/site-packages/xarray/core/dataset.py:1946\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1943\u001b[0m     encoding \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1944\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mxarray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 1946\u001b[0m \u001b[39mreturn\u001b[39;00m to_netcdf(  \u001b[39m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   1947\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1948\u001b[0m     path,\n\u001b[1;32m   1949\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   1950\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m   1951\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m   1952\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m   1953\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1954\u001b[0m     unlimited_dims\u001b[39m=\u001b[39;49munlimited_dims,\n\u001b[1;32m   1955\u001b[0m     compute\u001b[39m=\u001b[39;49mcompute,\n\u001b[1;32m   1956\u001b[0m     multifile\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1957\u001b[0m     invalid_netcdf\u001b[39m=\u001b[39;49minvalid_netcdf,\n\u001b[1;32m   1958\u001b[0m )\n",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/site-packages/xarray/backends/api.py:1255\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1252\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1253\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munrecognized option \u001b[39m\u001b[39m'\u001b[39m\u001b[39minvalid_netcdf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for engine \u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1254\u001b[0m         )\n\u001b[0;32m-> 1255\u001b[0m store \u001b[39m=\u001b[39m store_open(target, mode, \u001b[39mformat\u001b[39;49m, group, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1257\u001b[0m \u001b[39mif\u001b[39;00m unlimited_dims \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1258\u001b[0m     unlimited_dims \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mencoding\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39munlimited_dims\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:389\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    383\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    384\u001b[0m     clobber\u001b[39m=\u001b[39mclobber, diskless\u001b[39m=\u001b[39mdiskless, persist\u001b[39m=\u001b[39mpersist, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m\n\u001b[1;32m    385\u001b[0m )\n\u001b[1;32m    386\u001b[0m manager \u001b[39m=\u001b[39m CachingFileManager(\n\u001b[1;32m    387\u001b[0m     netCDF4\u001b[39m.\u001b[39mDataset, filename, mode\u001b[39m=\u001b[39mmode, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    388\u001b[0m )\n\u001b[0;32m--> 389\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(manager, group\u001b[39m=\u001b[39;49mgroup, mode\u001b[39m=\u001b[39;49mmode, lock\u001b[39m=\u001b[39;49mlock, autoclose\u001b[39m=\u001b[39;49mautoclose)\n",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:336\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group \u001b[39m=\u001b[39m group\n\u001b[1;32m    335\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m--> 336\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mds\u001b[39m.\u001b[39mdata_model\n\u001b[1;32m    337\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds\u001b[39m.\u001b[39mfilepath()\n\u001b[1;32m    338\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_remote \u001b[39m=\u001b[39m is_remote_uri(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:398\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    397\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mds\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire()\n",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:392\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_acquire\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 392\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager\u001b[39m.\u001b[39macquire_context(needs_lock) \u001b[39mas\u001b[39;00m root:\n\u001b[1;32m    393\u001b[0m         ds \u001b[39m=\u001b[39m _nc4_require_group(root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode)\n\u001b[1;32m    394\u001b[0m     \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/site-packages/xarray/backends/file_manager.py:198\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39m@contextlib\u001b[39m\u001b[39m.\u001b[39mcontextmanager\n\u001b[1;32m    196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macquire_context\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    197\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     file, cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire_with_cache_info(needs_lock)\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m         \u001b[39myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/lustre_scratch/conda-envs/coralshift/lib/python3.10/site-packages/xarray/backends/file_manager.py:216\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    214\u001b[0m     kwargs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    215\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode\n\u001b[0;32m--> 216\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_opener(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    218\u001b[0m     \u001b[39m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2449\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2012\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/jovyan/lustre_scratch/datasets/pathfinder_sst/19930101022011-NCEI-L3C_GHRSST-SSTskin-AVHRR_Pathfinder-PFV5.3_NOAA11_G_1993001_night-v02.0-fv01.0.nc'"
     ]
    }
   ],
   "source": [
    "download_and_sample_pathfinder(\n",
    "    \"lustre_scratch/datasets/pathfinder_sst\", [1993], {\"latitude\": (-17, -12), \"longitude\": (-142, -10)}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_man = data_structure.MyDatasets()\n",
    "ds_man.set_location(location)\n",
    "\n",
    "noaa_features = ['mlotst', 'bottomT', 'uo', 'so', 'zos', 'thetao', 'vo']\n",
    "\n",
    "# TODO: transparency in preprocessing to get to this (probably split into separate gt datarray)\n",
    "ds_man.add_dataset(\n",
    "    \"monthly_climate_1_12\", xa.open_dataset(\n",
    "        ds_man.get_location() / \"global_ocean_reanalysis/monthly_means/coral_climate_1_12.nc\")\n",
    ")\n",
    "\n",
    "ds_man.add_dataset(\n",
    "    \"monthly_climate_features\", ds_man.get_dataset(\"monthly_climate_1_12\")[noaa_features]\n",
    ")\n",
    "\n",
    "# ds_man.add_dataset(\n",
    "#     \"monthly_climate_1_12_X_y_np\", spatial_data.filter_out_nans(\n",
    "#         spatial_data.xa_ds_to_3d_numpy(ds_man.get_dataset(\"monthly_climate_1_12\")), \n",
    "#         np.array(ds_man.get_dataset(\"monthly_climate_1_12\")[\"coral_algae_1-12_degree\"].isel(time=-1)).reshape(-1, 1))\n",
    "# )\n",
    "ds_man.add_datasets(\n",
    "    [\"monthly_climate_1_12_X\", \"monthly_climate_1_12_y\"], \n",
    "        spatial_data.process_xa_ds_for_ml(ds_man.get_dataset(\"monthly_climate_1_12\"), \n",
    "        feature_vars=noaa_features, gt_var=\"coral_algae_1-12_degree\")\n",
    ")\n",
    "\n",
    "# TODO: handle depth\n",
    "ds_man.add_dataset(\n",
    "    \"daily_climate_1_12\", spatial_data.generate_and_add_gt_to_xa_d(xa.open_dataset(\n",
    "        Path(ds_man.get_location() / \"global_ocean_reanalysis/daily_means/dailies_combined.nc\")).isel(depth=0),\n",
    "        ds_man.get_dataset(\"monthly_climate_1_12\")[\"coral_algae_1-12_degree\"])\n",
    ")\n",
    "\n",
    "# TODO: streamline checking and saving process\n",
    "daily_climate_1_12_X_file_path = ds_man.get_location() / \"global_ocean_reanalysis/daily_means/daily_climate_1_12_X.npy\"\n",
    "# if daily_climate_1_12_X numpy array doesn't exist, generate and save\n",
    "if not file_ops.check_file_exists(filepath = daily_climate_1_12_X_file_path):\n",
    "    daily_climate_1_12_X = spatial_data.process_xa_ds_for_ml(ds_man.get_dataset(\"daily_climate_1_12\"),\n",
    "        feature_vars = noaa_features)\n",
    "    np.save(daily_climate_1_12_X_file_path, daily_climate_1_12_X) \n",
    "    ds_man.add_dataset(\"daily_climate_1_12_X\", np.load(daily_climate_1_12_X_file_path))\n",
    "else:\n",
    "    ds_man.add_dataset(\"daily_climate_1_12_X\", np.load(daily_climate_1_12_X_file_path))\n",
    "\n",
    "daily_climate_1_12_padded_1_file_path = ds_man.get_location() / \"global_ocean_reanalysis/daily_means/daily_climate_1_12_padded_1.nc\"\n",
    "# if daily_climate_1_12_padded_1 .nc file doesn't exist, generate and save\n",
    "if not file_ops.check_file_exists(filepath = daily_climate_1_12_padded_1_file_path):\n",
    "    daily_climate_1_12_padded_1 = spatial_data.spatially_buffer_timeseries(\n",
    "        ds_man.get_dataset(\"daily_climate_1_12\"), buffer_size=1, exclude_vars = [\"spatial_ref\", \"coral_algae_gt\"])\n",
    "    daily_climate_1_12_padded_1.to_netcdf(filepath = daily_climate_1_12_padded_1_file_path)\n",
    "    ds_man.add_dataset(\"daily_climate_1_12_padded_1\", xa.open_dataset(daily_climate_1_12_padded_1_file_path))\n",
    "else:\n",
    "    ds_man.add_dataset(\"daily_climate_1_12_padded_1\", xa.open_dataset(daily_climate_1_12_padded_1_file_path))\n",
    "\n",
    "# add in ground truth to padded\n",
    "ds_man.add_dataset(\n",
    "    \"daily_climate_1_12_padded_1_gt\", spatial_data.generate_and_add_gt_to_xa_d(\n",
    "        ds_man.get_dataset(\"daily_climate_1_12_padded_1\"),\n",
    "        ds_man.get_dataset(\"monthly_climate_1_12\")[\"coral_algae_1-12_degree\"])\n",
    ")\n",
    "\n",
    "ds_man.add_dataset(\n",
    "    \"bathymetry_A\", rio.open_rasterio(\n",
    "        rasterio.open(ds_man.get_location() / \"bathymetry/GBR_30m/Great_Barrier_Reef_A_2020_30m_MSL_cog.tif\"),\n",
    "        ).rename(\"bathymetry_A\").rename({\"x\": \"longitude\", \"y\": \"latitude\"})\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU function definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_coral_climate_1_12_features = ds_man.get_dataset(\"monthly_climate_features\")\n",
    "xa_coral_climate_1_12 = ds_man.get_dataset(\"monthly_climate_1_12\")\n",
    "\n",
    "xa_coral_climate_1_12_working = xa_coral_climate_1_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_Xs_onehot, all_lat_lon_dict_onehot = sample_spatial_batch(xa_coral_climate_1_12, lat_lon_starts=(-8,140), coord_range=(-20,13))\n",
    "# all_Xs_onehot, all_lat_lon_dict_onehot = subsample_to_array(xa_coral_climate_1_12, lat_lon_starts=(-8,140), coord_range=((-20,13)))\n",
    "# all_Xs_onehot = naive_X_nan_replacement(all_Xs_onehot)\n",
    "# all_ys_onehot, _ = subsample_to_array(xa_coral_climate_1_12, lat_lon_starts=(-8,140), coord_range=(-20,13), variables = [\"coral_algae_1-12_degree\"])\n",
    "# all_ys_onehot = naive_y_nan_replacement(all_ys_onehot)\n",
    "# all_ys_onehot = all_ys_onehot[:,:,0]\n",
    "\n",
    "train_onehot_Xs, train_onehot_ys, train_onehot_subsample, train_onehot_lat_lons_vals_dict = generate_patch(xa_ds=xa_coral_climate_1_12, lat_lon_starts=(-10,142), coord_range=(-6,6), onehot=False)\n",
    "test_onehot_Xs, test_onehot_ys, test_onehot_subsample, test_onehot_lat_lons_vals_dict = generate_patch(xa_ds=xa_coral_climate_1_12, lat_lon_starts=(-16,148), coord_range=(-6,6))\n",
    "\n",
    "print(\"train_onehot_Xs shape: \", train_onehot_Xs.shape)\n",
    "print(\"train_onehot_ys shape: \", train_onehot_ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bathymetry\n",
    "bath_A = ds_man.get_dataset(\"bathymetry_A\")\n",
    "bath_A\n",
    "\n",
    "# 1 km. Struggles displaying/processing 100m, but have yet to try saving to this/inferring\n",
    "target_resolution = 1000\n",
    "_,_,av_degrees = spatial_data.distance_to_degrees(target_resolution)\n",
    "bath_A_1km = spatial_data.upsample_xarray_to_target(bath_A, av_degrees)\n",
    "# im = bath_A_1km.plot(ax=ax)\n",
    "\n",
    "spatial_plots.plot_DEM(bath_A_1km, f\" DEM upsampled to {target_resolution} meters\", vmin=-100, vmax=0)\n",
    "# spatial_plots.format_spatial_plot(im, fig, ax, f\"Upsampled to {target_resolution} degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chunks_with_percentage(\n",
    "    array: np.ndarray,\n",
    "    range_min: float,\n",
    "    range_max: float,\n",
    "    chunk_size: int,\n",
    "    threshold_percent: float,\n",
    "    preprocess: bool = True\n",
    ") -> list[tuple[float, float]]:\n",
    "    \"\"\"Find chunks in the array that contain a certain threshold percentage of pixel values within a specified range.\n",
    "\n",
    "    Parameters\n",
    "        array (ndarray): Input array.\n",
    "        range_min (float): Minimum value for the range.\n",
    "        range_max (float): Maximum value for the range.\n",
    "        chunk_size (int): Size of the chunks in rows and columns.\n",
    "        threshold_percent (float): Threshold percentage for chunk selection.\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[tuple[float, float]], list[float]]: List of chunk coordinates that meet the threshold percentage\n",
    "            criteria and list of percentage of grid cells meeting criteria.\n",
    "    \"\"\"\n",
    "    if preprocess:\n",
    "        array = preprocess_array(array, range_min, range_max)\n",
    "\n",
    "    # to make chunk_size behave as expected in the face of non-inclusive final indices\n",
    "    chunk_size = chunk_size + 1\n",
    "    rows, cols = array.shape\n",
    "    chunk_rows = np.arange(0, rows - chunk_size, chunk_size)\n",
    "    chunk_cols = np.arange(0, cols - chunk_size, chunk_size)\n",
    "\n",
    "    chunk_coords = []\n",
    "    cell_coverages = []\n",
    "\n",
    "    for start_row in tqdm(chunk_rows, desc=\"Calculating areas within value range\"):\n",
    "        for start_col in chunk_cols:\n",
    "            # Calculate the sub-array within the chunk\n",
    "            sub_array = array[start_row:start_row + chunk_size, start_col:start_col + chunk_size]\n",
    "\n",
    "            # Count the number of values within the range\n",
    "            count = np.sum((sub_array >= range_min) & (sub_array <= range_max))\n",
    "\n",
    "            # Calculate the coverage percentage\n",
    "            cell_coverage = (count / (chunk_size ** 2)) * 100\n",
    "\n",
    "            if cell_coverage >= threshold_percent:\n",
    "                chunk_coords.append(\n",
    "                    (\n",
    "                        (start_row, start_col),\n",
    "                        (start_row + chunk_size - 1, start_col + chunk_size - 1),\n",
    "                    )\n",
    "                )\n",
    "                cell_coverages.append(cell_coverage.item())\n",
    "\n",
    "    return chunk_coords, cell_coverages\n",
    "\n",
    "\n",
    "def preprocess_array(array: np.ndarray, range_min: float, range_max: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess the input array by filtering out values outside the desired range.\n",
    "\n",
    "    Parameters:\n",
    "        array (ndarray): Input array.\n",
    "        range_min (float): Minimum value for the desired range.\n",
    "        range_max (float): Maximum value for the desired range.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Preprocessed array with values filtered within the desired range.\n",
    "    \"\"\"\n",
    "    return np.where(np.logical_and(array >= range_min, array <= range_max), array, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "def nc_chunk_files(\n",
    "    dest_dir_path: Path | str,\n",
    "    xa_ds: xa.Dataset,\n",
    "    chunk_size: int = 20,\n",
    "    threshold_percent: float = 10,\n",
    "    vmin: float = -100,\n",
    "    vmax: float = 0,\n",
    "):\n",
    "    \"\"\"Save chunks of an xarray Dataset to NetCDF files along with accompanying metadata JSON files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dest_dir_path (Path | str): Directory path to save the chunk files.\n",
    "    xa_ds (xa.Dataset): Input xarray Dataset.\n",
    "    chunk_size (int, optional): Size of the chunks (default is 20).\n",
    "    threshold_percent (float, optional): Threshold percentage for chunk coverage (default is 10).\n",
    "    vmin (float, optional): Minimum value for chunk selection (default is -100).\n",
    "    vmax (float, optional): Maximum value for chunk selection (default is 0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    chunk_coord_pairs, coverages = find_chunks_with_percentage(\n",
    "        xa_ds.values, vmin, vmax, chunk_size, threshold_percent\n",
    "    )\n",
    "\n",
    "    for i, coord_pair in tqdm(\n",
    "        enumerate(chunk_coord_pairs),\n",
    "        desc=\"Saving chunks .nc and accompanying metadata .json files\",\n",
    "        total=len(chunk_coord_pairs),\n",
    "    ):\n",
    "        sub_ds = spatial_data.ds_subsample_from_coord(xa_ds, coord_pair)\n",
    "        # generate filename and file_path\n",
    "        filename = \"_\".join(\n",
    "            (\"chunk\", utils.pad_number_with_zeros(number=i, resulting_len=3))\n",
    "        )\n",
    "        file_path = Path(dest_dir_path) / filename\n",
    "        # generate chunk metadata\n",
    "        info_dict = generate_chunk_json(sub_ds, file_path, coord_pair, coverages[i])\n",
    "        # save metadata file\n",
    "        file_ops.save_json(\n",
    "            info_dict, filepath=file_path.with_suffix(\".json\"), verbose=False\n",
    "        )\n",
    "        # save nc file\n",
    "        sub_ds.to_netcdf(path=file_path.with_suffix(\".nc\"))\n",
    "\n",
    "    print(f\".nc chunk files and accompanying metadata written to {str(dest_dir_path)}\")\n",
    "    return chunk_coord_pairs, coverages\n",
    "\n",
    "\n",
    "def add_data_to_chunk(xa_chunk_data, xa_new_data, interp_method: str=\"nearest\", broadcast: bool=True):\n",
    "    # TODO: add in checking about relative resolutions\n",
    "    interped = xa_new_data.interp(\n",
    "        latitude=xa_chunk_data[\"latitude\"], longitude=xa_chunk_data[\"longitude\"], method=interp_method)\n",
    "    # TODO: issue with time broadcasting?\n",
    "    merged_ds = xa.combine_by_coords([xa_chunk_data, interped], coords=['latitude', 'longitude', 'time'], join=\"inner\")\n",
    "    if broadcast:\n",
    "        (merged_ds,) = xa.broadcast(merged_ds)\n",
    "    return merged_ds\n",
    "    # save file\n",
    "\n",
    "\n",
    "def add_data_to_chunks(chunk_dir: Path | str, xa_new_data_area, new_dir_name: str):\n",
    "    # determine chunk_paths folder\n",
    "    chunk_paths = file_ops.return_list_filepaths(chunk_dir, \".nc\", incl_subdirs=False)\n",
    "    # make new folder for writing merged data to\n",
    "    new_dir = file_ops.guarantee_existence(Path(chunk_dir) / new_dir_name)\n",
    "\n",
    "    for p in tqdm(chunk_paths, desc=\"Merging additional data into .nc chunk files\"):\n",
    "        p = Path(p)\n",
    "        chunk_file_name = p.stem\n",
    "        new_chunk_path = new_dir / p.stem\n",
    "        xa_chunk_data = xa.open_dataset(p)\n",
    "        # determine spatial limts TODO: could replace this with reading from metadata (potentially faster)\n",
    "        lat_lims = spatial_data.xarray_coord_limits(xa_chunk_data, \"latitude\") \n",
    "        lon_lims = spatial_data.xarray_coord_limits(xa_chunk_data, \"longitude\")\n",
    "        # TODO: make selection of index order more universal (currently only good for negative lats)\n",
    "        extra_xa_chunk_data = xa_new_data_area.sel({\n",
    "            \"latitude\": slice(lat_lims[0], lat_lims[1]),\n",
    "            \"longitude\": slice(lon_lims[0], lon_lims[1])\n",
    "            })\n",
    "\n",
    "        # determine data to add TODO: change\n",
    "        merged_ds = add_data_to_chunk(xa_chunk_data, extra_xa_chunk_data)\n",
    "        info_dict = generate_chunk_json(merged_ds, new_chunk_path)\n",
    "        file_ops.save_json(info_dict, filepath=new_chunk_path.with_suffix(\".json\"), verbose=False)\n",
    "        merged_ds.to_netcdf(path=new_chunk_path.with_suffix(\".nc\"))\n",
    "    print(f\"Merged chunks written to .nc files at {str(new_dir)}\")\n",
    "\n",
    "def generate_chunk_json(\n",
    "    xa_d: xa.DataArray,\n",
    "    file_path: str | Path,\n",
    "    coord_pair: tuple[int] = None,\n",
    "    coverage: float = None,\n",
    ") -> dict:\n",
    "    \"\"\"Generate metadata JSON dictionary for a chunk of an xarray DataArray.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xa_d (xa.DataArray): Input xarray DataArray.\n",
    "    file_path (str | Path): File path of the chunk.\n",
    "    coord_pair (tuple[int]): Index pair containing the start and end coordinates.\n",
    "    coverage (float): Chunk coverage value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict: Metadata JSON dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: make robust with different dataset/dataarray\n",
    "\n",
    "    # make filename\n",
    "    vars = spatial_data.get_vars_from_ds_or_da(xa_d)\n",
    "    # convert coord indices to absolute coords (TODO: could add spatial functionality for chunking)\n",
    "    lat_lims = spatial_data.xarray_coord_limits(xa_d, \"latitude\")\n",
    "    lon_lims = spatial_data.xarray_coord_limits(xa_d, \"longitude\")\n",
    "    # find resolution\n",
    "    lat_resolution_d, lon_resolution_d = spatial_data.calculate_spatial_resolution(xa_d)\n",
    "    lat_resolution_m, lon_resolution_m = spatial_data.degrees_to_distances(\n",
    "        lat_resolution_d, lon_resolution_d\n",
    "    )\n",
    "\n",
    "\n",
    "    info_dict = {\n",
    "        \"file name\": file_path.stem,\n",
    "        \"file path\": str(file_path),\n",
    "        \"variables\": vars,\n",
    "        \"latitude range\": lat_lims,\n",
    "        \"longitude range\": lon_lims,\n",
    "        \"latitude resolution (degrees)\": lat_resolution_d,\n",
    "        \"longitude resolution (degrees)\": lon_resolution_d,\n",
    "        \"latitude resolution (meters)\": lat_resolution_m,\n",
    "        \"longitude resolution (meters)\": lon_resolution_m,\n",
    "    }\n",
    "\n",
    "    if coord_pair is not None:\n",
    "        # calculate minimum and maximum bathymetries\n",
    "        min_bath, max_bath = xa_d.values.min(), xa_d.values.max()\n",
    "        additional_info = {\n",
    "            \"latitude chunk size\": np.diff((coord_pair[0][0], coord_pair[1][0])).item(),\n",
    "            \"longitude chunk size\": np.diff(\n",
    "                (coord_pair[0][1], coord_pair[1][1])\n",
    "            ).item(),\n",
    "            \"start index pair\": coord_pair[0],\n",
    "            \"end index pair\": coord_pair[1],\n",
    "            \"minimum bathymetry\": min_bath,\n",
    "            \"maximum bathymetry\": max_bath,\n",
    "        }\n",
    "        info_dict.update(additional_info)\n",
    "    if coverage is not None:\n",
    "        additional_info = {\n",
    "            \"cell coverage\": coverage,\n",
    "        }\n",
    "        info_dict.update(additional_info)\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import generic_filter\n",
    "\n",
    "\n",
    "# assign nans to zero\n",
    "def calculate_slopes(array: np.ndarray, buffer_size: int = 3) -> np.ndarray:\n",
    "\n",
    "    def slope_sweeper(values:np.ndarray):\n",
    "        # bathymetry cell of interest\n",
    "        central_value = values[len(values) // 2]\n",
    "        # replace any nan values (outside array or coast) with bathymetry cell of interest (approximation)\n",
    "        values[np.isnan(values)] = central_value\n",
    "        # remove the duplicated central value\n",
    "        # contig_vals = remove_single_instance(values, central_value)\n",
    "        contig_vals = values[1::2]  # TODO: generalise for non-3kernel sizes\n",
    "        diff = abs(((np.sum(contig_vals)) - central_value * len(contig_vals))/len(contig_vals))\n",
    "        return diff\n",
    "        \n",
    "    sloped_array = generic_filter(array, slope_sweeper, size=buffer_size, mode=\"constant\", cval=np.nan)\n",
    "\n",
    "    return sloped_array\n",
    "\n",
    "\n",
    "def calculate_cell_slopes(bath: xa.DataArray, buffer_size: int = 3):\n",
    "    slopes = xa.apply_ufunc(\n",
    "        calculate_slopes,\n",
    "        bath,\n",
    "        input_core_dims=[[]],\n",
    "        output_core_dims=[[]],\n",
    "        kwargs={\"buffer_size\": buffer_size},\n",
    "    )\n",
    "    return slopes\n",
    "\n",
    "\n",
    "def remove_single_instance(array, value):\n",
    "    index = np.where(array == value)[0][0]\n",
    "    return np.concatenate((array[:index], array[index+1:]))\n",
    "\n",
    "# slopes = calculate_cell_slopes(test_array, buffer_size=3)\n",
    "slopes = calculate_cell_slopes(bath_A_1km.values[0,:,:], buffer_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.arange(0,16,1).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots()\n",
    "im = a.imshow(bath_A_1km.values[0,:,:], vmin=-100, vmax=0)\n",
    "f.colorbar(im, ax=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "slopes = gaussian_gradient_magnitude(bath_A_1km.values[0,:,:], sigma=1)\n",
    "\n",
    "row_start, row_end = 200, 300\n",
    "col_start, col_end = 180, 260\n",
    "\n",
    "bath_vals = bath_A_1km.values[0, row_start:row_end, col_start:col_end]\n",
    "slope_vals = slopes[row_start:row_end, col_start:col_end]\n",
    "# bath_vals[bath_vals < -500] = -500\n",
    "\n",
    "if bath_vals.max() < 0:\n",
    "    divnorm_bath = colors.TwoSlopeNorm(vmin=bath_vals.min(), vcenter=0, vmax=0.1)\n",
    "else:\n",
    "    divnorm_bath = colors.TwoSlopeNorm(vmin=bath_vals.min(), vcenter=0., vmax=bath_vals.max())\n",
    "# if slope_vals.max() < 0:\n",
    "#     divnorm_slope = colors.TwoSlopeNorm(vmin=slope_vals.min(), vcenter=slope_vals.max(), vmax=0)\n",
    "# else:\n",
    "#     divnorm_slope = colors.TwoSlopeNorm(vmin=slope_vals.min(), vcenter=0., vmax=0.1)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(1,2, figsize=[10,5])\n",
    "bath_im = ax[0].imshow(bath_vals, cmap=\"RdPu_r\", vmin=bath_vals.min(), vmax=bath_vals.max()\n",
    "    # norm=divnorm_bath\n",
    "    )\n",
    "ax[0].set_title(\"bathymetry\")\n",
    "f.colorbar(bath_im, ax=ax[0])\n",
    "\n",
    "slope_im = ax[1].imshow(slope_vals, cmap=\"RdPu\",\n",
    "    # norm=divnorm_slope\n",
    "    )\n",
    "ax[1].set_title(\"absolute slope value\")\n",
    "f.colorbar(slope_im, ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_gradient_magnitude\n",
    "\n",
    "plt.imshow(gaussian_gradient_magnitude(bath_A_1km.values[0,:,:], sigma=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 100x100 array of zeros\n",
    "arr = np.zeros((5, 5))\n",
    "\n",
    "# Set the central square of size 10x10 to 100\n",
    "start = 1\n",
    "end = 4\n",
    "arr[start:end, start:end] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes = calculate_cell_slopes(arr, buffer_size=3)\n",
    "\n",
    "f, ax = plt.subplots(1,2, figsize=[10,5])\n",
    "bath = ax[0].imshow(arr)\n",
    "ax[0].set_title(\"bathymetry\")\n",
    "f.colorbar(bath, ax=ax[0])\n",
    "\n",
    "\n",
    "slope = ax[1].imshow(slopes)\n",
    "ax[1].set_title(\"slopes\")\n",
    "f.colorbar(slope, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_A_1km.values[0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.array(np.arange(0,81,1).reshape(9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_climate_1_12_padded_1 = ds_man.get_dataset(\"daily_climate_1_12_padded_1\")\n",
    "# daily_climate_1_12_padded_1_gt = ds_man.get_dataset(\"daily_climate_1_12_padded_1_gt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_climate = xa.open_dataset(\"lustre_scratch/datasets/global_ocean_reanalysis/daily_means/daily_climate_1_12_padded_1.nc\", chunks={\"time\":100})\n",
    "dask_climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_gt = spatial_data.generate_and_add_gt_to_xa_d(dask_climate,ds_man.get_dataset(\"monthly_climate_1_12\")[\"coral_algae_1-12_degree\"])\n",
    "dask_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_all = add_data_to_chunk(bath_A_1km, dask_gt).transpose(\"latitude\", \"longitude\", ...)\n",
    "dask_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = xa.open_dataset(\"lustre_scratch/datasets/test/padded_climate_chunks/chunk_039.nc\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=[13,5])\n",
    "dask_all[\"bathymetry_A\"].isel(time=0).plot(ax=ax, cmap=\"Pastel2\")\n",
    "dask_all[\"coral_algae_gt\"].isel(time=0).plot(ax=ax, cmap=\"binary\", alpha=0.4)\n",
    "dask_all[\"bottomT\"].isel(time=0).plot(ax=ax, alpha=0.4)\n",
    "\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = xbatcher.BatchGenerator(dask_all, \n",
    "    input_dims={\"latitude\": 128, \"longitude\": 128}, \n",
    "    input_overlap={\"latitude\": 4, \"longitude\": 4},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch5 = batches[5]\n",
    "# len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch5.to_netcdf(\"lustre_scratch/datasets/test/batches/test_batch.ncf\")\n",
    "from dask.distributed import Client\n",
    "client = Client('dask-scheduler-address:8786')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spatial chunk from dask xarray\n",
    "chunk = dask_all.isel(latitude=slice(0,128),longitude=slice(0,128)).compute()\n",
    "# process for ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = xa.open_dataset(\"lustre_scratch/datasets/test/padded_climate_chunks/chunk_039.nc\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=[13,5])\n",
    "chunk[\"coral_algae_gt\"].isel(time=0).plot(ax=ax, cmap=\"binary\", alpha=1)\n",
    "chunk[\"bathymetry_A\"].isel(time=0).plot(ax=ax, cmap=\"Pastel2\", alpha=0.3)\n",
    "\n",
    "chunk[\"bottomT\"].isel(time=0).plot(ax=ax, alpha=0.2)\n",
    "\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lat_lims, test_lon_lims = spatial_data.xarray_coord_limits(test,\"latitude\"), spatial_data.xarray_coord_limits(test,\"longitude\")\n",
    "daily_climate_1_12_padded_1_gt[\"coral_algae_gt\"].isel(time=0).sel(\n",
    "    latitude=slice(test_lat_lims[0],test_lat_lims[1]), longitude=slice(test_lon_lims[0],test_lon_lims[1])\n",
    "    ).plot(cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"coral_algae_gt\"].isel(time=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_climate_1_12_padded_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = xa.open_dataset(\"lustre_scratch/datasets/test/padded_climate_chunks/chunk_000.nc\")\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"coral_algae_gt\"].isel(time=0).plot()\n",
    "# merged[\"bathymetry_A\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_coord_pairs, _ = nc_chunk_files(\"lustre_scratch/datasets/test\", bath_A_1km.isel(band=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = bath_A_1km\n",
    "_, ax, _ = spatial_plots.plot_DEM(da, \"Bathymetry showing chunked data, colorcoded by number\", orient_colorbar=\"vertical\")\n",
    "\n",
    "cmap = plt.cm.get_cmap('viridis')\n",
    "for i, coord in enumerate(chunk_coord_pairs):\n",
    "    color = cmap(i / len(chunk_coord_pairs))\n",
    "\n",
    "    xy = spatial_data.index_to_coord(da, coord[0])\n",
    "    height, width = spatial_data.delta_index_to_distance(da, coord[1], coord[0])\n",
    "    rect = patches.Rectangle(xy, width, height, linewidth=1, edgecolor='r', facecolor=color, alpha=0.8)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "cbar2 = plt.colorbar(plt.cm.ScalarMappable(cmap=cmap), ax=ax, orientation='vertical', label=\"chunk number\")\n",
    "cbar2.set_ticklabels(np.arange(0, len(chunk_coord_pairs), 50))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_bath = bath_A_1km.sel({\n",
    "    \"latitude\": slice(lat_lims[1], lat_lims[0]),\n",
    "    \"longitude\": slice(lon_lims[0], lon_lims[1])\n",
    "})\n",
    "restricted_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt downsampling climate in each square\n",
    "test_chunk = xa.open_dataset(\"lustre_scratch/datasets/test/chunk_000.nc\")\n",
    "\n",
    "lat_lims = spatial_data.xarray_coord_limits(test_chunk, \"latitude\")\n",
    "lon_lims = spatial_data.xarray_coord_limits(test_chunk, \"longitude\") \n",
    "\n",
    "bath_res_climate_test_chunk = test_chunk.interp_like(restricted_bath, method=\"nearest\")\n",
    "bath_res_climate_test_chunk\n",
    "# save as individual nc file\n",
    "# set up tf dataloader: load each nc file and take batches from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_res_climate_test_chunk[\"bathymetry_A\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interped = test_chunk.interp(latitude=restricted_bath[\"latitude\"], longitude=restricted_bath[\"longitude\"], method=\"nearest\")\n",
    "interped[\"bathymetry_A\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the ds_9km dataset to match the coordinates of restricted_bath\n",
    "ds_9km_reindexed = test_chunk.reindex(latitude=restricted_bath.latitude, longitude=restricted_bath.longitude, method=\"nearest\")\n",
    "\n",
    "# Repeat the values of ds_9km for each 30 meter cell\n",
    "# ds_9km_repeated = ds_9km_reindexed.repeat(restricted_bath.dims[\"latitude\"], axis=0).repeat(restricted_bath.dims[\"longitude\"], axis=1)\n",
    "\n",
    "# Expand the dimensions of ds_9km to match the shape of restricted_bath\n",
    "expanded_ds_9km = ds_9km_reindexed.expand_dims(latitude=restricted_bath.dims[\"latitude\"], longitude=restricted_bath.dims[\"longitude\"])\n",
    "\n",
    "# Repeat the values of ds_9km for each 30 meter cell using broadcasting\n",
    "ds_9km_repeated = expanded_ds_9km.broadcast_like(restricted_bath)\n",
    "\n",
    "# Combine the datasets into a new dataset\n",
    "combined_ds = xr.concat([restricted_bath, ds_9km_repeated], dim=\"variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_1_12_degree = spatial_data.upsample_xarray_to_target(bath_A, 1/12)\n",
    "\n",
    "bath_1_12_degree.values[0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_index_extreme_values(bath_1_12_degree.sel(latitude=slice(-12,-15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_1_12_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_climate.sel(latitude=slice(-10,-17.05), longitude=slice(141.95,147.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_band_bath = bath_1_12_degree.isel(band=0)\n",
    "\n",
    "# downsample climate data to 1km\n",
    "monthly_climate = ds_man.get_dataset(\"monthly_climate_1_12\")\n",
    "\n",
    "# get limits of bathymetry\n",
    "lat_lims = spatial_data.xarray_coord_limits(bath_1_12_degree, \"latitude\")\n",
    "lon_lims = spatial_data.xarray_coord_limits(bath_1_12_degree, \"longitude\")\n",
    "\n",
    "restricted_monthly_climate = monthly_climate.sel(latitude=slice(-10,-17), longitude=slice(142,147))\n",
    "\n",
    "\n",
    "# padded_restricted_monthly_climate = spatial_data.buffer_nans(restricted_monthly_climate, size=1\n",
    "km_monthly = restricted_monthly_climate.interp_like(bath_1_12_degree, method=\"linear\")\n",
    "\n",
    "coral_climate_1km = xa.combine_by_coords([km_monthly.drop(\"spatial_ref\"),no_band_bath], coords=[\"time\", \"latitude\", \"longitude\"])\n",
    "(coral_climate_1km,) = xa.broadcast(coral_climate_1km)\n",
    "coral_climate_1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_monthly_climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (13,) + inhomogeneous part.\n",
    "\n",
    "# train_comb_Xs, train_comb_ys, train_comb_subsample, train_comb_lat_lons_vals_dict = generate_patch(xa_ds=coral_climate_1km, lat_lon_starts=(-10,142), coord_range=(-6,6))\n",
    "# test_comb_Xs, test_comb_ys, test_comb_subsample, test_comb_lat_lons_vals_dict = generate_patch(xa_ds=coral_climate_1km, lat_lon_starts=(-16,148), coord_range=(-6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"all_Xs_onehot shape: \", all_Xs_onehot.shape)\n",
    "print(\"all_ys_onehot shape: \", all_ys_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: normalise along variable axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Xs, all_lat_lon_dict = sample_spatial_batch(xa_coral_climate_1_12, lat_lon_starts=(-8,140), coord_range=(-20,13))\n",
    "all_Xs, all_lat_lon_dict = subsample_to_array(xa_coral_climate_1_12, lat_lon_starts=(-8,140), coord_range=((-20,13)))\n",
    "all_Xs = naive_X_nan_replacement(all_Xs)\n",
    "all_ys, _ = subsample_to_array(xa_coral_climate_1_12, lat_lon_starts=(-10,142), coord_range=(-7,5), variables = [\"coral_algae_1-12_degree\"])\n",
    "all_ys = naive_y_nan_replacement(all_ys)\n",
    "all_ys = all_ys[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Xs shape: \", Xs.shape)\n",
    "print(\"ys shape: \", ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, ys, all_subsample, all_lat_lons_vals_dict = generate_patch(xa_coral_climate_1_12, lat_lon_starts=(-10,142), coord_range=(-7,5))\n",
    "patch1_Xs, patch1_ys, patch1_subsample, patch1_lat_lons_vals_dict = generate_patch(xa_coral_climate_1_12, (-10,142), (-7,5))\n",
    "patch2_Xs, patch2_ys, patch2_subsample, patch2_lat_lons_vals_dict = generate_patch(xa_coral_climate_1_12, (-17,147), (-7,5))\n",
    "patch3_Xs, patch3_ys, patch3_subsample, patch3_lat_lons_vals_dict = generate_patch(xa_coral_climate_1_12, (-16,146), (-7,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailies_combined = xa.open_dataset(\"/Volumes/MRes Drive/global_ocean_reanalysis/daily/dailies_combined.nc\").isel(depth=0)\n",
    "monthly = xa.open_dataset(\"/Volumes/MRes Drive/global_ocean_reanalysis/monthly_means/baseline_area/coral_climate_1_12.nc\")\n",
    "coral_gt, lat_lon_A_vals_dict = spatial_data.sample_spatial_batch(\n",
    "       monthly[\"coral_algae_1-12_degree\"], lat_lon_starts=(-10,141.95), coord_range=(-7.01,5.11))\n",
    "\n",
    "dailies_combined[\"coral_algae_1-12_degree\"] = coral_gt.isel(time=0)\n",
    "(dailies_combined,) = xa.broadcast(dailies_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral_gt.isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailies_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailies_combined[\"coral_algae_1-12_degree\"] = coral_gt.isel(time=0)\n",
    "(dailies_combined,) = xa.broadcast(dailies_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailies_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# really slow, even when ds isn't particularly large (5185, 9863, 8): probably due to ds.to_array().values\n",
    "# in xa_d_to_np_array\n",
    "(daily_Xs, daily_ys), daily_subsample, daily_lat_lons_vals_dict = spatial_data.generate_patch(\n",
    "    xa_ds=daily_climate_1_12, lat_lon_starts=(-17,142), coord_range=(7,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Xs shape: \", daily_Xs.shape)\n",
    "print(\"ys shape: \", daily_ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = daily_Xs[:]\n",
    "y_train = daily_ys[:]\n",
    "\n",
    "wandb.init(\n",
    "    project=\"coralshift\",\n",
    "    entity=\"orlando-code\",\n",
    "    settings=wandb.Settings(start_method=\"fork\")\n",
    "    # config={    }\n",
    "    )\n",
    "\n",
    "# initialize optimiser: will need hyperparameter scan for learning rate and others\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "optimizer = tf.keras.optimizers.Adam(3e-4)\n",
    "\n",
    "# X = ds_man.get_dataset(\"monthly_climate_1_12_X_np\")\n",
    "# y = ds_man.get_dataset(\"monthly_climate_1_12_y_np\")\n",
    "# # check that untrained model runs (should output array of non-nan values)\n",
    "# # why values change?\n",
    "# # g_model(X[:32])\n",
    "\n",
    "# X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "#     sub_X, sub_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Gated Recurrent Unit model class in TensorFlow\n",
    "class gru_model(tf.keras.Model):\n",
    "    # initialise class instance to define layers of the model\n",
    "    def __init__(self, rnn_units: list[int], num_layers: int, \n",
    "        # dff: int\n",
    "        ):\n",
    "        \"\"\"Sets up a GRU model architecture with multiple layers and dense layers for mapping the outputs of the GRU \n",
    "        layers to a desired output shape\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rnn_units (list[int]): list containing the number of neurons to use in each layer\n",
    "        num_layers (int): number of layers in GRU model\n",
    "        \"\"\"\n",
    "        super(gru_model, self).__init__()   # initialise GRU model as subclass of tf.keras.Model\n",
    "        # store values for later use\n",
    "        self.num_layers = num_layers    # number of layers in GRU model\n",
    "        self.rnn_units = rnn_units\n",
    "        # self.dff = dff\n",
    "        # define model layers: creating new `tf.keras.layers.GRU` layer for each iteration\n",
    "        self.grus = [tf.keras.layers.GRU(rnn_units[i],  # number (integer) of rnn units/neurons to use in each model layer\n",
    "                                   return_sequences=True,   # return full sequence of outputs for each timestep\n",
    "                                   return_state=True) for i in range(num_layers)] # return last hidden state of RNN at end of sequence\n",
    "        \n",
    "        # dense layers are linear mappings of RNN layer outputs to desired output shape\n",
    "        # self.w1 = tf.keras.layers.Dense(dff) # 10 units\n",
    "        self.w1 = tf.keras.layers.Dense(10) # 10 units\n",
    "\n",
    "        self.w2 = tf.keras.layers.Dense(1)  # 1 unit (dimension 1 required before final sigmoid function)\n",
    "        # self.A = tf.keras.layers.Dense(30)\n",
    "        # self.B = tf.keras.layers.Dense(dff)\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs: np.ndarray, training: bool=False):\n",
    "        \"\"\"Processes an input sequence of data through several layers of GRU cells, followed by a couple of\n",
    "        fully-connected dense layers, and outputs the probability of an event happening.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs (np.ndarray): input tensor of shape (batch_size, seq_length, features)\n",
    "            batch_size - defines the size of the sample drawn from datapoints\n",
    "            seq_length - number of timesteps in sequence\n",
    "            features - number of features associated with each datapoint\n",
    "        training (bool, defaults to False): True if model is in training, False if in inference mode\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        target: probability of an event occuring, with shape (batch_size, 1)\n",
    "        \"\"\"\n",
    "        # input shape: (batch_size, seq_length, features)\n",
    "       \n",
    "        assert self.num_layers == len(self.rnn_units)\n",
    "\n",
    "        # check that input tensor has correct shape\n",
    "        if (len(inputs.shape) != 3):\n",
    "            print(f\"Incorrect shape of input tensor. Expected 3D array. Recieved {len(inputs.shape)}D array.\")\n",
    "\n",
    "        # print('input dim ({}, {}, {})'.format(inputs.shape[0], inputs.shape[1], inputs.shape[2]))\n",
    "        # whole_seq, static_input = inputs\n",
    "        whole_seq = inputs\n",
    "\n",
    "\n",
    "        # iteratively passes input tensor to GRU layers, overwritting preceding sequence 'whole_seq'\n",
    "        for layer_num in range(self.num_layers):\n",
    "            whole_seq, final_s = self.grus[layer_num](whole_seq, training=training)\n",
    "\n",
    "        # adding extra layers\n",
    "        # static = self.B(tf.nn.gelu(self.A(static_input)))\n",
    "        # target = self.w1(final_s)  + static # final hidden state of last layer used as input to fully connected dense layers...\n",
    "        target = self.w1(final_s)   # final hidden state of last layer used as input to fully connected dense layers...\n",
    "\n",
    "        target = tf.nn.relu(target) # via ReLU activation function\n",
    "        target = self.w2(target)    # final hidden layer must have dimension 1 \n",
    "        \n",
    "        # obtain a probability value between 0 and 1\n",
    "        target = tf.nn.sigmoid(target)\n",
    "        \n",
    "        return target\n",
    "\n",
    "\n",
    "# initialise GRU model with 500 hidden layers, one GRU unit per layer \n",
    "g_model = gru_model([100], 1) # N.B. [x] is number of hidden layers in GRU network\n",
    "\n",
    "\n",
    "def negative_log_likelihood(y: np.ndarray, y_pred: np.ndarray, class_weights: np.ndarray = None) -> float:\n",
    "    \"\"\"Compute binary cross-entropy loss between ground-truth binary labels and predicted probabilities,\n",
    "    incorporating class weights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y (np.ndarray): true binary labels, where 0 represents the negative class\n",
    "    y_pred (np.ndarray): predicted labels (as probability value between 0 and 1)\n",
    "    class_weights (np.ndarray): weights for each class. If None, no class weights will be applied.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float: negative log likelihood loss computed using binary cross-entropy loss between 'y' and 'y_pred',\n",
    "    incorporating class weights if provided\n",
    "    \"\"\"\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()  \n",
    "\n",
    "    if class_weights is not None:\n",
    "        sample_weights = tf.gather(class_weights, np.asarray(y,dtype=np.int32))\n",
    "        return bce(y, y_pred, sample_weight=sample_weights)\n",
    "\n",
    "    return bce(y, y_pred)\n",
    "\n",
    "\n",
    "def training_batches(X: np.ndarray, y: np.ndarray, batch_num: int, batch_size: int=32):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = (batch_num + 1) * batch_size\n",
    "\n",
    "    X_batch = X[start_idx:end_idx]\n",
    "    y_batch = y[start_idx:end_idx]\n",
    "    \n",
    "    return X_batch, y_batch\n",
    "\n",
    "# https://stackoverflow.com/questions/52357542/attributeerror-tensor-object-has-no-attribute-numpy\n",
    "# should aim to delete the following to speed up training: but can't figure out a way to make wandb reporting work\n",
    "# without it\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "def build_graph():\n",
    "    \n",
    "    # compile function as graph using tf's autograph feature: leads to faster execution times, at expense of limitations\n",
    "    # to Python objects/certain control flow structures (somewhat relaxed by experimental_relax_shapes)\n",
    "    @tf.function(experimental_relax_shapes=True)\n",
    "    def train_step(gru: tf.keras.Model, optimizer: tf.keras.optimizers.Optimizer, X: np.ndarray, y: np.ndarray, \n",
    "        training: bool=True, class_weights=class_weights, batch_num:int=None, batch_size: int=None) -> tuple[np.ndarray, float]:\n",
    "        \"\"\"Train model using input `X` and target data `y` by computing gradients of the loss (via \n",
    "        negative_log_likelihood)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y (np.ndarray): true binary labels, where 0 represents the negative class\n",
    "        y_pred (np.ndarray): predicted labels (as probability value between 0 and 1)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float: negative log likelihood loss computed using binary cross-entropy loss between 'y' and 'y_pred'\n",
    "        \"\"\"\n",
    "        if training:\n",
    "            num_samples = X.shape[0]\n",
    "            num_batches = num_samples // batch_size\n",
    "            # num_batches = batch_num\n",
    "            total_epoch_loss = 0.0\n",
    "            for batch_num in tqdm(range(num_batches), desc=\"batches\", position=0, leave=True):\n",
    "                X_batch, y_batch = training_batches(X, y, batch_num=batch_num, batch_size=batch_size)\n",
    "\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = gru(X_batch, training) \n",
    "                    xent = negative_log_likelihood(y_batch, y_pred, class_weights)\n",
    "                    # y_pred = gru(X, training) # TO DELETE\n",
    "                    # xent = negative_log_likelihood(y, y_pred)\n",
    "                \n",
    "                gradients = tape.gradient(xent, gru.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, gru.trainable_variables))\n",
    "                # print(\"xent\", xent.numpy())\n",
    "                # print(\"total_epoch_loss\", total_epoch_loss)\n",
    "                total_epoch_loss += xent\n",
    "                # learning rate?\n",
    "                wandb.log({\"batch\": batch_num, \"loss\": xent, \"total_epoch_loss\": total_epoch_loss})\n",
    "\n",
    "            average_loss = total_epoch_loss / num_batches\n",
    "            # return predicted output values and total loss value\n",
    "            return y_pred, xent, total_epoch_loss\n",
    "\n",
    "    # set default float type\n",
    "    tf.keras.backend.set_floatx('float32')\n",
    "    # TODO: this isn't assigned... What should it return otherwise?\n",
    "    return train_step\n",
    "\n",
    "\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=np.reshape(y_train,-1))\n",
    "\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    num_epochs = 10\n",
    "    # will update so that subsamples are fed in from which batches are taken: will require recomputation\n",
    "    # of class_weight for each subsample\n",
    "    num_batches = 2\n",
    "    batch_size = 128\n",
    "    tr_step = build_graph()\n",
    "    for epoch in tqdm(range(num_epochs), desc= \" epochs\", position = 0, leave=True):\n",
    "        y_pred, xent, total_epoch_loss = tr_step(\n",
    "            g_model, optimizer, X_train[:], y_train[:], class_weights=class_weights, \n",
    "            batch_size=batch_size, batch_num=num_batches, training=True)\n",
    "        wandb.log({\"epoch\": epoch, \"epoch_loss\": total_epoch_loss})\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "# check (with prints) that wandb is functioning\n",
    "# check against known timeseries task for correct implementation\n",
    "# find timeseries which get bad loss and debug why\n",
    "# log best loss which can be logged: save weights (and do a inference plot with best weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(daily_subsample_Xs, daily_subsample_ys), daily_subsample, daily_subsample_lat_lon_vals_dict = spatial_data.generate_patch(xa_ds=daily_climate_1_12, lat_lon_starts=(-17,144), coord_range=(3,3))\n",
    "\n",
    "# sample, ll_dict = spatial_data.sample_spatial_batch(xa_ds=daily_climate_1_12, lat_lon_starts=(-17,145), coord_range=(-2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[0,1,2,3,4,5]\n",
    "for i in range(0,3):\n",
    "    print(arr[:-i or None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_subsample_Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train/predict\n",
    "# if training:\n",
    "    # assign epoch output to dataset\n",
    "# if testing:\n",
    "# patch1_pred = g_model(patch1_Xs, training=False)\n",
    "# patch2_pred = g_model(patch2_Xs, training=False)\n",
    "# patch3_pred = g_model(patch3_Xs, training=False)\n",
    "pred = g_model(daily_subsample_Xs, training=False)\n",
    "\n",
    "# all_predicted = g_model(all_Xs, training=False)\n",
    "    # assign output predictions to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = spatial_data.reformat_prediction(daily_climate_1_12, daily_subsample, pred, daily_subsample_lat_lon_vals_dict)\n",
    "spatial_plots.plot_var(patch[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_pred_xa_ds_onehot_lim = reformat_prediction(xa_coral_climate_1_12_working, test_onehot_subsample, pred, test_onehot_lat_lons_vals_dict)\n",
    "\n",
    "mask = patch_pred_xa_ds_onehot_lim[\"output\"] > 0.6\n",
    "\n",
    "spatial_plots.plot_var(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_pred_xa_ds_onehot_lim = reformat_prediction(xa_coral_climate_1_12_working, test_onehot_subsample, pred, test_onehot_lat_lons_vals_dict)\n",
    "\n",
    "spatial_plots.plot_var(patch_pred_xa_ds_onehot_lim[\"output\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_Xs_onehot, patch_ys_onehot, patch_subsample_onehot, patch_lat_lons_vals_dict_onehot = generate_patch(xa_coral_climate_1_12, (-10,142), (-7,5))\n",
    "\n",
    "patch_pred_xa_ds_onehot = reformat_prediction(xa_coral_climate_1_12_working, patch_subsample_onehot, pred, patch_lat_lons_vals_dict_onehot)\n",
    "\n",
    "spatial_plots.plot_var(patch_pred_xa_ds_onehot[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(patch1_pred_xa_ds[\"output\"].values,patch2_pred_xa_ds[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch1_pred_xa_ds = reformat_prediction(xa_coral_climate_1_12_working, patch1_subsample, patch1_pred, patch1_lat_lons_vals_dict)\n",
    "# patch2_pred_xa_ds = reformat_prediction(xa_coral_climate_1_12_working, patch2_subsample, patch2_pred, patch2_lat_lons_vals_dict)\n",
    "# patch3_pred_xa_ds = reformat_prediction(xa_coral_climate_1_12_working, patch3_subsample, patch3_pred, patch3_lat_lons_vals_dict)\n",
    "\n",
    "\n",
    "f, a0 = spatial_plots.plot_var_at_time(xa_coral_climate_1_12[\"coral_algae_1-12_degree\"], \"2020-12-16\")\n",
    "# # visualise result\n",
    "# spatial_plots.plot_var(patch1_pred_xa_ds[\"output\"])\n",
    "# spatial_plots.plot_var(patch2_pred_xa_ds[\"output\"])\n",
    "# spatial_plots.plot_var(patch3_pred_xa_ds[\"output\"])\n",
    "\n",
    "# pred_xa_ds[\"coral_algae_1-12_degree\"].isel(time=-1).plot(ax=ax[0])\n",
    "# pred_xa_ds[\"output\"].plot(ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_coral_climate_1_12[\"bottomT\"].isel(time=-1).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding in bathymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample climate data to 1km\n",
    "monthly_climate = ds_man.get_dataset(\"monthly_climate_1_12\")\n",
    "\n",
    "# get limits of bathymetry\n",
    "lat_lims = spatial_data.xarray_coord_limits(coarsened_bath_A, \"latitude\")\n",
    "lon_lims = spatial_data.xarray_coord_limits(coarsened_bath_A, \"longitude\")\n",
    "\n",
    "restricted_monthly_climate = monthly_climate.sel(latitude=slice(-10,-17), longitude=slice(142,147))\n",
    "\n",
    "\n",
    "# padded_restricted_monthly_climate = spatial_data.buffer_nans(restricted_monthly_climate, size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 3\n",
    "exclude_vars = [\"spatial_ref\", \"coral_algae_1-12_degree\", \"siconc\", \"usi\", \"vsi\", \"sithick\"]\n",
    "buffered_ds = spatially_buffer_timeseries(monthly_climate, buffer_size=buffer_size, exclude_vars=exclude_vars)\n",
    "\n",
    "buffered_ds.to_netcdf(\n",
    "    ds_man.get_location() / f\"global_ocean_reanalysis/monthly_means/monthly_climate_{buffer_size}_buffer.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,2, figsize=[10,5])\n",
    "monthly_climate[\"mlotst\"].isel(time=99).plot(ax=a[0], cmap=\"jet\")\n",
    "buffer_attempt[\"mlotst\"].isel(time=99).plot(ax=a[1],cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral_climate_1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_attempt.equals(monthly_climate.isel(time=slice(0,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_attempt.isel(time=1)[\"mlotst\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarsened_bath_A.isel(band=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral_climate_1km[\"bathymetry_A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,2, figsize=[10,5])\n",
    "coral_climate_1km.isel(time=-1)[\"bathymetry_A\"].plot(ax=a[0], vmin=-100, vmax=0)\n",
    "coral_climate_1km.isel(time=-1)[\"mlotst\"].plot(ax=a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt.isel(time=-1)[\"mlotst\"].plot()\n",
    "eg_data = buffer_attempt.isel(time=-1)[\"mlotst\"]\n",
    "\n",
    "spatial_plots.plot_DEM(eg_data, f\" DEM upsampled to {target_resolution} meters\", \n",
    "    landmask=False, vmin=np.nanmin(eg_data.values), vmax=np.nanmax(eg_data.values), cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "\n",
    "# for longitude in array\n",
    "# get \n",
    "sub_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: optionally replace batching with spatial batching"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test GRU functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices())\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/GPU:0\"):\n",
    "    num_epochs = 5\n",
    "    num_batches = 100\n",
    "    tr_step = build_graph()\n",
    "    for epoch in tqdm(range(num_epochs), desc= \" epochs\", position = 0):\n",
    "        y_pred, average_loss = tr_step(g_model, optimizer, X_train[:1000], y_train[:1000], batch_size=32, training=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # for batch in range(num_batches):\n",
    "        #     array, y  = batcher_fun(X, 32, 276 \n",
    "        #     #training = True)# shapes: (batch_s, seq_l, features), (batch_s, 1)\n",
    "        #     )\n",
    "        #     y_pred, xent = tr_step(g_model, optimizer, X[:32], y, training=True)\n",
    "            \n",
    "        #  ## validation set \n",
    "        #  ## test_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative_log_likelihood(y_test,g_model(X_test))\n",
    "y_test=y_test[:1000]\n",
    "y_pred = g_model(X[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made unnecssary due to isel indexing\n",
    "# def pixels_to_coord_diff(xa_ds: xa.Dataset | xa.DataArray, window_dim: int, coord: str) -> list[float, float]:\n",
    "#     return float(window_dim * np.diff(spatial_data.min_max_of_coords(xa_ds, coord)) / len(list(xa_coral_climate_1_12[coord])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample[\"bottomT\"].isel(time=-1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_spatial_batch(xa_coral_climate_1_12,lat_lon_starts=(-16,144), coord_range=(-4,2))[\"coral_algae_1-12_degree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_coral_climate_1_12_working = xa_coral_climate_1_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [lat_lon_vals_dict.items() for key in [\"latitude\", \"longitude\"]]\n",
    "{key: lat_lon_vals_dict[key] for key in [\"latitude\", \"longitude\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_y_nans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(list(subsample.data_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix boolean indexing\n",
    "# # For now, shallowest depth is taken (0.45)\n",
    "# # TODO: process this and export it to new file since takes a while to run\n",
    "# ds_man.add_dataset(\n",
    "#     \"daily_climate_1_12_X_np\", filter_out_nans(\n",
    "#         spatial_data.xa_ds_to_3d_numpy(ds_man.get_dataset(\"daily_climate_1_12\").isel(depth=0)), ds_man.get_dataset(\"daily_climate_1_12_y_np\"))[0]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put this merge into data processing pipeline\n",
    "# merge daily mean files\n",
    "# var_daily_dir = Path(\"lustre_scratch/datasets/global_ocean_reanalysis/daily_means\")\n",
    "# save_combined_dailies_path = Path(\"lustre_scratch/datasets/global_ocean_reanalysis/daily_means/dailies_combined.nc\")\n",
    "# daily_file_paths = file_ops.return_list_filepaths(var_daily_dir, \".nc\")\n",
    "# combined_dailies = xa.open_mfdataset(daily_file_paths)\n",
    "# combined_dailies.to_netcdf(save_combined_dailies_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create 3D array from xarray dataset variables. Shape: (num_samples, num_parameters, sequence_len)\n",
    "# X_with_nans = spatial_data.xa_ds_to_3d_numpy(xa_coral_climate_1_12_features)\n",
    "# print(f'X_with_nans shape (num_samples: {X_with_nans.shape[0]}, total num_parameters (includes nans parameters): {X_with_nans.shape[1]}, sequence_len: {X_with_nans.shape[2]})')\n",
    "\n",
    "# for i, param in enumerate(xa_coral_climate_1_12_features.data_vars):\n",
    "#     print(f\"{i}: {param}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove observations for which there are nan values\n",
    "\n",
    "99% sure these are are just gridcells containing land. Would be a good thing to investigate, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X_with_nans\n",
    "# # problem, probably with sea ice features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter out columns that contain entirely NaN values\n",
    "# col_mask = ~np.all(np.isnan(X), axis=(0,2)) # boolean mask indicating which columns to keep\n",
    "# masked_cols = X[:, col_mask, :] # keep only the columns that don't contain entirely NaN values\n",
    "# print(\"masked_cols shape:\", masked_cols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter out all rows which contain any NaN values\n",
    "# row_mask = ~np.any(np.isnan(masked_cols), axis=1) # boolean mask indicating which rows to keep\n",
    "# masked_cols_rows = masked_cols[row_mask[:,0], :, :] # keep only the rows that don't contain any NaN values\n",
    "# masked_cols_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter out all depths which contain any NaN values\n",
    "# depth_mask = ~np.any(np.isnan(masked_cols_rows), axis=(0,1)) # boolean mask indicating which depths to keep\n",
    "# X = masked_cols_rows[:, :, depth_mask] # keep only the depths that don't contain any NaN values\n",
    "# X = np.swapaxes(X, 1, 2)\n",
    "# print(f\"X shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create target from coral ground truth. Shape: (num_samples, 1)\n",
    "# # TODO: not sure if this is shuffling the values when reshaping\n",
    "# y_with_nans = np.array(xa_coral_climate_1_12[\"coral_algae_1-12_degree\"].sel(\n",
    "#     time=xa_coral_climate_1_12.time[-1])).reshape(-1, 1)\n",
    "# # remove ys with nan values in other variables\n",
    "# y = y_with_nans[row_mask[:,0]]\n",
    "\n",
    "# print(f\"y_with_nans shape: {y_with_nans.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = filter_out_nans(X_with_nans, np.array(xa_coral_climate_1_12[\"coral_algae_1-12_degree\"].isel(time=-1)).reshape(-1, 1))\n",
    "# print(f\"X shape: {X.shape}\")\n",
    "# print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_X = np.moveaxis(np.array(test_array), 2, 1)\n",
    "sub_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mask = ~np.all(np.isnan(test_array), axis=(0,2))\n",
    "sub_X = test_array[:, col_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_coral_climate_1_12_features = ds_man.get_dataset(\"monthly_climate_features\")\n",
    "xa_coral_climate_1_12 = ds_man.get_dataset(\"monthly_climate_1_12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, lat_lon_dict = subsample_to_array(xa_coral_climate_1_12, lat_lon_starts=(-10,142), coord_range=(-7,5))\n",
    "Xs_nonans = naive_X_nan_replacement(Xs)\n",
    "ys, _ = subsample_to_array(xa_coral_climate_1_12, lat_lon_starts=(-10,142), coord_range=(-7,5), variables = [\"coral_algae_1-12_degree\"])\n",
    "ys = ys[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample subset\n",
    "# subsample, lat_lon_vals_dict = sample_spatial_batch(xa_coral_climate_1_12_features,lat_lon_starts=(-12,144), coord_range=(-4,2))\n",
    "# subsample, lat_lon_vals_dict = sample_spatial_batch(xa_coral_climate_1_12_features,lat_lon_starts=(-10,142), coord_range=(-7,5))\n",
    "# convert to ndarray\n",
    "# # test_array = spatial_data.xa_ds_to_3d_numpy(subsample)\n",
    "# # subsample_all, _ = sample_spatial_batch(xa_coral_climate_1_12,lat_lon_starts=(-16,144), coord_range=(-4,2))\n",
    "# subsample_all, _ = sample_spatial_batch(xa_coral_climate_1_12,lat_lon_starts=(-10,142), coord_range=(-7,5))\n",
    "# sub_y_nans = (np.array(subsample_all[\"coral_algae_1-12_degree\"].isel(time=-1))).reshape(-1, 1)\n",
    "# # remove nans\n",
    "# #sub_X, sub_y = filter_out_nans(test_array, sub_y_nans)\n",
    "# # testing, so replace nans with -1\n",
    "# # filter out columns that contain entirely NaN values\n",
    "# # col_mask = ~np.all(np.isnan(test_array), axis=(0,2)) # boolean mask indicating which columns to keep\n",
    "# # sub_X = test_array[:, col_mask, :] # keep only the columns that don't contain entirely NaN values\n",
    "\n",
    "# # sub_X = np.moveaxis(np.array(sub_X), 2, 1)\n",
    "# sub_y = sub_y_nans\n",
    "# # sub_X[np.isnan(sub_X)] = -10000\n",
    "# sub_y[np.isnan(sub_y)] = -10000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_to_dataset_var(xa_ds: xa.Dataset | xa.DataArray, subset_vals: np.ndarray, dims: list=['latitude', 'longitude', \"time\"]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_train = np.append(100*np.ones((50,50,5)), 1*np.ones((50,50,5)), 0)\n",
    "test_y_train = np.append(np.ones(50,), np.zeros(50,))\n",
    "\n",
    "\n",
    "print(\"test_x_train:\", test_x_train.shape)\n",
    "# print(\"x_test:\", x_test.shape)\n",
    "print(\"test_y_train:\", test_y_train.shape)\n",
    "# print(\"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.normal(size = (32, 20, 1))    # shape: (num_samples, sequence_length, num_features)\n",
    "y_dud = np.random.choice([0, 1], size = 32)\n",
    "print(\"array shape:\", array.shape)\n",
    "print(\"y_dud shape:\", y_dud.shape)\n",
    "\n",
    "x_train, y_train = X[:500], y[:500].reshape(500,)\n",
    "# x_test, y_test = X[5000:6000], y[5000:6000].reshape((1000,))\n",
    "\n",
    "print(\"x_train:\", x_train.shape)\n",
    "# print(\"x_test:\", x_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "# print(\"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_model(test_x_train[:],training=False).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = g_model(X[:5610],training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_coral_climate_1_12[\"coral_algae_1-12_degree\"].isel(time=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30*187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out = ax.imshow(predicted.numpy().reshape(30,187))\n",
    "fig.colorbar(out, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_coral_climate_1_12_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_coral_climate_1_12[\"coral_algae_1-12_degree\"].isel(time=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out = ax.imshow(y_pred.numpy().reshape(20,25))\n",
    "fig.colorbar(out, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((y_pred > 0.5).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check log likelihood is computable\n",
    "negative_log_likelihood(y[:32], g_model(X[:32]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batcher function (by space and time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher_fun(X, y, batch_size, seq_len):\n",
    "    \"\"\"\n",
    "    A function to prepare the data for training the LSTM.\n",
    "    \n",
    "    :param data: The input data to the LSTM.\n",
    "    :param batch_size: The number of samples in each batch.\n",
    "    :param seq_len: The sequence length of each sample.\n",
    "    \n",
    "    :return: A tuple of (batch_x, batch_y), where batch_x is a numpy array of shape (batch_size, seq_len, num_features) \n",
    "             and batch_y is a numpy array of shape (batch_size, num_classes).\n",
    "    \"\"\"\n",
    "    num_samples = len(data)\n",
    "    num_batches = int(num_samples / batch_size)\n",
    "    num_features = spatial_data.shape[1]\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = (i + 1) * batch_size\n",
    "        \n",
    "        batch_x = np.zeros((batch_size, seq_len, num_features))\n",
    "        batch_y = np.zeros((batch_size, 1))\n",
    "        \n",
    "        for j in range(start_idx, end_idx):\n",
    "            sample = data[j]\n",
    "            X = sample[:-1]\n",
    "            y = y[]\n",
    "            \n",
    "            batch_x[j - start_idx] = x.reshape((seq_len, num_features))\n",
    "            batch_y[j - start_idx, y] = 1\n",
    "            \n",
    "        yield batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    num_epochs = 1\n",
    "    num_batches = 100\n",
    "    tr_step = build_graph()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in range(num_batches):\n",
    "            array, y  = batcher_fun(X, 32, 276 \n",
    "            #training = True)# shapes: (batch_s, seq_l, features), (batch_s, 1)\n",
    "            )\n",
    "            y_pred, xent = tr_step(g_model, optimizer, X[:32], y, training=True)\n",
    "            \n",
    "         ## validation set \n",
    "         ## test_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copypasta\n",
    "\n",
    "[Source](https://github.com/christianversloot/machine-learning-articles/blob/main/build-an-lstm-model-with-tensorflow-and-keras.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers.legacy import Adam # https://stackoverflow.com/questions/75356826/attributeerror-adam-object-has-no-attribute-get-updates\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Model configuration\n",
    "additional_metrics = [\"accuracy\"]\n",
    "# batch_size = 128\n",
    "batch_size = 32\n",
    "# embedding_output_dims = 15\n",
    "# embedding_output_dims = 10\n",
    "loss_function = BinaryCrossentropy()\n",
    "# max_sequence_length = 300\n",
    "max_sequence_length = 276\n",
    "# num_distinct_words = 5000\n",
    "# num_distinct_words = 10000\n",
    "number_of_epochs = 5\n",
    "optimizer = Adam()\n",
    "validation_split = 0.20\n",
    "verbosity_mode = 1\n",
    "\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_distinct_words)\n",
    "x_train, y_train = X[:5000], y[:5000].reshape((5000,))\n",
    "x_test, y_test = X[5000:6000], y[5000:6000].reshape((1000,))\n",
    "\n",
    "print(\"x_train:\", x_train.shape)\n",
    "print(\"x_test:\", x_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad all sequences: keras requires sequences of equal lengths. Should be handled in pre-processing, but here for now for security\n",
    "padded_inputs = pad_sequences(x_train, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>\n",
    "padded_inputs_test = pad_sequences(x_test, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>\n",
    "\n",
    "# (number_samples, sequence_length, num_features)\n",
    "print(\"padded_inputs:\", padded_inputs.shape)\n",
    "print(\"padded_inputs_test:\", padded_inputs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_inputs = pad_sequences(x_train[:,:,0], maxlen=max_sequence_length, value = 0.0)\n",
    "padded_inputs_test = pad_sequences(x_test[:,:,0], maxlen=max_sequence_length, value = 0.0)\n",
    "\n",
    "# (number_samples, sequence_length)\n",
    "print(\"padded_inputs:\", padded_inputs.shape)\n",
    "print(\"padded_inputs_test:\", padded_inputs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(\n",
    "        num_distinct_words+1, embedding_output_dims, input_length=max_sequence_length\n",
    "    )\n",
    ")\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)\n",
    "\n",
    "# Give a summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    padded_inputs,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=number_of_epochs,\n",
    "    verbose=verbosity_mode,\n",
    "    validation_split=validation_split,\n",
    ")\n",
    "\n",
    "# Test the model after training\n",
    "test_results = model.evaluate(padded_inputs_test, y_test, verbose=False)\n",
    "print(f\"Test results - Loss: {test_results[0]} - Accuracy: {100*test_results[1]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_timeseries(history) -> None:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[\"accuracy\"])\n",
    "    ax.plot(history.history[\"val_accuracy\"])\n",
    "\n",
    "    ax.set_title(\"Model accuracy against epoch\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.legend(['train set', 'validation set'], loc='upper left')\n",
    "\n",
    "plot_score_timeseries(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate model\n",
    "\n",
    "[Source](https://medium.com/@canerkilinc/hands-on-multivariate-time-series-sequence-to-sequence-predictions-with-lstm-tensorflow-keras-ce86f2c0e4fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_toy = X[:32*10,:10,:3]\n",
    "print(\"X_toy:\", X_toy.shape)\n",
    "y_toy = y[:32*10]\n",
    "print(\"y_toy:\", y_toy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "#####################################\n",
    "#Before do anything else do not forget to reset the backend for the next iteration (rerun the model)\n",
    "tensorflow.keras.backend.clear_session()\n",
    "#####################################\n",
    "# Initialising the LSTM Model with MAE Loss-Function\n",
    "batch_size = 32\n",
    "epochs = 120\n",
    "timesteps = 10\n",
    "num_features = 3\n",
    "input_1 = Input(batch_shape=(batch_size,timesteps,num_features))\n",
    "#each layer is the input of the next layer\n",
    "lstm_hidden_layer_1 = LSTM(10, stateful=True, return_sequences=True)(input_1)\n",
    "lstm_hidden_layer_2 = LSTM(10, stateful=True, return_sequences=True)(lstm_hidden_layer_1)\n",
    "output_1 = Dense(units = 1)(lstm_hidden_layer_2)\n",
    "regressor_mae = Model(inputs=input_1, outputs = output_1)\n",
    "#adam is fast starting off and then gets slower and more precise\n",
    "#mae -> mean absolute error loss function\n",
    "regressor_mae.compile(optimizer='adam', loss = 'mae')\n",
    "#####################################\n",
    "#Summarize and observe the layers as well as paramter configurations\n",
    "regressor_mae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_mae.fit(\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CORALSHIFT",
   "language": "python",
   "name": "coralshift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data storage setup\n",
    "\n",
    "#### The following notebook may be used to install all data used in the `coralshift` paper from source. Due to the huge quantity of data, the sequential calls to various APIs take a very long time (~days). \n",
    "\n",
    "#### It is therefore recommended to make use of the example datasets provided at the following link: [https://doi.org/10.5281/zenodo.8110926](https://doi.org/10.5281/zenodo.8110926)\n",
    "\n",
    "## Dataset structure\n",
    "\n",
    "Datasets will be downloaded and processed into the following directory structure:\n",
    "\n",
    "- coralshift (cloned repository containing Python scripts, Jupyter notebooks etc.)\n",
    "- datasets\n",
    "    - **bathymetry**\n",
    "        - REGION_NAME_1_2020_30m_MSL_cog.tif\n",
    "        - REGION_NAME_2_2020_30m_MSL_cog.tif\n",
    "        - ...\n",
    "        - REGION_NAME_N_2020_30m_MSL_cog.tif\n",
    "        - bathymetry_REGION_NAME_1_RESOLUTION.nc\n",
    "        - bathymetry_REGION_NAME_2_RESOLUTION.nc\n",
    "        - ...\n",
    "        - bathymetry_REGION_NAME_N_RESOLUTION.nc\n",
    "    - **gradients**\n",
    "        - region_REGION_NAME_1_RESOLUTION_gradients.nc\n",
    "        - region_REGION_NAME_2_RESOLUTION_gradients.nc\n",
    "        - ...\n",
    "        - region_REGION_NAME_N_RESOLUTION_gradients.nc\n",
    "    - **reef_baseline**\n",
    "        - region_name\n",
    "            - benthic.gpkg\n",
    "            - benthic.pkl\n",
    "            - REGION_NAME shapefile components\n",
    "        - gt_files\n",
    "            - RESOLUTION_arrays\n",
    "                - coral_region_REGION_NAME_1_1000m_RESOLUTION.nc\n",
    "                - coral_region_REGION_NAME_2_1000m_RESOLUTION.nc\n",
    "                - ...\n",
    "                - coral_region_REGION_NAME_N_1000m_RESOLUTION.nc\n",
    "        - coral_region_REGION_NAME_1_1000m.tif\n",
    "        - coral_region_REGION_NAME_2_1000m.tif\n",
    "        - ...\n",
    "        - coral_region_REGION_NAME_N_1000m.tif\n",
    "    - **global_ocean_reanalysis**\n",
    "        - daily_means\n",
    "            - region_name e.g. Great_Barrier_Reef_A\n",
    "                - var1 (.nc files and accompanying metadata containing variable data grouped by year)\n",
    "                - var2\n",
    "                - ...\n",
    "                - varN\n",
    "                - merged_vars (.nc files and accompanying metadata for each variable)\n",
    "                - cmems_gopr_daily_REGION_NAME.nc (merged variables for region + metadata)\n",
    "        - monthly_means\n",
    "            - region_name e.g. Great_Barrier_Reef_A\n",
    "                - var1 (.nc files and accompanying metadata containing variable data grouped by year)\n",
    "                - var2\n",
    "                - ...\n",
    "                - varN\n",
    "                - merged_vars (.nc files and accompanying metadata for each variable)\n",
    "                - cmems_gopr_monthly_REGION_NAME.nc (merged variables for region + metadata)\n",
    "    - **era5**\n",
    "        - region_name e.g. Great_Barrier_Reef_A\n",
    "            - var1 (.nc files containing variable data grouped by year)\n",
    "            - var2\n",
    "            - ...\n",
    "            - varN\n",
    "            - weather_parameters (.nc file for each variable for whole specified time period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this line to the where directory in which the GitHub repository is located: datasets will be installed into \n",
    "# the directory one level above this\n",
    "os.chdir(\"/lustre_scratch/orlando-code/coralshift/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from IPython.display import HTML\n",
    "\n",
    "from coralshift.dataloading import data_structure, climate_data, bathymetry, reef_extent\n",
    "from coralshift.utils import directories\n",
    "from coralshift.plotting import spatial_plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify your area of interest\n",
    "\n",
    "The availability of high-resolution (30m) bathymetric data means that areas of interest are currently confined to 4 areas on the Great Barrier Reef (GBR). The following code downloads the specified area of bathymetry data:\n",
    "\n",
    "| Reef Area Name                \t| Latitudes \t| Longitudes \t|\n",
    "|-------------------------------\t|-----------\t|------------\t|\n",
    "| Great Barrier Reef A 2020 30m \t| 10-17°S   \t| 142-147°E  \t|\n",
    "| Great Barrier Reef B 2020 30m \t| 16-23°S   \t| 144-149°E  \t|\n",
    "| Great Barrier Reef C 2020 30m \t| 18-24°S   \t| 148-154°E  \t|\n",
    "| Great Barrier Reef D 2020 30m \t| 23-29°S   \t| 150-156°E  \t|\n",
    "\n",
    "\n",
    "![bathymetry_regions.png](https://github.com/orlando-code/coralshift/blob/dev-setup/bathymetry_regions.png?raw=true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose resolution (should be above 4000m for processing in decent time)\n",
    "# native resolutions are 1 (1, \"m\") or 1/12 degrees (1/12, \"d\"), or 1/27 degrees (1/27, \"d\")\n",
    "target_resolution_m, target_resolution_d = spatial_data.choose_resolution(\n",
    "    resolution=1/27, unit=\"d\")\n",
    "\n",
    "print(f\"Data will be resampled to {target_resolution_d:.04f} degrees (~{target_resolution_m:.0f}m).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the letters or names of regions to download\n",
    "region_letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "# visualise area(s)\n",
    "spatial_plots.plot_reef_areas(region_letters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bathymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reef_areas = bathymetry.ReefAreas()\n",
    "\n",
    "for region in region_letters:\n",
    "    file_name = reef_areas.get_short_filename(area_name)\n",
    "    bath_dir = directories.get_bathymetry_datasets_dir()\n",
    "    _, xa_bath = bathymetry.generate_bathymetry_xa_da(region)\n",
    "    _, _ = spatial_data.upsample_and_save_xa_a(\n",
    "        bath_dir, xa_d=xa_bath, name=file_name, target_resolution_d=target_resolution_d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate absolute gradients from bathymetry and save to file\n",
    "bathymetry.generate_gradient_magnitude_ncs(regions=region_letters, resolution_d=target_resolution_d, sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display different resolutions\n",
    "fig, (ax_left, ax_right) = plt.subplots(1, 2, figsize=(16,9), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "\n",
    "ax1 = spatial_plots.plot_spatial(xa_bath_upsampled, \n",
    "    fax= (fig,ax_left), val_lims=(-50,0), name=\"depth\", title=f\"Bathymetry at {target_resolution_m}m resolution\")\n",
    "ax2 = spatial_plots.plot_spatial(grads, \n",
    "    fax=(fig, ax_right), val_lims=(0,10), name=\"gradient magnitude\", \n",
    "    title=f\"Absolute seafloor gradients at {target_resolution_m}m resolution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coral ground truth: Allen Coral Atlas\n",
    "\n",
    "\n",
    "There is currently no API for accessing data directly from your local machine. Please follow the instructions* below:\n",
    "1. Make an account on the [Allen Coral Atlas](https://allencoralatlas.org/atlas/#6.00/-13.5257/144.5000) webpage\n",
    "2. Generate a geojson file using the code cell below (generated in the `reef_baseline` directory)\n",
    "\n",
    "*Instructions correct as of 30.06.23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/N8vPKXc0W4k\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate geojson file in reef_baseline directory for download from the Allen Coral Atlas\n",
    "geojson_path = reef_extent.generate_area_geojson(area_class = reef_areas, area_name=file_name)\n",
    "\n",
    "print(f\"geoJSON file saved at {geojson_path} for upload to GEE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Upload the geojson file via:\n",
    "\n",
    "    \\> My Areas > Upload a GeoJSON or KML file\n",
    "4. Specify a region name and navigate to the \"Download data\" tab when it becomes available.\n",
    "4. Select \"Benthic Map (OGC GeoPackage (.gpkg))\". Sign the terms and conditions \n",
    "and select \"Prepare Download\". After ~two minutes a sequence of emails will arrive notifying you that your download is ready.\n",
    "5. Download the file and unzip it using a unzipping utility. Then, add the `benthic.gpkg` file to the `reef_baseline` directory.\n",
    "6. Continue with the subsequent code cells.\n",
    "\n",
    "----\n",
    "\n",
    "You have now downloaded:\n",
    "\n",
    "**`benthic.gpkg`**\n",
    "\n",
    "This is a dataframe of Shapely objects (\"geometry\" polygons) defining the boundaries of different benthic classes:\n",
    "\n",
    "| Class           \t| Number of polygons \t|\n",
    "|-----------------\t|--------------------\t|\n",
    "| Coral/Algae     \t| 877787             \t|\n",
    "| Rock            \t| 766391             \t|\n",
    "| Rubble          \t| 568041             \t|\n",
    "| Sand            \t| 518805             \t|\n",
    "| Microalgal Mats \t| 27569              \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read .gpkg file and save to .pkl format for faster reading later\n",
    "region_benthic_df = file_ops.check_pkl_else_read_gpkg(directories.get_reef_baseline_dir() / file_name, filename = \"benthic.pkl\")\n",
    "region_benthic_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rasterize polygons\n",
    "\n",
    "Rasterized arrays are necessary to process the geospatial data e.g. to align different gridcells. Doing this locally through rasterio requires such significant compute that cloud computing is the only reasonable option. A JavaScript file (`rasterization.js`) for use in Google Earth Engine (GEE) is accessible [here](https://code.earthengine.google.com/ae68c68309b04643e8f5f5dc45f0dbca). Visit [this page](https://developers.google.com/earth-engine/guides/getstarted) for information regarding setting up a GEE account and getting started.\n",
    "\n",
    "GEE requires shapefile (.shp) format to ingest data. This is generated in the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process df to gpd.GeoDataFrame. \n",
    "# We are interested only in the \"Coral/Algae\" class, so gdf is limited to these rows by default\n",
    "gdf_coral = reef_extent.process_benthic_pd(region_benthic_df)\n",
    "# save as shapely file (if not already present) for rasterisation in GEE\n",
    "reef_extent.generate_coral_shp(gdf_coral, file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ingest the shapefile (and all accompanying files: .cpg, .dbf, .prj, .shx) as a GEE asset.\n",
    "2. Import the subsequent `Table` into the script.\n",
    "3. Update the `resolution` variable as desired (usually that matching the target resolution specified above).\n",
    "3. Run the script, and submit the `coral_raster_Xm` task. Sit back and wait! After ~1 hour (depending on the chosen resolution) the rasters will be available to download from your Google Drive as GeoTIFFS: after this, add them to the `reef_baseline` directory and carry on with the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all tifs in reef_extent directory to nc files at specified target resolution\n",
    "process_reef_extent_tifs(target_resolution_d=target_resolution_d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Ocean Physics Reanalysis\n",
    "\n",
    "The dataset and its metadata can be accessed [here](https://doi.org/10.48670/moi-00021)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "You're required to set up an account with the [Copernicus Marine Service](https://marine.copernicus.eu/). \n",
    "\n",
    "\n",
    "**Warning:**  this is a large amount of data for which the only way to gather it is to query the copernicus API via motu. Requests are queued, and request sizes are floated to the top of the queue. The following functions take advantage of this by splitting a single request up by date adn variable before amalgamating the files, but this can still take a **very long time**, and vary significantly depending on overall website traffic. For those who aren't interested in the entire database, it's highly recommended that you use the toy dataset provided as a `.npy` file in the GitHub repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download monthly data for all specified areas \n",
    "# Can be adjusted to specify subset of variables, dates, and depths to download.\n",
    "# Values generated here are those reported in the accompanying paper.\n",
    "\n",
    "for area_name in region_letters:\n",
    "    _, _ = climate_data.download_reanalysis(\n",
    "        download_dir=directories.get_monthly_cmems_dir(),\n",
    "        region = reef_areas.get_short_filename(area_name),\n",
    "        final_filename = f\"cmems_gopr_monthly_{area_name}\",\n",
    "        lat_lims = reef_areas.get_lat_lon_limits(area_name)[0], lon_lims = reef_areas.get_lat_lon_limits(area_name)[1], \n",
    "        product_id = \"cmems_mod_glo_phy_my_0.083_P1M-m\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download daily data for all specified areas\n",
    "for area_name in region_letters:\n",
    "    _, _ = climate_data.download_reanalysis(\n",
    "        download_dir=directories.get_daily_cmems_dir(),\n",
    "        region = reef_areas.get_short_filename(area_name),\n",
    "        final_filename = f\"cmems_gopr_daily_{area_name}\",\n",
    "        lat_lims = reef_areas.get_lat_lon_limits(area_name)[0], lon_lims = reef_areas.get_lat_lon_limits(area_name)[1], \n",
    "        product_id = \"cmems_mod_glo_phy_my_0.083_P1D-m\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample daily climate data to desired resolution\n",
    "_, _ = spatial_data.upsample_and_save_xa_a(\n",
    "    directories.get_daily_cmems_dir() / reef_areas.get_short_filename(area_name), \n",
    "    xa_d=xa_cmems_daily, name=cmems_daily_path.stem, target_resolution_d=target_resolution_d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ERA5 data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "European Reanalysis v.5 (ERA5) is the fifth generation European Centre for Medium-range Weather Forecasting's (ECMWF) reanalysis for the global climate and weather over the past 8 decades.\n",
    "\n",
    "The dataset and its metadata may be accessed [here](10.24381/cds.adbb2d47)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download ERA5 data for each region\n",
    "for region in region_letters:\n",
    "    lat_lims=reef_areas.get_lat_lon_limits(region)[0]\n",
    "    lon_lims=reef_areas.get_lat_lon_limits(region)[1]\n",
    "    region = reef_areas.get_short_filename(region)\n",
    "    generate_era5_data(\n",
    "        lat_lims=lat_lims, lon_lims=lon_lims,\n",
    "        region = region\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All necessary data has now beeen downloaded.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coralshift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6967558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71072828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gru_model(tf.keras.Model):\n",
    "    def __init__(self, rnn_units, num_layers):\n",
    "        super(gru_model, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn_units = rnn_units\n",
    "        self.grus = [tf.keras.layers.GRU(rnn_units[i],\n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True) for i in range(num_layers)]\n",
    "        \n",
    "        self.w1 = tf.keras.layers.Dense(10) ## Dense is a linear layer \n",
    "        self.w2 = tf.keras.layers.Dense(1) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        #input shape: (batch_size, seq_length, features)\n",
    "        assert self.num_layers == len(self.rnn_units)\n",
    "        x = inputs\n",
    "        if (len(x.shape) != 3):\n",
    "            print('what are you doing? this is wrong shape')\n",
    "        print('input dim ({}, {}, {})'.format(x.shape[0], x.shape[1], x.shape[2]))\n",
    "        whole_seq = x\n",
    "\n",
    "        ## RNN stuff\n",
    "        for i in range(self.num_layers):\n",
    "            whole_seq, final_s = self.grus[i](whole_seq, training=training)\n",
    "        ##\n",
    "        \n",
    "        ## extra layers\n",
    "        target = self.w1(final_s)\n",
    "        target = tf.nn.relu(target) ## just non-linearity \n",
    "        target = self.w2(target)\n",
    "        \n",
    "        ### The Dense layer right before the sigmoid must be dimension 1. \n",
    "        ### We must keep sigmoid for probability in [0, 1]\n",
    "        target = tf.nn.sigmoid(target)\n",
    "        \n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3e92c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if inputs are [x1, x2]\n",
    "## Dense(x1, x2) == w1x1 + w2x2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8babe04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(y, y_pred):\n",
    "    '''y_pred is a probability value between 0 to 1'''\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()    \n",
    "    return bce(y, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26194d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    \n",
    "    @tf.function(experimental_relax_shapes=True)\n",
    "    def train_step(gru, optimizer, x,y, training=True):\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            μ = gru(x, training) \n",
    "            xent = nll(y, μ)\n",
    "        \n",
    "        gradients = tape.gradient(xent, gru.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, gru.trainable_variables))\n",
    "        return μ, xent\n",
    "\n",
    "    tf.keras.backend.set_floatx('float32')\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e3c11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.random.choice([0, 1], size = 32)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c35665f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.normal(size = (32, 20, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e44d1811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 20, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape # batch_size X seq_len (timestamps in time-series) X features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94265c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 22:03:29.165404: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "g_model = gru_model([32], 1) #term in [] is size of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bee77090",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim (32, 20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
       "array([[0.5095421 ],\n",
       "       [0.4956858 ],\n",
       "       [0.47816133],\n",
       "       [0.4688766 ],\n",
       "       [0.46282226],\n",
       "       [0.46647865],\n",
       "       [0.4871919 ],\n",
       "       [0.48821723],\n",
       "       [0.45809904],\n",
       "       [0.47964028],\n",
       "       [0.46525875],\n",
       "       [0.47405523],\n",
       "       [0.47509232],\n",
       "       [0.44130936],\n",
       "       [0.4762384 ],\n",
       "       [0.47616076],\n",
       "       [0.4909564 ],\n",
       "       [0.4910372 ],\n",
       "       [0.48490867],\n",
       "       [0.4758533 ],\n",
       "       [0.4857951 ],\n",
       "       [0.48292905],\n",
       "       [0.4855606 ],\n",
       "       [0.52518517],\n",
       "       [0.4895521 ],\n",
       "       [0.4754499 ],\n",
       "       [0.48418042],\n",
       "       [0.48313034],\n",
       "       [0.48713794],\n",
       "       [0.44082937],\n",
       "       [0.47536755],\n",
       "       [0.4943494 ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model(array)\n",
    "# output shape batch_size X 1 \n",
    "# outptut is a probability between 0 to 1 \n",
    "# interpretation is how likely each sequence to be a coral/not coral  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "171eecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim (32, 20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.68439996>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(y, g_model(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9505ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ebc3b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim (32, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    num_epochs = 1\n",
    "    num_batches = 100\n",
    "    tr_step = build_graph()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in range(num_batches):\n",
    "            array = np.random.normal(size = (32, 20, 1))# fake data\n",
    "            y = np.random.choice([0, 1], size = 32)  # fake             \n",
    "            ### array, y  = batcher_fun(data, training = True) shapes: (batch_s, seq_l, features), (batch_s, 1)\n",
    "            y_pred, xent = tr_step(g_model, optimizer, array, y, training=True)\n",
    "            \n",
    "         ## validation set \n",
    "         ## test_set "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# choose whether to work on a remote machine\n",
    "location = \"remote\"\n",
    "if location == \"remote\":\n",
    "    # change this line to the where the GitHub repository is located\n",
    "    os.chdir(\"/lustre_scratch/orlando-code/coralshift/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /home/jovyan/lustre_scratch/conda-envs/coralshift/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import xarray as xa\n",
    "import numpy as np\n",
    "import json\n",
    "import math as m\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sklmetrics\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.enums import Resampling\n",
    "import rioxarray as rio\n",
    "import pickle\n",
    "\n",
    "from coralshift.utils import directories, file_ops, utils\n",
    "from coralshift.processing import spatial_data, baselines\n",
    "from coralshift.plotting import spatial_plots, model_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_reproducing_xa_das() -> list[xa.DataArray]:\n",
    "    \"\"\"\n",
    "    Load and process xarray data arrays for reproducing metrics.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        list[xa.DataArray]: A list containing the processed xarray data arrays.\n",
    "    \"\"\"\n",
    "    # load in daily sea water potential temp\n",
    "    thetao_daily = xa.open_dataarray(directories.get_processed_dir() / \"arrays/thetao.nc\")\n",
    "    \n",
    "    # load in daily sea water salinity means\n",
    "    salinity_daily = xa.open_dataarray(directories.get_processed_dir() / \"arrays/so.nc\")\n",
    "\n",
    "    # load in daily latitudinal and longitudinal currents\n",
    "    uo_daily = xa.open_dataarray(directories.get_processed_dir() / \"arrays/uo.nc\")\n",
    "    vo_daily = xa.open_dataarray(directories.get_processed_dir() / \"arrays/vo.nc\")\n",
    "    # calculate current magnitude\n",
    "    current_daily = baselines.calculate_magnitude(uo_daily, vo_daily).rename(\"current\")\n",
    "\n",
    "    bathymetry = xa.open_dataset(\n",
    "        directories.get_bathymetry_datasets_dir() / \"bathymetry_A_0-00030d.nc\").rio.write_crs(\"EPSG:4326\")[\"bathymetry_A\"]\n",
    "\n",
    "    # Load in ERA5 surface net solar radiation and upscale to climate variable resolution\n",
    "    solar_radiation = xa.open_dataarray(\n",
    "        directories.get_era5_data_dir() / \"weather_parameters/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_1993-2020.nc\"\n",
    "        ).rio.write_crs(\"EPSG:4326\")\n",
    "    # average solar_radiation daily\n",
    "    solar_radiation_daily = solar_radiation.resample(time=\"1D\").mean(dim=\"time\")\n",
    "\n",
    "    # Load in ground truth data\n",
    "    gt_1000m = xa.open_dataarray(directories.get_processed_dir() / \"arrays/coral_raster_1000m.nc\").rename(\"gt\")\n",
    "\n",
    "    return [thetao_daily, salinity_daily, current_daily, solar_radiation_daily, bathymetry, gt_1000m]\n",
    "\n",
    "\n",
    "def resample_list_xa_ds_to_target_resolution_and_merge(xa_das: list[xa.DataArray], target_resolution: float, \n",
    "    unit: str = \"m\", lat_lims: tuple[float] = (-10,-17), lon_lims: tuple[float] = (142,147)) -> dict:\n",
    "    \"\"\"\n",
    "    Resample a list of xarray DataArrays to the target resolution and merge them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        xa_das (list[xa.DataArray]): A list of xarray DataArrays to be resampled and merged.\n",
    "        target_resolution (float): The target resolution for resampling.\n",
    "        unit (str, defaults to \"m\"): The unit of the target resolution.\n",
    "        interp_method: (str, defaults to \"linear\") The interpolation method for resampling.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A dictionary containing the resampled xarray DataArrays merged by their names.\n",
    "    \"\"\"\n",
    "    # TODO: will probably need to save to individual files/folders and combine at test/train time\n",
    "    # may need to go to target array here\n",
    "    target_resolution_d = spatial_data.choose_resolution(target_resolution, unit)[1]\n",
    "    dummy_xa = generate_dummy_xa(target_resolution_d, lat_lims, lon_lims)\n",
    "\n",
    "    resampled_xa_das_dict = {}\n",
    "    for xa_da in tqdm(xa_das, desc = \"Resampling xarray DataArrays\"):\n",
    "\n",
    "        xa_resampled = upsample_xa_d_to_other(xa_da, dummy_xa, name=xa_da.name)\n",
    "\n",
    "        resampled_xa_das_dict[xa_da.name] = xa_resampled\n",
    "    \n",
    "    return resampled_xa_das_dict\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def find_index_pair(xa_da, lat, lon, lat_spacing, lon_spacing):\n",
    "    # Get the latitude and longitude spacing\n",
    "\n",
    "    lat_values = list(xa_da.latitude.values)\n",
    "    lon_values = list(xa_da.longitude.values)\n",
    "\n",
    "    lat_index = np.where(np.isclose(lat_values, lat))[0][0]\n",
    "    lon_index = np.where(np.isclose(lon_values, lon))[0][0]\n",
    "\n",
    "    return lat_index, lon_index\n",
    "\n",
    "\n",
    "def select_rows_by_coordinates(dataframe: pd.DataFrame, coordinates: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Select rows from a Pandas DataFrame based on matching latitude and longitude values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        dataframe (pd.DataFrame): The Pandas DataFrame.\n",
    "        coordinates (list): List of tuples containing latitude and longitude values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        pd.DataFrame: The selected subset of the DataFrame.\n",
    "    \"\"\"\n",
    "    indices = list(zip(dataframe.index.get_level_values(0), dataframe.index.get_level_values(1)))\n",
    "    row_inds = [index for index, item in enumerate(indices) if item in coordinates]\n",
    "\n",
    "    return dataframe.iloc[row_inds]\n",
    "\n",
    "\n",
    "def generate_coordinate_pairs(xa_da: xa.DataArray, split_ratio: float, random_seed: int = None) -> tuple[list, list]:\n",
    "    \"\"\"\n",
    "    Generate two lists of coordinate pairs from an xarray DataArray in the specified split ratio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        xa_da (xa.DataArray): The xarray DataArray.\n",
    "        split_ratio (float): The split ratio for dividing the coordinates.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        tuple[list, list]: A tuple containing the two lists of coordinate pairs.\n",
    "    \"\"\"\n",
    "    # TODO: could omit nans from test/train\n",
    "    if random_seed:\n",
    "        # set random seed\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    spatial_coords = xa_da.drop_dims(\"time\").drop([\"spatial_ref\",\"depth\",\"band\"]).coords\n",
    "\n",
    "    # Get the total number of samples\n",
    "    num_samples = len(spatial_coords[\"latitude\"]) * len(spatial_coords[\"longitude\"])\n",
    "\n",
    "    # Calculate the split sizes\n",
    "    test_size = int(num_samples * split_ratio)\n",
    "    train_size = num_samples - test_size\n",
    "\n",
    "    # Split the coordinates into two lists based on the split sizes\n",
    "    coordinates_list = spatial_coords.to_index().tolist()  # Convert to a list of tuples\n",
    "    # Shuffle the coordinates randomly\n",
    "    np.random.shuffle(coordinates_list)\n",
    "\n",
    "    train_coordinates = coordinates_list[:train_size]\n",
    "    test_coordinates = coordinates_list[train_size:train_size+test_size]\n",
    "\n",
    "    return train_coordinates, test_coordinates\n",
    "\n",
    "\n",
    "def generate_test_train_coordinates(xa_ds: xa.Dataset, split_type: str=\"pixel\", test_lats: tuple[float]= None, \n",
    "    test_lons: tuple[float]= None, test_fraction: float=0.2, bath_mask: bool = True) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate test and train coordinates for a given dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        xa_ds (xa.Dataset): The input xarray Dataset.\n",
    "        split_type (str): The split type, either \"pixel\" or \"region\". Default is \"pixel\".\n",
    "        test_lats (tuple[float]): The latitude range for the test region. Required for \"region\" split type. Default is None.\n",
    "        test_lons (tuple[float]): The longitude range for the test region. Required for \"region\" split type. Default is None.\n",
    "        test_fraction (float): The fraction of data to be used for the test set. Default is 0.2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        tuple[pd.DataFrame, pd.DataFrame]: A tuple containing train coordinates and test coordinates as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    # if chosen to restrict to shallow regions only, set all values outside of threshold to nan\n",
    "    if bath_mask:\n",
    "        xa_ds = xa_ds.compute()\n",
    "        bath_mask = generate_var_mask(xa_ds)\n",
    "        xa_ds = xa_ds.where(bath_mask, np.nan)\n",
    "    \n",
    "\n",
    "    if split_type == \"pixel\":\n",
    "        # have to handle time: make sure sampling spatially rather than spatiotempoorally\n",
    "        train_coordinates, test_coordinates = generate_coordinate_pairs(xa_ds, test_fraction)\n",
    "\n",
    "    elif split_type == \"region\":\n",
    "        # if specific latitude/longitude boundary not specified, separate region horizontally\n",
    "        if not (test_lons and test_lats):\n",
    "            \n",
    "            # calculate the number of latitude cells\n",
    "            num_lats = len(xa_ds.latitude.values)\n",
    "            # calculate number of latitude rows in test and train sets\n",
    "            test_size = int(num_lats * test_fraction)\n",
    "            train_size = num_lats - test_size\n",
    "\n",
    "            # slice region into test and train xa.Datasets\n",
    "            train_xa = xa_ds.isel({\"latitude\": slice(0, train_size)})\n",
    "            test_xa = xa_ds.isel({\"latitude\": slice(train_size, num_lats)})\n",
    "            \n",
    "            train_coordinates,_ = generate_coordinate_pairs(train_xa, 0)\n",
    "            test_coordinates,_ = generate_coordinate_pairs(test_xa, 0)\n",
    "\n",
    "        # if specific latitude/longitude boundary specified, cut out test region and train on all else\n",
    "        else:\n",
    "            test_xa = xa_ds.isel({\"latitude\": slice(test_lats[0], test_lats[1]), \n",
    "                \"longitude\": slice(test_lons[0], test_lons[1])})\n",
    "            all_coordinates = generate_coordinate_pairs(xa_ds)\n",
    "            \n",
    "            test_coordinates = generate_coordinate_pairs(test_xa)\n",
    "            train_coordinates = list(set(all_coordinates - set(test_coordinates)))\n",
    "\n",
    "    return train_coordinates, test_coordinates\n",
    "\n",
    "\n",
    "def spatial_split_train_test(xa_ds: xa.Dataset, gt_label: str=\"gt\", data_type: str = \"continuous\", \n",
    "    ignore_vars: list = [\"time\",\"spatial_ref\",\"band\",\"depth\"],\n",
    "    split_type: str=\"pixel\", test_lats: tuple[float]= None, test_lons: tuple[float]= None, test_fraction: float=0.2,\n",
    "    bath_mask: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    Split the input dataset into train and test sets based on spatial coordinates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        xa_ds (xa.Dataset): The input xarray Dataset.\n",
    "        gt_label: The ground truth label.\n",
    "        ignore_vars (list): A list of variables to ignore during splitting. Default is \n",
    "            [\"time\", \"spatial_ref\", \"band\", \"depth\"].\n",
    "        split_type (str): The split type, either \"pixel\" or \"region\". Default is \"pixel\".\n",
    "        test_lats (tuple[float]): The latitude range for the test region. Required for \"region\" split type. \n",
    "            Default is None.\n",
    "        test_lons (tuple[float]): The longitude range for the test region. Required for \"region\" split type. \n",
    "            Default is None.\n",
    "        test_fraction (float): The fraction of data to be used for the test set. Default is 0.2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        tuple: A tuple containing X_train, X_test, y_train, and y_test.\n",
    "    \"\"\"\n",
    "    # generate lists of tuples specifying coordinates to be used for training and testing\n",
    "    train_coordinates, test_coordinates = generate_test_train_coordinates(\n",
    "        xa_ds, split_type, test_lats, test_lons, test_fraction, bath_mask\n",
    "    )\n",
    "\n",
    "    # flatten dataset for row indexing and model training\n",
    "    # compute out dasked chunks, fill Nan values with 0, drop columns which would confuse model\n",
    "    flattened_data = xa_ds.stack(points=(\"latitude\", \"longitude\", \"time\")).compute().to_dataframe().fillna(0).drop(\n",
    "        [\"time\",\"spatial_ref\",\"band\",\"depth\"], axis=1).astype(\"float32\")\n",
    "    \n",
    "    # return train and test rows from dataframe\n",
    "    train_rows = select_rows_by_coordinates(flattened_data, train_coordinates)\n",
    "    test_rows = select_rows_by_coordinates(flattened_data, test_coordinates)\n",
    "\n",
    "    # assign rows to test and train features/labels\n",
    "    X_train, X_test = train_rows.drop(\"gt\", axis=1), test_rows.drop(\"gt\", axis=1)\n",
    "    y_train, y_test = train_rows[\"gt\"], test_rows[\"gt\"]\n",
    "\n",
    "    if data_type == \"discrete\":\n",
    "        y_train, y_test = model_results.threshold_array(y_train), model_results.threshold_array(y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, train_coordinates, test_coordinates\n",
    "\n",
    "\n",
    "def visualise_train_test_split(xa_ds: xa.Dataset, train_coordinates, test_coordinates):\n",
    "    \"\"\"\n",
    "    Visualizes the training and testing regions on a spatial grid.\n",
    "\n",
    "    Parameters:\n",
    "        xa_ds (xarray.Dataset): Input dataset containing spatial grid information.\n",
    "        train_coordinates (list): List of training coordinates as (latitude, longitude) tuples.\n",
    "        test_coordinates (list): List of testing coordinates as (latitude, longitude) tuples.\n",
    "\n",
    "    Returns:\n",
    "        xarray.DataArray: DataArray with the same coordinates and dimensions as xa_ds, where the spatial pixels\n",
    "                          corresponding to training and testing regions are color-coded.\n",
    "    \"\"\"\n",
    "    lat_spacing = xa_ds.latitude.values[1] - xa_ds.latitude.values[0]\n",
    "    lon_spacing = xa_ds.longitude.values[1] - xa_ds.longitude.values[0]\n",
    "\n",
    "    array_shape = tuple(all_data.dims[d] for d in list(all_data.dims))\n",
    "    train_pixs, test_pixs = np.empty(array_shape), np.empty(array_shape)\n",
    "    train_pixs[:] = np.nan\n",
    "    test_pixs[:] = np.nan\n",
    "    # Color the spatial pixels corresponding to training and testing regions\n",
    "    for train_index in tqdm(train_coordinates, desc=\"Coloring in training indices...\"):\n",
    "        row, col = find_index_pair(xa_ds, train_index[0], train_index[1], lat_spacing, lon_spacing)\n",
    "        train_pixs[row,col] = 0\n",
    "\n",
    "    for test_index in tqdm(test_coordinates, desc=\"Coloring in training indices...\"):\n",
    "        row, col = find_index_pair(xa_ds, test_index[0], test_index[1], lat_spacing, lon_spacing)\n",
    "        test_pixs[row,col] = 1\n",
    "\n",
    "    train_test_ds = xa.DataArray(\n",
    "        np.nansum(np.stack((train_pixs,test_pixs)), axis=0),\n",
    "        coords = xa_ds.coords,\n",
    "        dims = xa_ds.dims\n",
    "    )\n",
    "    return train_test_ds\n",
    "\n",
    "\n",
    "def generate_var_mask(xa_d: xa.Dataset | xa.DataArray, var_name: str = \"bathymetry_A\", limits: tuple[float] = [-100, 0], \n",
    "    sub_val: float = np.nan) -> xa.DataArray:\n",
    "    if isinstance(xa_d, xa.DataArray):\n",
    "        return (xa_d >= max(limits)) & (xa_d <= min(limits))\n",
    "    elif isinstance(xa_d, xa.Dataset):\n",
    "        return (xa_d[var_name] <= max(limits)) & (xa_d[var_name] >= min(limits))\n",
    "    else:\n",
    "        raise TypeError(f\"xa_d was neither an xarray Dataset nor a DataArray. Instead type: {type(xa_d)}.\")\n",
    "\n",
    "\n",
    "def plot_train_test_spatial(xa_da: xa.DataArray, figsize: tuple[float,float] = (7,7), bath_mask: xa.DataArray = None):\n",
    "    \"\"\"\n",
    "    Plot two spatial variables from a dataset with different colors and labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset (xarray.Dataset): The dataset containing the variables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots(figsize = figsize, subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "\n",
    "    cmap = spatial_plots.get_cbar()\n",
    "    bounds = [0,0.5,1]\n",
    "    # TODO: fix cmap\n",
    "    # https://matplotlib.org/stable/api/_as_gen/matplotlib.colors.BoundaryNorm.html    \n",
    "    if bath_mask.any():\n",
    "        xa_da = xa_da.where(bath_mask, np.nan)\n",
    "\n",
    "    im = xa_da.isel(time=-1).plot.pcolormesh(ax=ax, cmap = cmap, add_colorbar=False)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(\"Geographical visualisation of train-test split\")\n",
    "    ax.add_feature(\n",
    "        cfeature.NaturalEarthFeature(\n",
    "            \"physical\", \"land\", \"10m\", edgecolor=\"black\", facecolor=\"#cccccc\"\n",
    "        )\n",
    "    )    \n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)\n",
    "    # plt.colorbar(im)\n",
    "    # format categorical colorbar\n",
    "    bounds = [0,0.5,1]\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, 2)\n",
    "    \n",
    "    # calculate the position of the tick labels\n",
    "    min_, max_ = 0,1\n",
    "    positions = [0.25, 0.75]\n",
    "    val_lookup = dict(zip(positions, [\"train\", \"test\"]))\n",
    "\n",
    "    def formatter_func(x, pos):\n",
    "        'The two args are the value and tick position'\n",
    "        val = val_lookup[x]\n",
    "        return str(val)\n",
    "\n",
    "    formatter = plt.FuncFormatter(formatter_func)\n",
    "    fig.colorbar(ax=ax, mappable=mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "        ticks=positions, format=formatter, spacing='proportional', pad=0.1, fraction=0.046);\n",
    "    return xa_da\n",
    "\n",
    "    \n",
    "\n",
    "def generate_reproducing_metrics_at_different_resolutions(resolutions: list[float], units: list[str]) -> xa.Dataset:\n",
    "\n",
    "    target_resolutions = [spatial_data.choose_resolution(number, string)[1] for number, string in zip(resolutions, units)]\n",
    "\n",
    "\n",
    "    for res in tqdm(target_resolutions, total=len(target_resolutions), desc=\"Processing metrics at various resolutions\"):\n",
    "        \n",
    "        files_dir = directories.get_comparison_dir() / utils.replace_dot_with_dash(f\"{res:.05f}d_arrays\")\n",
    "        files = file_ops.return_list_filepaths(files_dir, \".nc\")\n",
    "        xa_ds_dict = {}\n",
    "\n",
    "        for fl in files:\n",
    "            name = (fl.stem).split(\"_\")[0]\n",
    "            ds = xa.open_dataset(fl).rio.write_crs(\"epsg:4326\")\n",
    "            variable_name = next((var_name for var_name in ds.data_vars if var_name != \"spatial_ref\"), None)\n",
    "            xa_ds_dict[name] = ds[variable_name]\n",
    "\n",
    "        generate_reproducing_metrics(xa_ds_dict, res)\n",
    "        \n",
    "\n",
    "def calc_weighted_mean(xa_da_daily_means: xa.DataArray, period: str):\n",
    "    \"\"\"\n",
    "    Calculates the weighted mean of daily means for a given period.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xa_da_daily_means (xarray.DataArray): The input xarray DataArray of daily means.\n",
    "    period (str): The time period for grouping (e.g., 'year', 'month', 'week').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray: The weighted mean values for the given period.\n",
    "    \"\"\"\n",
    "    group, offset = baselines.return_time_grouping_offset(period)\n",
    "    # determine original crs\n",
    "    crs = xa_da_daily_means.rio.crs\n",
    "\n",
    "    # Determine the month length (has no effect on other time periods)\n",
    "    month_length = xa_da_daily_means.time.dt.days_in_month\n",
    "    # Calculate the monthly weights\n",
    "    weights = month_length.groupby(group) / month_length.groupby(group).sum()\n",
    "\n",
    "    # Setup our masking for nan values\n",
    "    ones = xa.where(xa_da_daily_means.isnull(), 0.0, 1.0)\n",
    "\n",
    "    # Calculate the numerator\n",
    "    xa_da_daily_means_sum = (\n",
    "        (xa_da_daily_means * weights).resample(time=offset).sum(dim=\"time\")\n",
    "    )\n",
    "    # Calculate the denominator\n",
    "    ones_out = (ones * weights).resample(time=offset).sum(dim=\"time\")\n",
    "\n",
    "    # weighted average\n",
    "    return (xa_da_daily_means_sum / ones_out).rio.write_crs(crs, inplace=True)\n",
    "\n",
    "\n",
    "def calc_timeseries_params(xa_da_daily_means: xa.DataArray, period: str, param: str):\n",
    "    \"\"\"\n",
    "    Calculates time series parameters (mean, standard deviation, min, max) for a given period.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xa_da_daily_means (xarray.DataArray): The input xarray DataArray of daily means.\n",
    "    period (str): The time period for grouping (e.g., 'year', 'month', 'week').\n",
    "    param (str): The parameter name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray, xarray.DataArray, tuple(xarray.DataArray, xarray.DataArray): The weighted average,\n",
    "        standard deviation, and (min, max) values for the given period.\n",
    "    \"\"\"\n",
    "    # determine original crs\n",
    "    crs = xa_da_daily_means.rio.crs\n",
    "\n",
    "    base_name = f\"{param}_{period}_\"\n",
    "    # weighted average\n",
    "    weighted_av = calc_weighted_mean(xa_da_daily_means, period)\n",
    "\n",
    "    weighted_av = weighted_av.rename(\n",
    "        base_name + \"mean\"\n",
    "    )\n",
    "    # standard deviation of weighted averages\n",
    "    stdev = (\n",
    "        weighted_av.std(dim=\"time\", skipna=True)\n",
    "        .rename(base_name + \"std\")\n",
    "        .rio.write_crs(crs, inplace=True)\n",
    "    )\n",
    "    # max and min\n",
    "    min = (\n",
    "        xa_da_daily_means.min(dim=\"time\", skipna=True)\n",
    "        .rename(base_name + \"min\")\n",
    "        .rio.write_crs(crs, inplace=True)\n",
    "    )\n",
    "    max = (\n",
    "        xa_da_daily_means.max(dim=\"time\", skipna=True)\n",
    "        .rename(base_name + \"max\")\n",
    "        .rio.write_crs(crs, inplace=True)\n",
    "    )\n",
    "\n",
    "    # Return the weighted average\n",
    "    return weighted_av, stdev, (min, max)\n",
    "\n",
    "\n",
    "\n",
    "def generate_reproducing_metrics(resampled_xa_das_dict: dict, target_resolution: float = None) -> xa.Dataset:\n",
    "    \"\"\"\n",
    "    Generate metrics used in Couce et al (2013, 2023) based on the upsampled xarray DataArrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        resampled_xa_das_dict (dict): A dictionary containing the upsampled xarray DataArrays.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        xa.Dataset: An xarray Dataset containing the reproduced metrics.\n",
    "    \"\"\"\n",
    "    if target_resolution:\n",
    "        resolution = target_resolution\n",
    "    else:\n",
    "        resolution = np.mean(spatial_data.calculate_spatial_resolution(resampled_xa_das_dict[\"ssr\"]))\n",
    "\n",
    "    res_string = f\"{resolution:.05f}d\"\n",
    "    filename = utils.replace_dot_with_dash(f\"{res_string}_arrays/all_{res_string}_comparative\")\n",
    "    save_path = (directories.get_comparison_dir() / filename).with_suffix(\".nc\")\n",
    "\n",
    "    if not save_path.is_file():\n",
    "        ### TEMPERATURE\n",
    "        thetao_daily = resampled_xa_das_dict[\"thetao\"]\n",
    "        # annual average, stdev of annual averages, annual minimum, annual maximum\n",
    "        thetao_annual_average, _, (thetao_annual_min, thetao_annual_max) = calc_timeseries_params(thetao_daily, \"y\", \"thetao\")\n",
    "        # monthly average, stdev of monthly averages, monthly minimum, monthly maximum\n",
    "        thetao_monthly_average, thetao_monthly_stdev, (thetao_monthly_min, thetao_monthly_max) = baselines.calc_timeseries_params(\n",
    "            thetao_daily, \"m\", \"thetao\")\n",
    "        # annual range (monthly max - monthly min)\n",
    "        thetao_annual_range = (thetao_annual_max - thetao_annual_min).rename(\"thetao_annual_range\")\n",
    "        # weekly minimum, weekly maximum\n",
    "        _, _, (thetao_weekly_min, thetao_weekly_max) = baselines.calc_timeseries_params(thetao_daily, \"w\", \"thetao\")\n",
    "        print(\"Generated thetao data.\")\n",
    "\n",
    "        ### SALINITY\n",
    "        salinity_daily = resampled_xa_das_dict[\"so\"]\n",
    "        # annual average\n",
    "        salinity_annual_average, _, _ = baselines.calc_timeseries_params(salinity_daily, \"y\", \"salinity\")\n",
    "        # monthly min, monthly max\n",
    "        _, _, (salinity_monthly_min, salinity_monthly_max) = baselines.calc_timeseries_params(salinity_daily, \"m\", \"salinity\")\n",
    "        print(\"Generated so data\")\n",
    "\n",
    "        ### CURRENT\n",
    "        current_daily = resampled_xa_das_dict[\"current\"]\n",
    "        # annual average\n",
    "        current_annual_average, _, _ = baselines.calc_timeseries_params(current_daily, \"y\", \"current\")\n",
    "        # monthly min, monthly max\n",
    "        _, _, (current_monthly_min, current_monthly_max) = baselines.calc_timeseries_params(current_daily, \"m\", \"current\")\n",
    "        print(\"Generated current data\")\n",
    "\n",
    "        ### BATHYMETRY\n",
    "        bathymetry_climate_res = resampled_xa_das_dict[\"bathymetry\"]\n",
    "        # bathymetry_climate_res = spatial_data.upsample_xa_d_to_other(bathymetry, thetao_annual_average, name = \"bathymetry\")\n",
    "        print(\"Generated bathymetry data\")\n",
    "\n",
    "        ### ERA5\n",
    "        solar_daily = resampled_xa_das_dict[\"ssr\"]\n",
    "        # annual average\n",
    "        solar_annual_average, _, _ = baselines.calc_timeseries_params(solar_daily, \"y\", \"net_solar\")\n",
    "        # monthly min, monthly max\n",
    "        _, _, (solar_monthly_min, solar_monthly_max) = baselines.calc_timeseries_params(solar_daily, \"m\", \"net_solar\")\n",
    "        print(\"Generated solar data\")\n",
    "\n",
    "        ### GT\n",
    "        gt_climate_res = resampled_xa_das_dict[\"gt\"]\n",
    "        # upsample to same resolution as climate (1/12 of a degree)\n",
    "        # gt_climate_res = spatial_data.upsample_xa_d_to_other(gt_1000m, thetao_annual_average, name = \"gt\")\n",
    "        print(\"Generated ground truth data\")\n",
    "\n",
    "        merge_list = [thetao_annual_average, thetao_annual_range, thetao_monthly_min, thetao_monthly_max, \n",
    "            thetao_monthly_stdev, thetao_weekly_min, thetao_weekly_max, \n",
    "            salinity_annual_average, salinity_monthly_min, salinity_monthly_max,\n",
    "            current_annual_average, current_monthly_min, current_monthly_max,\n",
    "            solar_annual_average, solar_monthly_min, solar_monthly_max,\n",
    "            gt_climate_res, bathymetry_climate_res\n",
    "            ]\n",
    "        for xa_da in merge_list:\n",
    "            if \"grid_mapping\" in xa_da.attrs:\n",
    "                del xa_da.attrs[\"grid_mapping\"]\n",
    "        ### MERGE\n",
    "        merged = xa.merge(merge_list)\n",
    "        merged.to_netcdf(save_path)\n",
    "        return merged\n",
    "\n",
    "    else:\n",
    "        print(f\"{save_path} already exists.\")\n",
    "        return xa.open_dataset(save_path)\n",
    "\n",
    "\n",
    "def resample_list_xa_ds_to_target_res_and_save(xa_das: list[xa.DataArray], target_resolution_d: float, \n",
    "    unit: str = \"m\", lat_lims: tuple[float] = (-10,-17), lon_lims: tuple[float] = (142,147)) -> None:\n",
    "    \"\"\"\n",
    "    Resamples a list of xarray DataArrays to a target resolution, and saves the resampled DataArrays to NetCDF files.\n",
    "\n",
    "    Args:\n",
    "        xa_das (list[xa.DataArray]): A list of xarray DataArrays to be resampled.\n",
    "        target_resolution_d (float): The target resolution in degrees or meters, depending on the unit specified.\n",
    "        unit (str, optional): The unit of the target resolution. Defaults to \"m\".\n",
    "        lat_lims (tuple[float], optional): Latitude limits for the dummy DataArray used for resampling. Defaults to (-10, -17).\n",
    "        lon_lims (tuple[float], optional): Longitude limits for the dummy DataArray used for resampling. Defaults to (142, 147).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    dummy_xa = spatial_data.generate_dummy_xa(target_resolution_d, lat_lims, lon_lims)\n",
    "\n",
    "    save_dir = file_ops.generate_filepath(\n",
    "        (directories.get_comparison_dir() / utils.replace_dot_with_dash(f\"{target_resolution_d:.05f}d_arrays\")))\n",
    "\n",
    "    for xa_da in tqdm(xa_das, desc = f\"Resampling xarray DataArrays to {target_resolution_d:.05f}d\", position=1, leave=True):\n",
    "        filename = utils.replace_dot_with_dash(f\"{xa_da.name}_{target_resolution_d:.05f}d\")\n",
    "        save_path = (save_dir / filename).with_suffix(\".nc\")\n",
    "\n",
    "        if not save_path.is_file():\n",
    "            xa_resampled = spatial_data.process_xa_d(\n",
    "                spatial_data.upsample_xa_d_to_other(spatial_data.process_xa_d(xa_da), dummy_xa, name=xa_da.name))\n",
    "            # causes problems with saving\n",
    "            if \"grid_mapping\" in xa_resampled.attrs:\n",
    "                del xa_resampled.attrs[\"grid_mapping\"]\n",
    "\n",
    "            xa_resampled.to_netcdf(save_path)\n",
    "        else:\n",
    "            print(f\"{filename} already exists in {save_dir}\")\n",
    "\n",
    "\n",
    "def resample_list_xa_ds_to_target_res_list_and_save(xa_das: list[xa.DataArray], target_resolutions: list[float], \n",
    "    units: list[str], lat_lims: tuple[float] = (-10,-17), lon_lims: tuple[float] = (142,147)) -> None:\n",
    "    \"\"\"\n",
    "    Resamples a list of xarray DataArrays to multiple target resolutions specified in a list, and saves the resampled \n",
    "    DataArrays to NetCDF files.\n",
    "\n",
    "    Args:\n",
    "        xa_das (list[xa.DataArray]): A list of xarray DataArrays to be resampled.\n",
    "        target_resolutions (list[float]): A list of target resolutions in degrees or meters, depending on the units specified.\n",
    "        units (list[str]): A list of units corresponding to the target resolutions.\n",
    "        lat_lims (tuple[float], optional): Latitude limits for the dummy DataArray used for resampling. Defaults to (-10, -17).\n",
    "        lon_lims (tuple[float], optional): Longitude limits for the dummy DataArray used for resampling. Defaults to (142, 147).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    target_resolutions = [spatial_data.choose_resolution(number, string)[1] for number, string in zip(resolutions, units)]\n",
    "    for i, resolution in tqdm(enumerate(target_resolutions), desc = \"Progress through resolutions\", position=0, leave=True, total=len(target_resolutions)):\n",
    "        unit = units[i]\n",
    "        resample_list_xa_ds_to_target_res_and_save(xa_das, resolution, unit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = [1,  0.5, 0.25, 1/12, 4000]\n",
    "units = [\"d\", \"d\", \"d\", \"d\", \"m\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_list = load_and_process_reproducing_xa_das()\n",
    "resample_list_xa_ds_to_target_res_list_and_save(xa_list, resolutions, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_reproducing_metrics_at_different_resolutions(resolutions, units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twelve = xa.open_dataset(directories.get_comparison_dir() / \"0-03691d_arrays/all_0-03691d_comparative.nc\")\n",
    "twelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twelve[\"thetao_annual_range\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_varied_data_resolutions(resolutions: list[float], xa_list: list[xa.DataArray]):\n",
    "#     for res in tqdm(resolutions, desc=\"Generating various resolution xa.Datasets\"):\n",
    "#         save_path = (directories.get_comparison_dir() / f\"all_{res:.05f}d\").with_suffix(\".nc\")\n",
    "#         if not save_path.exists():\n",
    "#             resampled_xa_das_dict = resample_list_xa_ds_to_target_resolution_and_merge(xa_list, target_resolution=res, unit=\"m\")\n",
    "#             all = xa.merge(list(resampled_xa_das_dict.values()))\n",
    "#             all.to_netcdf(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list(resampled_xa_das_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_list = load_and_process_reproducing_xa_das()\n",
    "# resampled_xa_das_dict = resample_list_xa_ds_to_target_resolution_and_merge(xa_list, target_resolution=4000, unit=\"m\")\n",
    "# all_4km = generate_reproducing_metrics(resampled_xa_das_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resample_train_predict(data_):\n",
    "\n",
    "import time\n",
    "\n",
    "def create_train_metadata(name: str, model_path: Path | str, model_type: str, data_type: str, \n",
    "    randomised_search_time: float, fit_time: float, test_fraction: float, features: list[str], resolution: float) -> None:\n",
    "    metadata = {\n",
    "        \"model name\": name,\n",
    "        \"model path\": str(model_path),\n",
    "        \"model type\": model_type,\n",
    "        \"data type\": data_type,\n",
    "        \"hyperparameter tune time\": randomised_search_time,\n",
    "        \"model fit time (s)\": fit_time,\n",
    "        \"test fraction\": test_fraction,\n",
    "        \"features\": features,\n",
    "        \"approximate spatial resolution\": resolution\n",
    "    }\n",
    "    out_path = Path(model_path).parent / f\"{name}_metadata.json\"\n",
    "    out_file = open(out_path, \"w\")\n",
    "    json.dump(metadata, out_file, indent=4) \n",
    "    print(f\"{name} metadata saved to {out_path}\")\n",
    "\n",
    "\n",
    "def initialise_model(model_type: str, random_state: int = 42):\n",
    "\n",
    "    # continuous models\n",
    "    data_type = \"continuous\"\n",
    "    if model_type == \"rf_reg\":\n",
    "        model = RandomForestRegressor(random_state=random_state)\n",
    "        search_grid = rf_search_grid() \n",
    "    elif model_type == \"brt\":\n",
    "        model = GradientBoostingRegressor(random_state=random_state)\n",
    "        search_grid = boosted_regression_search_grid()\n",
    "\n",
    "    # discrete models\n",
    "    elif model_type == \"maxent\":\n",
    "        model = LogisticRegression(random_state=random_state)\n",
    "        data_type = \"discrete\"\n",
    "        search_grid = maximum_entropy_search_grid()\n",
    "    elif model_type == \"rf_cla\":\n",
    "        model = RandomForestClassifier(random_state=random_state)\n",
    "        data_type = \"discrete\"\n",
    "        search_grid = rf_search_grid()\n",
    "\n",
    "    return model, data_type, search_grid\n",
    "\n",
    "\n",
    "def train_test_visualise_roc(all_data: xa.Dataset, model_type: str, name: str = \"_\", runs_n: int = 10, \n",
    "    test_fraction: float = 0.25, save_dir: Path | str = None):\n",
    "\n",
    "    model, data_type, search_grid = initialise_model(model_type)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, train_coordinates, test_coordinates = spatial_split_train_test(\n",
    "        all_data, \"gt\", data_type=\"discrete\", split_type=\"pixel\", test_fraction = test_fraction)\n",
    "    \n",
    "    if data_type == \"discrete\":\n",
    "        y_train, y_test = model_results.threshold_array(y_train), model_results.threshold_array(y_test)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_random = RandomizedSearchCV(\n",
    "        estimator = model, param_distributions = search_grid, n_iter = 100, cv = 5, verbose=2, \n",
    "        random_state=42, n_jobs = -1)\n",
    "    end_time = time.time()\n",
    "    randomised_search_time = end_time-start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_random.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    fit_time = end_time-start_time\n",
    "\n",
    "    resolution = np.mean(spatial_data.calculate_spatial_resolution(all_data))\n",
    "\n",
    "    # save best parameters\n",
    "    if not save_dir:\n",
    "        save_dir = file_ops.guarantee_existence(directories.get_datasets_dir() / \"model_params\")\n",
    "\n",
    "    save_path = save_sklearn_model(model_random, save_dir, name)\n",
    "    create_train_metadata(\n",
    "        name = name,\n",
    "        model_path = save_path,\n",
    "        model_type = model_type,\n",
    "        data_type = data_type,\n",
    "        randomised_search_time = randomised_search_time,\n",
    "        fit_time = fit_time,\n",
    "        test_fraction = test_fraction,\n",
    "        features = list(all_data.data_vars),\n",
    "        resolution = resolution\n",
    "    )\n",
    "    # test\n",
    "    run_outcomes = n_random_runs_preds(\n",
    "        model = model_random, data_type = data_type, runs_n = 10, xa_ds = all_data, test_fraction = test_fraction)\n",
    "\n",
    "    return run_outcomes\n",
    "\n",
    "\n",
    "def train_test_visualise_roc_across_resolutions(model_type: str, d_resolutions: list[float], \n",
    "    runs_n: int = 10, test_fraction: float = 0.25):\n",
    "\n",
    "    resolutions_dict = {}\n",
    "    for res in tqdm(d_resolutions, desc=\"Training models at different resolutions\"):\n",
    "        # load in correct-resolution dataset\n",
    "        res_string = utils.replace_dot_with_dash(f\"{res:.05f}d\")\n",
    "        dir = directories.get_comparison_dir() / f\"{res_string}_arrays\"\n",
    "        filename = f\"all_{res_string}_comparative\"\n",
    "        comparison_file = (dir / filename).with_suffix(\".nc\")\n",
    "        all_data = xa.open_dataset(comparison_file)\n",
    "\n",
    "        run_outcomes = train_test_visualise_roc(all_data,\n",
    "            model_type=model_type, \n",
    "            name=f\"{model_type}_{res_string}\",\n",
    "            runs_n = runs_n, test_fraction = test_fraction)\n",
    "\n",
    "        resolutions_dict[f\"{res:.05f}\"] = run_outcomes\n",
    "\n",
    "    return resolutions_dict\n",
    "\n",
    "\n",
    "def train_test_across_models(model_types: list[str], d_resolution: float = 0.03691):\n",
    "    model_comp_dir = file_ops.guarantee_existence(directories.get_datasets_dir() / \"model_params/best_models\")\n",
    "\n",
    "    res_string = utils.replace_dot_with_dash(f\"{d_resolution:.05f}d\")\n",
    "    all_data_dir = directories.get_comparison_dir() / f\"{res_string}_arrays\"\n",
    "    all_data_name = f\"all_{res_string}_comparative\" \n",
    "    all_data = xa.open_dataset((all_data_dir / all_data_name).with_suffix(\".nc\"))\n",
    "\n",
    "    all_model_outcomes = []\n",
    "    for model in tqdm(model_types, total=len(model_types), desc = \"Fitting each model via random search\"):\n",
    "        run_outcomes = train_test_visualise_roc(\n",
    "            all_data = all_data, \n",
    "            model_type=model, \n",
    "            save_dir = model_comp_dir,\n",
    "            name=f\"{model}_{res_string}_tuned\",\n",
    "            runs_n = 10, test_fraction = 0.25)\n",
    "        all_model_outcomes.append(run_outcomes)\n",
    "\n",
    "    return all_model_outcomes\n",
    "\n",
    "\n",
    "\n",
    "def rf_search_grid(\n",
    "    estimator_lims: tuple[int] = (200,2000), \n",
    "    max_features: list[str] = ['auto', 'sqrt'], \n",
    "    max_depth_lims: tuple[int] = (10,110),\n",
    "    min_samples_split: list[int] = [2, 5, 10], \n",
    "    min_samples_leaf: list[int] = [1, 2, 4],\n",
    "    bootstrap: list[bool] = [True, False]) -> dict:\n",
    "\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = min(estimator_lims), stop = max(estimator_lims), num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = max_features\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(min(max_depth_lims), max(max_depth_lims), num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = min_samples_split\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = min_samples_leaf\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = bootstrap\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap}\n",
    "    return random_grid\n",
    "\n",
    "\n",
    "def boosted_regression_search_grid(\n",
    "    n_estimators_lims: tuple[int] = (100, 2000),\n",
    "    learning_rate_lims: tuple[float] = (0.001, 1.0),\n",
    "    max_depth_lims: tuple[int] = (1, 10),\n",
    "    min_samples_split: list[int] = [2, 5, 10],\n",
    "    min_samples_leaf: list[int] = [1, 2, 4],\n",
    "    max_features: list[str] = ['auto', 'sqrt'],\n",
    "    loss: list[str] = ['ls', 'lad', 'huber', 'quantile'],\n",
    "    subsample_lims: tuple[float] = (0.1, 1.0),\n",
    "    criterion: list[str] = ['friedman_mse', 'mse'],\n",
    ") -> dict:\n",
    "\n",
    "    # Number of trees in the ensemble\n",
    "    n_estimators = [int(x) for x in np.linspace(start=min(n_estimators_lims), stop=max(n_estimators_lims), num=10)]\n",
    "    # Learning rate (shrinkage)\n",
    "    learning_rate = np.logspace(*np.log10(learning_rate_lims), num=10).tolist()\n",
    "    # Maximum depth of each tree\n",
    "    max_depth = [int(x) for x in np.linspace(start=min(max_depth_lims), stop=max(max_depth_lims), num=10)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = min_samples_split\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = min_samples_leaf\n",
    "    # Maximum number of features to consider at each split\n",
    "    max_features = max_features\n",
    "    # Loss function to optimize\n",
    "    loss = loss\n",
    "    # Fraction of samples to be used for training each tree\n",
    "    subsample = np.linspace(start=subsample_lims[0], stop=subsample_lims[1], num=10).tolist()\n",
    "    # Splitting criterion\n",
    "    criterion = criterion\n",
    "\n",
    "    # Create the random grid\n",
    "    random_grid = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'learning_rate': learning_rate,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'max_features': max_features,\n",
    "        'loss': loss,\n",
    "        'subsample': subsample,\n",
    "        'criterion': criterion,\n",
    "    }\n",
    "    return random_grid\n",
    "\n",
    "\n",
    "def maximum_entropy_search_grid(\n",
    "    penalty: list[str] = ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    dual: list[bool] = [True, False],\n",
    "    tol: list[float] = [1e-4, 1e-3, 1e-2],\n",
    "    C: list[float] = [0.1, 1.0, 10.0],\n",
    "    fit_intercept: list[bool] = [True, False],\n",
    "    intercept_scaling: list[float] = [1.0, 2.0, 5.0],\n",
    "    solver: list[str] = ['sag', 'saga',\"newton-cholesky\"],\n",
    "    max_iter: list[int] = [100, 200, 500],\n",
    "    multi_class: list[str] = ['auto', 'ovr', 'multinomial'],\n",
    "    verbose: list[int] = [0, 1, 2],\n",
    "    warm_start: list[bool] = [True, False],\n",
    "    ) -> dict:\n",
    "    \n",
    "    # Regularization penalty\n",
    "    penalty = penalty\n",
    "    # Dual formulation\n",
    "    dual = dual\n",
    "    # Convergence tolerance\n",
    "    tol = tol\n",
    "    # Inverse of regularization strength\n",
    "    C = C\n",
    "    # Fit intercept\n",
    "    fit_intercept = fit_intercept\n",
    "    # Intercept scaling\n",
    "    intercept_scaling = intercept_scaling\n",
    "    # Solver algorithm\n",
    "    solver = solver\n",
    "    # Maximum number of iterations\n",
    "    max_iter = max_iter\n",
    "    # Multi-class option\n",
    "    multi_class = multi_class\n",
    "    # Verbosity level\n",
    "    verbose = verbose\n",
    "    # Warm start\n",
    "    warm_start = warm_start\n",
    "\n",
    "\n",
    "    # Create the random grid\n",
    "    random_grid = {\n",
    "        'penalty': penalty,\n",
    "        'dual': dual,\n",
    "        'tol': tol,\n",
    "        'C': C,\n",
    "        'fit_intercept': fit_intercept,\n",
    "        'intercept_scaling': intercept_scaling,\n",
    "        'solver': solver,\n",
    "        'max_iter': max_iter,\n",
    "        'multi_class': multi_class,\n",
    "        'verbose': verbose,\n",
    "        'warm_start': warm_start,\n",
    "    }\n",
    "    \n",
    "    return random_grid\n",
    "\n",
    "\n",
    "def n_random_runs_preds(model, runs_n, xa_ds, data_type: str = \"continuous\", test_fraction: float=0.25, \n",
    "    bath_mask: bool=True) -> list[tuple[list]]:\n",
    "    \"\"\"\n",
    "    Perform multiple random test runs for inference using a model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        model: The model used for inference.\n",
    "        runs_n: The number of random test runs.\n",
    "        xa_ds: The xarray Dataset containing the data.\n",
    "        test_fraction (optional): The fraction of data to use for testing. Defaults to 0.25.\n",
    "        bath_mask (optional): Whether to apply a bathymetry mask during splitting. Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        run_outcomes: A list of tuples containing the true labels and predicted values for each test run.\n",
    "    \"\"\"\n",
    "    # TODO: allow spatial splitting, perhaps using **kwarg functionality to declare lat/lon limits\n",
    "    # prediction_list = []\n",
    "    run_outcomes = []\n",
    "    for run in tqdm(range(runs_n), desc=f\" Running inference on {runs_n} randomly-initialised test splits with {test_fraction} test fraction\"):\n",
    "        # randomly select test data\n",
    "        _, X_test, _, y_test,_,_ = spatial_split_train_test(\n",
    "            xa_ds, data_type = data_type, test_fraction=test_fraction, bath_mask=bath_mask)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        run_outcomes.append((y_test, pred))\n",
    "\n",
    "    return run_outcomes\n",
    "\n",
    "\n",
    "def rocs_n_runs(run_outcomes: tuple[list[float]], binarize_threshold: float=0, figsize=[7, 7]):\n",
    "    \"\"\"\n",
    "    Plot ROC curves for multiple random test runs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        run_outcomes: A list of tuples containing the true labels and predicted values for each test run.\n",
    "        binarize_threshold (optional): The threshold value for binarizing the labels. Defaults to 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    color_map = spatial_plots.get_cbar(\"seq\")\n",
    "    num_colors = len(run_outcomes)\n",
    "    colors = [color_map(i / num_colors) for i in range(num_colors)]\n",
    "\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    for c, outcome in enumerate(run_outcomes):\n",
    "        # cast regression to binary classification for plotting\n",
    "        binary_y_labels, binary_predictions = model_results.threshold_label(outcome[0], outcome[1], binarize_threshold)\n",
    "\n",
    "        fpr, tpr, _ = sklmetrics.roc_curve(binary_y_labels, binary_predictions, drop_intermediate=False)\n",
    "        roc_auc = sklmetrics.auc(fpr, tpr)\n",
    "\n",
    "        label = f\"{roc_auc:.02f}\"\n",
    "        ax.plot(fpr, tpr, label=label, color=colors[c])\n",
    "\n",
    "    n_runs = len(run_outcomes)\n",
    "    # format\n",
    "    format_roc(\n",
    "        ax=ax, title=f\"Receiver Operating Characteristic (ROC) Curve\\n for {n_runs} randomly initialised test datasets.\")\n",
    "\n",
    "def save_sklearn_model(model, savedir: Path | str, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Save a scikit-learn model to a file using pickle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : object\n",
    "        The scikit-learn model object to be saved.\n",
    "    savedir : Union[pathlib.Path, str]\n",
    "        The directory path where the model file should be saved.\n",
    "    filename : str\n",
    "        The name of the model file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    save_path = (Path(savedir) / filename).with_suffix(\".pickle\")\n",
    "\n",
    "    if not save_path.is_file():\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"Saved model to {save_path}.\")\n",
    "    else:\n",
    "        print(f\"{save_path} already exists.\")\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(directories.get_datasets_dir() / \"model_params/all_0-03691d_comparative_10_runs_0.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0.5, 0.25, 0.08333333333333333]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolutions = [1,  0.5, 0.25, 1/12]\n",
    "units = [\"d\", \"d\", \"d\", \"d\"]\n",
    "\n",
    "target_resolutions = [spatial_data.choose_resolution(number, string)[1] for number, string in zip(resolutions, units)]\n",
    "target_resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting each model via random search:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=100, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=100, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=100, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=100, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.0021544346900318843, loss=huber, max_depth=2, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1155, subsample=0.9; total time=   2.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.0021544346900318843, loss=huber, max_depth=2, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1155, subsample=0.9; total time=   2.3s\n",
      "max_iter reached after 0 seconds\n",
      "[CV] END C=0.1, dual=False, fit_intercept=True, intercept_scaling=5.0, max_iter=100, multi_class=ovr, penalty=l1, solver=saga, tol=0.001, verbose=1, warm_start=False; total time=   0.0s\n",
      "Epoch 1, change: 1.00000000\n",
      "Epoch 2, change: 0.42350775\n",
      "Epoch 3, change: 0.31328133\n",
      "Epoch 4, change: 0.18634559\n",
      "Epoch 5, change: 0.18644336\n",
      "Epoch 6, change: 0.16809173\n",
      "Epoch 7, change: 0.09855399\n",
      "Epoch 8, change: 0.11020520\n",
      "Epoch 9, change: 0.08377609\n",
      "Epoch 10, change: 0.07902234\n",
      "Epoch 11, change: 0.06893109\n",
      "Epoch 12, change: 0.06323761\n",
      "Epoch 13, change: 0.05707201\n",
      "Epoch 14, change: 0.05203758\n",
      "Epoch 15, change: 0.04700650\n",
      "Epoch 16, change: 0.04353761\n",
      "Epoch 17, change: 0.04114490\n",
      "Epoch 18, change: 0.03610978\n",
      "Epoch 19, change: 0.03428204\n",
      "Epoch 20, change: 0.03187509\n",
      "Epoch 21, change: 0.03014293\n",
      "Epoch 22, change: 0.02797773\n",
      "Epoch 23, change: 0.02634699\n",
      "Epoch 24, change: 0.02400035\n",
      "Epoch 25, change: 0.02282718\n",
      "Epoch 26, change: 0.02165375\n",
      "Epoch 27, change: 0.02014449\n",
      "Epoch 28, change: 0.01942680\n",
      "Epoch 29, change: 0.01832856\n",
      "Epoch 30, change: 0.01685926\n",
      "Epoch 31, change: 0.01611883\n",
      "Epoch 32, change: 0.01549449\n",
      "Epoch 33, change: 0.01459281\n",
      "Epoch 34, change: 0.01352480\n",
      "Epoch 35, change: 0.01316154\n",
      "Epoch 36, change: 0.01241271\n",
      "Epoch 37, change: 0.01185682\n",
      "Epoch 38, change: 0.01119889\n",
      "Epoch 39, change: 0.01077997\n",
      "Epoch 40, change: 0.01035722\n",
      "Epoch 41, change: 0.00975012\n",
      "Epoch 42, change: 0.00914212\n",
      "Epoch 43, change: 0.00888343\n",
      "Epoch 44, change: 0.00849416\n",
      "Epoch 45, change: 0.00804874\n",
      "Epoch 46, change: 0.00774853\n",
      "Epoch 47, change: 0.00741703\n",
      "Epoch 48, change: 0.00700792\n",
      "Epoch 49, change: 0.00679684\n",
      "Epoch 50, change: 0.00631897\n",
      "Epoch 51, change: 0.00625865\n",
      "Epoch 52, change: 0.00588684\n",
      "Epoch 53, change: 0.00568618\n",
      "Epoch 54, change: 0.00543773\n",
      "Epoch 55, change: 0.00526956\n",
      "Epoch 56, change: 0.00476275\n",
      "Epoch 57, change: 0.00494126\n",
      "Epoch 58, change: 0.00458739\n",
      "Epoch 59, change: 0.00446307\n",
      "Epoch 60, change: 0.00434033\n",
      "Epoch 61, change: 0.00432244\n",
      "Epoch 62, change: 0.00430441\n",
      "Epoch 63, change: 0.00428899\n",
      "Epoch 64, change: 0.00427328\n",
      "Epoch 65, change: 0.00425849\n",
      "Epoch 66, change: 0.00424355\n",
      "Epoch 67, change: 0.00423135\n",
      "Epoch 68, change: 0.00421747\n",
      "Epoch 69, change: 0.00420634\n",
      "Epoch 70, change: 0.00419413\n",
      "Epoch 71, change: 0.00418254\n",
      "Epoch 72, change: 0.00417220\n",
      "Epoch 73, change: 0.00416708\n",
      "Epoch 74, change: 0.00415795\n",
      "Epoch 75, change: 0.00415704\n",
      "Epoch 76, change: 0.00414797\n",
      "Epoch 77, change: 0.00413869\n",
      "Epoch 78, change: 0.00413004\n",
      "Epoch 79, change: 0.00412158\n",
      "Epoch 80, change: 0.00411491\n",
      "Epoch 81, change: 0.00410686\n",
      "Epoch 82, change: 0.00409911\n",
      "Epoch 83, change: 0.00409231\n",
      "Epoch 84, change: 0.00408594\n",
      "Epoch 85, change: 0.00407937\n",
      "Epoch 86, change: 0.00407320\n",
      "Epoch 87, change: 0.00406744\n",
      "Epoch 88, change: 0.00406143\n",
      "Epoch 89, change: 0.00405621\n",
      "Epoch 90, change: 0.00405055\n",
      "Epoch 91, change: 0.00404565\n",
      "Epoch 92, change: 0.00404118\n",
      "Epoch 93, change: 0.00403622\n",
      "Epoch 94, change: 0.00403195\n",
      "Epoch 95, change: 0.00402773\n",
      "Epoch 96, change: 0.00402325\n",
      "Epoch 97, change: 0.00401925\n",
      "Epoch 98, change: 0.00401554\n",
      "Epoch 99, change: 0.00401153\n",
      "Epoch 100, change: 0.00400877\n",
      "max_iter reached after 0 seconds\n",
      "[CV] END C=0.1, dual=False, fit_intercept=True, intercept_scaling=5.0, max_iter=100, multi_class=ovr, penalty=l1, solver=saga, tol=0.001, verbose=1, warm_start=False; total time=   0.0s\n",
      "Epoch 1, change: 1.00000000\n",
      "Epoch 2, change: 0.41224930\n",
      "Epoch 3, change: 0.25941589\n",
      "Epoch 4, change: 0.18233575\n",
      "Epoch 5, change: 0.14815055\n",
      "Epoch 6, change: 0.13086307\n",
      "Epoch 7, change: 0.11289013\n",
      "Epoch 8, change: 0.10335766\n",
      "Epoch 9, change: 0.09176413\n",
      "Epoch 10, change: 0.08339030\n",
      "Epoch 11, change: 0.07599565\n",
      "Epoch 12, change: 0.06949148\n",
      "Epoch 13, change: 0.06460339\n",
      "Epoch 14, change: 0.05991356\n",
      "Epoch 15, change: 0.05564969\n",
      "Epoch 16, change: 0.05219438\n",
      "Epoch 17, change: 0.04907429\n",
      "Epoch 18, change: 0.04613144\n",
      "Epoch 19, change: 0.04357505\n",
      "Epoch 20, change: 0.04124903\n",
      "Epoch 21, change: 0.03908349\n",
      "Epoch 22, change: 0.03729152\n",
      "Epoch 23, change: 0.03545538\n",
      "Epoch 24, change: 0.03374908\n",
      "Epoch 25, change: 0.03225640\n",
      "Epoch 26, change: 0.03088020\n",
      "Epoch 27, change: 0.02956125\n",
      "Epoch 28, change: 0.02832017\n",
      "Epoch 29, change: 0.02719322\n",
      "Epoch 30, change: 0.02613093\n",
      "Epoch 31, change: 0.02519832\n",
      "Epoch 32, change: 0.02427472\n",
      "Epoch 33, change: 0.02331668\n",
      "Epoch 34, change: 0.02257986\n",
      "Epoch 35, change: 0.02178094\n",
      "Epoch 36, change: 0.02102633\n",
      "Epoch 37, change: 0.02041392\n",
      "Epoch 38, change: 0.01972678\n",
      "Epoch 39, change: 0.01905981\n",
      "Epoch 40, change: 0.01849351\n",
      "Epoch 41, change: 0.01787297\n",
      "Epoch 42, change: 0.01738472\n",
      "Epoch 43, change: 0.01683139\n",
      "Epoch 44, change: 0.01638601\n",
      "Epoch 45, change: 0.01593847\n",
      "Epoch 46, change: 0.01545082\n",
      "Epoch 47, change: 0.01502482\n",
      "Epoch 48, change: 0.01466643\n",
      "Epoch 49, change: 0.01424109\n",
      "Epoch 50, change: 0.01388479\n",
      "Epoch 51, change: 0.01351734\n",
      "Epoch 52, change: 0.01315039\n",
      "Epoch 53, change: 0.01281083\n",
      "Epoch 54, change: 0.01255164\n",
      "Epoch 55, change: 0.01217831\n",
      "Epoch 56, change: 0.01187683\n",
      "Epoch 57, change: 0.01162498\n",
      "Epoch 58, change: 0.01134081\n",
      "Epoch 59, change: 0.01108120\n",
      "Epoch 60, change: 0.01082932\n",
      "Epoch 61, change: 0.01058745\n",
      "Epoch 62, change: 0.01035972\n",
      "Epoch 63, change: 0.01009353\n",
      "Epoch 64, change: 0.00990907\n",
      "Epoch 65, change: 0.00966293\n",
      "Epoch 66, change: 0.00945954\n",
      "Epoch 67, change: 0.00923209\n",
      "Epoch 68, change: 0.00906275\n",
      "Epoch 69, change: 0.00885998\n",
      "Epoch 70, change: 0.00866030\n",
      "Epoch 71, change: 0.00850427\n",
      "Epoch 72, change: 0.00831907\n",
      "Epoch 73, change: 0.00815493\n",
      "Epoch 74, change: 0.00800696\n",
      "Epoch 75, change: 0.00783287\n",
      "Epoch 76, change: 0.00768581\n",
      "Epoch 77, change: 0.00753379\n",
      "Epoch 78, change: 0.00736507\n",
      "Epoch 79, change: 0.00722832\n",
      "Epoch 80, change: 0.00709814\n",
      "Epoch 81, change: 0.00696702\n",
      "Epoch 82, change: 0.00682961\n",
      "Epoch 83, change: 0.00669753\n",
      "Epoch 84, change: 0.00657216\n",
      "Epoch 85, change: 0.00643642\n",
      "Epoch 86, change: 0.00633780\n",
      "Epoch 87, change: 0.00620540\n",
      "Epoch 88, change: 0.00609234\n",
      "Epoch 89, change: 0.00600407\n",
      "Epoch 90, change: 0.00587493\n",
      "Epoch 91, change: 0.00577648\n",
      "Epoch 92, change: 0.00567945\n",
      "Epoch 93, change: 0.00558286\n",
      "Epoch 94, change: 0.00547366\n",
      "Epoch 95, change: 0.00540951\n",
      "Epoch 96, change: 0.00530917\n",
      "Epoch 97, change: 0.00520270\n",
      "Epoch 98, change: 0.00513977\n",
      "Epoch 99, change: 0.00502410\n",
      "Epoch 100, change: 0.00493667\n",
      "[CV] END bootstrap=True, max_depth=100, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=100, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "models = [\"rf_reg\", \"brt\", \"maxent\", \"rf_cla\"]\n",
    "\n",
    "all_outputs = train_test_across_models(models)\n",
    "# run_outputs = train_test_visualise_roc_across_resolutions(d_resolutions=target_resolutions,model_type=\"rf_cla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1.00000', '0.50000', '0.25000', '0.08333'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2, 336)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.0021544346900318843, loss=huber, max_depth=2, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1155, subsample=0.9; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.0021544346900318843, loss=huber, max_depth=2, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1155, subsample=0.9; total time=   3.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.0021544346900318843, loss=huber, max_depth=2, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1155, subsample=0.9; total time=   4.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.0021544346900318843, loss=huber, max_depth=2, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1155, subsample=0.9; total time=   5.2s\n"
     ]
    }
   ],
   "source": [
    "np.shape(run_outputs['1.00000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 0.5, 0.25, 0.08333333333333333])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=friedman_mse, learning_rate=0.0021544346900318843, loss=huber, max_depth=2, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1155, subsample=0.9; total time=  25.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.0021544346900318843, loss=huber, max_depth=2, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1155, subsample=0.9; total time=  32.1s\n"
     ]
    }
   ],
   "source": [
    "rocs_n_runs(run_outputs['0.08333'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0.083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SST (sea water potential temperature)\n",
    "# load in daily sea water potential temp\n",
    "thetao_daily = xa.open_dataarray(directories.get_processed_dir() / \"arrays/thetao.nc\")\n",
    "\n",
    "# annual average, stdev of annual averages, annual minimum, annual maximum\n",
    "thetao_annual_average, _, (thetao_annual_min, thetao_annual_max) = baselines.calc_timeseries_params(thetao_daily, \"y\", \"thetao\")\n",
    "# monthly average, stdev of monthly averages, monthly minimum, monthly maximum\n",
    "thetao_monthly_average, thetao_monthly_stdev, (thetao_monthly_min, thetao_monthly_max) = baselines.calc_timeseries_params(\n",
    "    thetao_daily, \"m\", \"thetao\")\n",
    "# annual range (monthly max - monthly min)\n",
    "thetao_annual_range = (thetao_annual_max - thetao_annual_min).rename(\"thetao_annual_range\")\n",
    "# weekly minimum, weekly maximum\n",
    "_, _, (thetao_weekly_min, thetao_weekly_max) = baselines.calc_timeseries_params(thetao_daily, \"w\", \"thetao\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Salinity\n",
    "# load in daily sea water salinity means\n",
    "salinity_daily = xa.open_dataarray(directories.get_processed_dir() / \"arrays/so.nc\")\n",
    "\n",
    "# annual average\n",
    "salinity_annual_average, _, _ = baselines.calc_timeseries_params(salinity_daily, \"y\", \"salinity\")\n",
    "# monthly min, monthly max\n",
    "_, _, (salinity_monthly_min, salinity_monthly_max) = baselines.calc_timeseries_params(salinity_daily, \"m\", \"salinity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Current speed (dot product of horizontal and vertical)\n",
    "# load in daily currents (longitudinal and latitudinal)\n",
    "uo_daily = xa.open_dataarray(directories.get_processed_dir() / \"arrays/uo.nc\")\n",
    "vo_daily = xa.open_dataarray(directories.get_processed_dir() / \"arrays/vo.nc\")\n",
    "# calculate current magnitude\n",
    "current_daily = baselines.calculate_magnitude(uo_daily, vo_daily)\n",
    "\n",
    "# annual average\n",
    "current_annual_average, _, _ = baselines.calc_timeseries_params(current_daily, \"y\", \"current\")\n",
    "# monthly min, monthly max\n",
    "_, _, (current_monthly_min, current_monthly_max) = baselines.calc_timeseries_params(current_daily, \"m\", \"current\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Light penetration proxy\n",
    "# Load in bathymetry and scale to climate variable resolution\n",
    "bathymetry = xa.open_dataset(\n",
    "    directories.get_bathymetry_datasets_dir() / \"bathymetry_A_0-00030d.nc\").rio.write_crs(\"EPSG:4326\")[\"bathymetry_A\"]\n",
    "bathymetry_climate_res = spatial_data.upsample_xa_d_to_other(bathymetry, thetao_annual_average, name = \"bathymetry\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in ERA5 surface net solar radiation and upscale to climate variable resolution\n",
    "solar_radiation = xa.open_dataarray(\n",
    "    directories.get_era5_data_dir() / \"weather_parameters/VAR_surface_net_solar_radiation_LATS_-10_-17_LONS_142_147_YEAR_1993-2020.nc\"\n",
    "    ).rio.write_crs(\"EPSG:4326\")\n",
    "    \n",
    "# average solar_radiation daily\n",
    "solar_radiation_daily = solar_radiation.resample(time=\"1D\").mean(dim=\"time\")\n",
    "solar_climate_res = spatial_data.upsample_xa_d_to_other(solar_radiation_daily, thetao_annual_average, name = \"solar_radiation\")\n",
    "\n",
    "# annual average\n",
    "solar_annual_average, _, _ = baselines.calc_timeseries_params(solar_climate_res, \"y\", \"net_solar\")\n",
    "# monthly min, monthly max\n",
    "_, _, (solar_monthly_min, solar_monthly_max) = baselines.calc_timeseries_params(solar_climate_res, \"m\", \"net_solar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in ground truth data\n",
    "gt_1000m = xa.open_dataarray(directories.get_processed_dir() / \"arrays/coral_raster_1000m.nc\")\n",
    "# upsample to same resolution as climate (1/12 of a degree)\n",
    "gt_climate_res = spatial_data.upsample_xa_d_to_other(gt_1000m, thetao_annual_average, name = \"gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display different resolutions\n",
    "fig, (ax_left, ax_right) = plt.subplots(1, 2, figsize=(16,9), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "\n",
    "ax1 = spatial_plots.plot_spatial(gt_1000m, fax= (fig,ax_left), title=\"Ground truth coral presence map at 1000m\")\n",
    "ax2 = spatial_plots.plot_spatial(\n",
    "    gt_climate_res, fax=(fig, ax_right), val_lims = (0,1), title=\"Ground truth coral presence map at 1/12 degree\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data\n",
    "all_data = xa.merge([thetao_annual_average, thetao_annual_range, thetao_monthly_min, thetao_monthly_max, \n",
    "    thetao_monthly_stdev, thetao_weekly_min, thetao_weekly_max, \n",
    "    salinity_annual_average, salinity_monthly_min, salinity_monthly_max,\n",
    "    current_annual_average, current_monthly_min, current_monthly_max,\n",
    "    bathymetry_climate_res, solar_annual_average, solar_monthly_min, solar_monthly_max,\n",
    "    gt_climate_res\n",
    "    ])\n",
    "    \n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = all_data.to_dataframe()\n",
    "# test_df = test_df.dropna(subset=subset, how=\"any\",axis=0)\n",
    "test_df = test_df.fillna(0)\n",
    "\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "features_df = pd.get_dummies(test_df).drop([\"spatial_ref\",\"band\",\"depth\",\"gt\"], axis=1)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = test_df[\"gt\"]\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test, train_coordinates,test_coordinates, xa_masked = spatial_split_train_test(\n",
    "#     all_data, \"gt\", split_type=\"pixel\", test_fraction = 0.2)\n",
    "\n",
    "# test_train_da = visualise_train_test_split(all_data, train_coordinates, test_coordinates)\n",
    "bath_mask = generate_var_mask(all_data)\n",
    "test_xa = plot_train_test_spatial(test_train_da, bath_mask=bath_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_outcomes = n_random_runs_preds(rf_random, 10, all_data)\n",
    "\n",
    "rocs_n_runs(run_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_resolution_predictions(xa_ds: xa.DataArray):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.mean(spatial_data.calculate_spatial_resolution(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_label_thresholds(\n",
    "    thresholds: list[float],\n",
    "    y_test: np.ndarray | pd.Series,\n",
    "    y_predictions: np.ndarray | pd.Series,\n",
    "    figsize=[7, 7],\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot ROC curves with multiple lines for different label thresholds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        thresholds (list[float]): List of label thresholds.\n",
    "        y_test (np.ndarray or pd.Series): True labels.\n",
    "        y_predictions (np.ndarray or pd.Series): Predicted labels.\n",
    "        figsize (list, optional): Figure size for the plot. Default is [7, 7].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    # TODO: fix UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
    "\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    # prepare colour assignment\n",
    "    color_map = spatial_plots.get_cbar(\"seq\")\n",
    "    num_colors = len(thresholds)\n",
    "    colors = [color_map(i / num_colors) for i in range(num_colors)]\n",
    "\n",
    "    # plot ROC curves\n",
    "    for c, thresh in enumerate(thresholds):\n",
    "        binary_y_labels, binary_predictions = model_results.threshold_label(\n",
    "            y_test, y_predictions, thresh\n",
    "        )\n",
    "        fpr, tpr, _ = sklmetrics.roc_curve(\n",
    "            binary_y_labels, binary_predictions, drop_intermediate=False\n",
    "        )\n",
    "        roc_auc = sklmetrics.auc(fpr, tpr)\n",
    "\n",
    "        label = f\"{thresh:.01f} | {roc_auc:.02f}\"\n",
    "        ax.plot(fpr, tpr, label=label, color=colors[c])\n",
    "\n",
    "    # format\n",
    "    title = \"Receiver Operating Characteristic (ROC) Curve\\nfor several coral presence/absence thresholds\"\n",
    "    format_roc(ax=ax, title=title)\n",
    "    ax.legend(title=\"threshold value | auc\")\n",
    "\n",
    "\n",
    "def format_roc(ax, title: str = \"Receiver Operating Characteristic (ROC) Curve\"):\n",
    "    \"\"\"\n",
    "    Format the ROC plot axes.\n",
    "\n",
    "    Args:\n",
    "        ax: The matplotlib axes object.\n",
    "        title (optional): The title of the ROC plot. Defaults to \"Receiver Operating Characteristic (ROC) Curve\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"false positive rate\")\n",
    "    ax.set_ylabel(\"true positive rate\")\n",
    "    ax.set_aspect(\"equal\", \"box\")\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "\n",
    "    # plot \"random\" line for comparison (y=x)\n",
    "    ax.plot([0, 1], [0, 1], color='gray', linestyle=(5,(10,3)))\n",
    "    # Plot the grid\n",
    "    ax.grid(color='lightgray', linestyle=':', linewidth=0.5)\n",
    "    ax.set_xticks(np.arange(0, 1.2, 0.2))\n",
    "    ax.set_yticks(np.arange(0, 1.2, 0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_preds = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigate_label_thresholds(np.linspace(0,1,10), y_test, rf_random_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "rf_reg = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "# rf_reg.get_params()\n",
    "# rf_random = RandomizedSearchCV(\n",
    "#     estimator = rf_reg, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, \n",
    "#     random_state=RANDOM_STATE, n_jobs = -1)\n",
    "\n",
    "rf_reg.fit(X_train, y_train)\n",
    "# rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_params={\"n_estimators\":400,\n",
    "\"min_samples_split\":2,\n",
    "\"min_samples_leaf\":4,\n",
    "\"max_features\":\"sqrt\",\n",
    "\"max_depth\":10,\n",
    "\"bootstrap\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = rf_reg.set_params(**best_rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_search_best_params = rf_random.best_params_ \n",
    "# save best parameteers to json (in coralshift folder)\n",
    "import json\n",
    "\n",
    "with open(\"rf_random_search_best_params.json\", \"w\") as fp:\n",
    "    json.dump(rf_random_search_best_params, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = rf_random.predict(X_test)\n",
    "# np.shape(predictions)\n",
    "bce = log_loss(y_true=list(y_test), y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn import metrics\n",
    "# predictions = rf_random.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = rf_reg.predict(X_test)\n",
    "# predictions\n",
    "sum(y_test.where(y_test <= 0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 0\n",
    "for i in range(11):\n",
    "    print(val, sum(y_test.where(y_test >= val, 1)))\n",
    "    val += 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.array(y_test)\n",
    "sum(np.where(out > 0.1, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "rf_reg_preds = rf_reg.predict(X_test)\n",
    "rf_random_preds = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(sum(np.array(y_test)) > 0.1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: function to do N model runs and plot resultant ROC\n",
    "# TODO: test whether training/optimising on binary helps\n",
    "\n",
    "\n",
    "model_results.investigate_label_thresholds(np.linspace(0,1,100), y_test, rf_reg_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_labels_bin, predictions_bin, drop_intermediate=False)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                            estimator_name='example estimator')\n",
    "display.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Entropy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#convert y values to categorical values\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y_transformed = lab.fit_transform(target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxent = LogisticRegression(random_state=0)\n",
    "# maxent.fit(features_df, y_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_maxent = maxent.predict(features_df)\n",
    "\n",
    "# predicted_maxent_data = xa.DataArray(pred_maxent.reshape((85,61,28)),\n",
    "#     coords=all_data.coords, \n",
    "#     dims=all_data.dims)\n",
    "\n",
    "# f,a = plt.subplots(1,2,figsize=[14,7])\n",
    "# all_data[\"gt\"].plot(ax=a[0])\n",
    "# predicted_maxent_data.isel(time=-1).plot(ax=a[1]\n",
    "#     , vmin=all_data[\"gt\"].values.min(), vmax=all_data[\"gt\"].values.max()\n",
    "#     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification and Regression Trees (CART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "clf = RandomForestRegressor()\n",
    "clf_lim = RandomForestRegressor()\n",
    "\n",
    "num_vals = 50000\n",
    "clf.fit(features_df, target_df)\n",
    "clf_lim.fit(features_df[:num_vals], target_df[:num_vals])\n",
    "pred_lim = clf_lim.predict(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.fit(features_df, target_df)\n",
    "pred = clf.predict(features_df)\n",
    "predicted_data = xa.DataArray(pred.reshape((85,61,28)),\n",
    "    coords=all_data.coords, \n",
    "    dims=all_data.dims).isel(time=0)\n",
    "\n",
    "predicted_lim_data = xa.DataArray(pred_lim.reshape((85,61,28)),\n",
    "    coords=all_data.coords, \n",
    "    dims=all_data.dims).isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare predicted and ground truth values\n",
    "spatial_plots.plot_spatial_diffs(predicted_data, gt_climate_res, figsize=(14,13))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_plots.plot_spatial_diffs(predicted_lim_data, gt_climate_res, figsize=(14,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_test_random_forest(xa_ds: xa.Dataset, target_variable: str = \"gt\", test_fraction=0.5, random_state=None):\n",
    "    # TODO: tidy up and document\n",
    "    # Extract latitude, longitude, and time values from the spatial image\n",
    "    lats = xa_ds.latitude.values\n",
    "    lons = xa_ds.longitude.values\n",
    "    times = xa_ds.time.values\n",
    "\n",
    "\n",
    "    if len(xa_ds.dims) > 2:\n",
    "        # Flatten the spatial image into 2D arrays for training and testing\n",
    "        flattened_data = xa_ds.stack(points=(\"latitude\", \"longitude\", \"time\")).compute().to_dataframe().fillna(0).drop(\n",
    "            [\"time\",\"spatial_ref\",\"band\",\"depth\"], axis=1).astype(\"float32\")\n",
    "    else:\n",
    "        flattened_data = xa_ds.stack(points=(\"latitude\", \"longitude\")).compute().to_dataframe().fillna(0).drop(\n",
    "            [\"time\",\"spatial_ref\",\"band\",\"depth\"], axis=1).astype(\"float32\")\n",
    "\n",
    "    features = flattened_data.drop(\"gt\", axis=1)\n",
    "    # flattened_data = np.transpose(flattened_data, axes=(1, 0))\n",
    "    labels = flattened_data[\"gt\"]\n",
    "\n",
    "    # # Split the data into training and testing datasets\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #     features, labels, test_size=test_fraction, random_state=random_state\n",
    "    # )\n",
    "\n",
    "    # Train the random forest regressor\n",
    "    regressor = RandomForestRegressor()\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the target variable for the testing dataset\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    train_indices = X_train.index.values\n",
    "    test_indices = X_test.index.values\n",
    "\n",
    "    lat_spacing = xa_ds.latitude.values[1] - xa_ds.latitude.values[0]\n",
    "    lon_spacing = xa_ds.longitude.values[1] - xa_ds.longitude.values[0]\n",
    "\n",
    "    # TODO: refer to generic data_var dimension rather than calling by variable\n",
    "    train_pixs = np.empty(xa_ds[\"thetao_y_mean\"].values.shape)\n",
    "    train_pixs[:] = np.nan\n",
    "    test_pixs = np.empty(xa_ds[\"thetao_y_mean\"].values.shape)\n",
    "    test_pixs[:] = np.nan\n",
    "    # Color the spatial pixels corresponding to training and testing regions\n",
    "    for train_index in tqdm(train_indices, desc=\"Coloring in training indices...\"):\n",
    "        row, col = find_index_pair(xa_ds, train_index[0], train_index[1], lat_spacing, lon_spacing)\n",
    "        # ax.add_patch(Rectangle((lons[col], lats[row]), 1, 1, facecolor=train_color, alpha=0.2))\n",
    "        train_pixs[row,col] = 0\n",
    "\n",
    "    for test_index in tqdm(test_indices, desc=\"Coloring in training indices...\"):\n",
    "        row, col = find_index_pair(xa_ds, test_index[0], test_index[1], lat_spacing, lon_spacing)\n",
    "        # ax.add_patch(Rectangle((lons[col], lats[row]), 1, 1, facecolor=test_color, alpha=0.2))\n",
    "        test_pixs[row,col] = 1\n",
    "\n",
    "\n",
    "    # ds = xa.Dataset(\n",
    "    # {\n",
    "    #     'test_train': (xa_ds.dims, np.nansum(np.stack((test_pixs,train_pixs)), axis=0)),\n",
    "    # },\n",
    "    # coords=xa_image.coords)\n",
    "\n",
    "    return regressor, y_pred, ds\n",
    "\n",
    "\n",
    "def find_index_pair(data_array, lat, lon, lat_spacing, lon_spacing):\n",
    "    # Get the latitude and longitude spacing\n",
    "\n",
    "    lat_values = list(data_array.latitude.values)\n",
    "    lon_values = list(data_array.longitude.values)\n",
    "\n",
    "    lat_index = np.where(np.isclose(lat_values, lat))[0][0]\n",
    "    lon_index = np.where(np.isclose(lon_values, lon))[0][0]\n",
    "\n",
    "    return lat_index, lon_index\n",
    "\n",
    "reg,random_pred,ds = train_test_random_forest(all_data.isel(time=0), target_variable=all_data[\"gt\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pred_data = xa.DataArray(random_pred.reshape((85,61,28)),\n",
    "    coords=all_data.coords,\n",
    "    dims=all_data.dims)\n",
    "\n",
    "\n",
    "spatial_plots.plot_spatial_diffs(random_pred_data, gt_climate_res, figsize=(14,13))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test_spatial(dataset, figsize: tuple[float,float] = (7,7)):\n",
    "    \"\"\"\n",
    "    Plot two spatial variables from a dataset with different colors and labels.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (xarray.Dataset): The dataset containing the variables.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots(figsize = figsize, subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "\n",
    "    # Plot variable1 with color and label\n",
    "    dataset[\"train_pixs\"].plot(ax=ax, vmin=0, vmax=1, levels=2, label=\"train_pixs\",add_colorbar=False)\n",
    "\n",
    "    # Plot variable2 with color and label\n",
    "    dataset[\"test_pixs\"].plot(ax=ax, vmin=0, vmax=1, levels=2, label=\"test_pixs\", add_colorbar=False)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.coastlines(resolution=\"10m\", color=\"red\", linewidth=3)\n",
    "    # Add a colorbar for each variable\n",
    "    # cbar1 = plt.colorbar(ax=ax, mappable=dataset[\"train_pixs\"])\n",
    "    # cbar2 = plt.colorbar(ax=ax, mappable=dataset[\"test_pixs\"])\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_train_test_spatial(ds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_categorical_data(dataset, variable_name,  color1='red', color2='blue'):\n",
    "    \"\"\"\n",
    "    Plot categorical spatial data from an xarray dataset.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (xarray.Dataset): The dataset containing the categorical data.\n",
    "    variable_name (str): The name of the variable in the dataset to plot.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Extract the required data variable\n",
    "    variable = dataset[variable_name]\n",
    "\n",
    "    # Get the latitude, longitude, and values arrays\n",
    "    latitudes = variable.latitude.values\n",
    "    longitudes = variable.longitude.values\n",
    "    values = variable.values\n",
    "\n",
    "    # Create a meshgrid from latitude and longitude arrays\n",
    "    lon_mesh, lat_mesh = np.meshgrid(longitudes, latitudes)\n",
    "\n",
    "    # Plot the categorical data\n",
    "    mask1 = values == 0\n",
    "    mask2 = values == 1\n",
    "\n",
    "    # Plot the binary categorical data\n",
    "    plt.pcolormesh(lon_mesh, lat_mesh, mask1, cmap='Greys', facecolor=color1)\n",
    "    plt.pcolormesh(lon_mesh, lat_mesh, mask2, cmap='Greys', facecolor=color2)\n",
    "\n",
    "    # Add colorbar and labels\n",
    "    # plt.colorbar()\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title(variable_name)\n",
    "    plt.legend()\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_categorical_data(ds,\"test_train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predicted_lim_data = xa.DataArray(pred_lim.reshape((85,61,28)),\n",
    "    # coords=all_data.coords, \n",
    "    dims=all_data.dims)\n",
    "\n",
    "f,a = plt.subplots(1,2,figsize=[14,7])\n",
    "predicted_data.isel(time=0).plot(ax=a[0])\n",
    "predicted_lim_data.isel(time=0).plot(ax=a[1], vmin=predicted_data.min(), vmax=predicted_data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: training and testing on subsamples of data (train_test_split for linear, somehow something spatial...)\n",
    "# add in bathymetry\n",
    "# try binary (classifier)\n",
    "# function to plot difference between predicted and true\n",
    "# hyperparameter tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Regression Trees (BRT)\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "    features_df, target_df, test_size=0.1, random_state=13\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = np.zeros((params[\"n_estimators\"],), dtype=np.float64)\n",
    "for i, y_pred in enumerate(reg.staged_predict(X_test)):\n",
    "    test_score[i] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.title(\"Deviance\")\n",
    "plt.plot(\n",
    "    np.arange(params[\"n_estimators\"]) + 1,\n",
    "    reg.train_score_,\n",
    "    \"b-\",\n",
    "    label=\"Training Set Deviance\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(params[\"n_estimators\"]) + 1, test_score, \"r-\", label=\"Test Set Deviance\"\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Boosting Iterations\")\n",
    "plt.ylabel(\"Deviance\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = reg.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "plt.yticks(pos, np.array(features_df.columns)[sorted_idx])\n",
    "plt.title(\"Feature Importance (MDI)\")\n",
    "\n",
    "result = permutation_importance(\n",
    "    reg, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(\n",
    "    result.importances[sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels=np.array(features_df.columns)[sorted_idx],\n",
    ")\n",
    "plt.title(\"Permutation Importance (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_pred = reg.predict(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_gbr_data = xa.DataArray(gbr_pred.reshape((85,61,28)),\n",
    "    coords=all_data.coords, \n",
    "    dims=all_data.dims).isel(time=0)\n",
    "\n",
    "\n",
    "spatial_plots.plot_spatial_diffs(predicted_gbr_data, gt_climate_res, figsize=(14,13))\n",
    "\n",
    "\n",
    "\n",
    "# f,a = plt.subplots(1,2,figsize=[14,7])\n",
    "# all_data[\"gt\"].plot(ax=a[0])\n",
    "# predicted_gbr_data.isel(time=-1).plot(ax=a[1]\n",
    "#     , vmin=all_data[\"gt\"].values.min(), vmax=all_data[\"gt\"].values.max()\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CORALSHIFT",
   "language": "python",
   "name": "coralshift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "import xarray as xa\n",
    "import rioxarray as rxr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import geopandas as gpd\n",
    "\n",
    "from coralshift.utils import file_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is VERY hacky: but couldn't figure out how to scrape links from buttons: there seems to be no html which\n",
    "# # differentiates one button from another...\n",
    "\t    \n",
    "# def download_30m_gbr_bathymetry(download_dest_dir: Path | str, areas: list[str]) -> None:\n",
    "#     data_urls = [\"https://ausseabed-public-warehouse-bathymetry.s3.ap-southeast-2.amazonaws.com/L3/0b9ad3f3-7ade-40a7-ae70-f7c6c0f3ae2e/Great_Barrier_Reef_A_2020_30m_MSL_cog.tif\",\n",
    "#         \"https://ausseabed-public-warehouse-bathymetry.s3.ap-southeast-2.amazonaws.com/L3/4a6e7365-d7b1-45f9-a576-2be8ff8cd755/Great_Barrier_Reef_B_2020_30m_MSL_cog.tif\",\n",
    "#         \"https://ausseabed-public-warehouse-bathymetry.s3.ap-southeast-2.amazonaws.com/L3/3b171f8d-9248-4aeb-8b32-0737babba3c2/Great_Barrier_Reef_C_2020_30m_MSL_cog.tif\",\n",
    "#         \"https://ausseabed-public-warehouse-bathymetry.s3.ap-southeast-2.amazonaws.com/L3/7168f130-f903-4f2b-948b-78508aad8020/Great_Barrier_Reef_D_2020_30m_MSL_cog.tif\"\n",
    "#         ]\n",
    "\n",
    "#     for area_url in list(data_urls):\n",
    "#         area_filename = get_n_last_subparts_path(area_url, 1)\n",
    "#         # area_filename = f\"Great_Barrier_Reef_{alpha.upper()}_2020_30m_MSL_cog.tif\"\n",
    "#         # area_url = '/'.join((start_data_url, area_filename))\n",
    "\n",
    "#         filepath = Path(download_dest_dir, area_filename)\n",
    "#         # check whether file already downloaded\n",
    "#         check_exists_download_url(filepath, area_url)\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_30m_gbr_bathymetry(\n",
    "# \t'/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/datasets/bathymetry/GBR_30m', \n",
    "# \tareas = ['a','b','c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tif\n",
    "\n",
    "src = rasterio.open('/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/datasets/bathymetry/GBR_30m/Great_Barrier_Reef_A_2020_30m_MSL_cog.tif')\n",
    "gbr_a_data = src.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = file_ops.return_list_filepaths(\"/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/coralshift/datasets/bathymetry/GBR_30m\", \"tif\")\n",
    "dict_out = open_tifs_to_dict(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a = dict_out['Great_Barrier_Reef_A_2020_30m_MSL_cog.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coralshift.processing import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_xa_array(xa_array: xa.DataArray, upsampling: dict = {\"x\": 1000, \"y\": 1000}) -> xa.DataArray:\n",
    "    \"\"\"Displays an xarray DataArray as a plot, optionally with upsampling to increase the resolution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    xa_array (xr.DataArray): The xarray DataArray to be displayed.\n",
    "    upsampling (dict, optional): A dictionary specifying the upsampling factor for each dimension. The keys should be \n",
    "        the names of the dimensions, and the values should be integers indicating the factor by which to increase the\n",
    "        resolution. Default is {\"x\": 1000, \"y\": 1000}.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray: The xarray DataArray that was displayed.\n",
    "    \"\"\"\n",
    "    min_val, max_val = xa_array.values.min(), xa_array.values.max()\n",
    "\n",
    "    if upsampling:\n",
    "        xa_array = data.upsample_xarray(xa_array, upsampling)\n",
    "\n",
    "    xa_array.plot(cmap='gist_earth', vmin=min_val, vmax=max_val)\n",
    "\n",
    "    return xa_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gbr_a_coarse.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_xa_array(gbr_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a_coarse.plot(cmap='gist_earth', vmin=min_val, vmax=max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a_coarse[0, -50:, -50:].plot(cmap='gist_earth', vmin=min_val, vmax=max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a[0, -5000:, -5000:].plot(cmap='gist_earth', vmin=min_val, vmax=max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.add_feature(cfeature.LAND.with_scale(\"10m\"))\n",
    "ax.add_feature(cfeature.OCEAN.with_scale(\"10m\"))\n",
    "\n",
    "gbr_a.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['Great_Barrier_Reef_A_2020_30m_MSL_cog.tif'].bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a_coarse.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_xarray(gbr_a, {\"x\": 10, \"y\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def align_tifs_to_worldmap(tifs_dict: dict) -> gpd.GeoDataFrame:\n",
    "    \"\"\"TODO: docstring\"\"\"\n",
    "    \n",
    "    gdf_list = []\n",
    "    for tif_name, tif_array in tifs_dict:\n",
    "        bbox_gdf = align_tifs_to_worldmap(tif_array)\n",
    "        gdf_list.append(bbox_gdf)\n",
    "\n",
    "    all_gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True), crs=gdf_list[0].crs)\t\n",
    "    return all_gdf\n",
    "\n",
    "\n",
    "def tif_to_gdf(xa_array) -> gpd.GeoDataFrame:\n",
    "    \"\"\"TODO: function to line tif files up with world map\"\"\"\n",
    "\n",
    "    # Create GeoDataFrame with extent of the raster\n",
    "    xmin, ymin, xmax, ymax = xa_array.bounds\n",
    "    bbox_gdf = gpd.GeoDataFrame({'geometry': gpd.box(xmin, ymin, xmax, ymax)}, index=[0], crs=xa_array.crs)\n",
    "\n",
    "    # Reproject the GeoDataFrame to Web Mercator\n",
    "    bbox_gdf = bbox_gdf.to_crs(epsg=3857)\n",
    "\n",
    "    return bbox_gdf\n",
    "\n",
    "\n",
    "# def display_gdf_on_worldmap(gdf: gpd.GeoDataFrame) -> None:\n",
    "    \n",
    "\n",
    "# function to return pixel values closest to the shoreline\n",
    "def return_pixels_closest_to_value(\n",
    "    array: np.ndarray, \n",
    "    central_value: float, \n",
    "    tolerance: float = .5, \n",
    "    buffer_pixels: int = 10,\n",
    "    bathymetry_only: bool = True\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"Returns a 1D array of all the pixels in the input array that are closest to a specified central value within a \n",
    "    given tolerance and within a pixel buffer zone.\n",
    "\n",
    "       Parameters\n",
    "    ----------\n",
    "    array (np.ndarray): The input array of pixel values.\n",
    "    central_value (float): The central value to which the pixels should be compared.\n",
    "    tolerance (float, optional): The tolerance within which the pixels are considered to be \"close\" to the central \n",
    "        value. Defaults to 0.5.\n",
    "    buffer_pixels (int, optional): The size of the buffer zone around the pixels. Defaults to 10.\n",
    "    bathymetry_only (bool, optional): Whether to only consider bathymetric data, i.e., values less than zero. \n",
    "        Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray: A 1D array of all the pixels in the input array that are closest to the specified central value within \n",
    "        the given tolerance and within the pixel buffer zone.\n",
    "    \"\"\"\n",
    "    binary = np.isclose(array, central_value, atol=0.5)\n",
    "    # morphological dilation operation\n",
    "    dilated = binary_dilation(binary, iterations=buffer_pixels)\n",
    "\n",
    "    array_vals = array[dilated]\n",
    "    # if specifying only bathymetric data\n",
    "    if bathymetry_only:\n",
    "        array_vals = array_vals[array_vals < 0]\n",
    "    \n",
    "    # return only non-zero values as 1d array\n",
    "    return array_vals[np.nonzero(array_vals)]\n",
    "\n",
    "\n",
    "def return_distance_closest_to_value(\n",
    "    array: np.ndarray, \n",
    "    central_value: float, \n",
    "    tolerance: float = .5, \n",
    "    buffer_distance: float = 300,\n",
    "    distance_per_pixel: float = 30,\n",
    "    bathymetry_only: bool = True,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Wrapper for return_pixels_closest_to_value() allowing specification by distance from thresholded values rather \n",
    "    than number of pixels\n",
    "    \n",
    "    Returns a 1D array of all the pixels in the input array that are closest to a specified central value within a \n",
    "    given tolerance and within a distance buffer zone.\n",
    "\n",
    "       Parameters\n",
    "    ----------\n",
    "    array (np.ndarray): The input array of pixel values.\n",
    "    central_value (float): The central value to which the pixels should be compared.\n",
    "    tolerance (float, optional): The tolerance within which the pixels are considered to be \"close\" to the central \n",
    "        value. Defaults to 0.5.\n",
    "    buffer_distance (float, optional): The size of the buffer zone around the pixels. Defaults to 300.\n",
    "    bathymetry_only (bool, optional): Whether to only consider bathymetric data, i.e., values less than zero. \n",
    "        Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray: A 1D array of all the pixels in the input array that are closest to the specified central value within \n",
    "        the given tolerance and within the distance buffer zone.\n",
    "    \"\"\"\n",
    "    buffer_pixels = buffer_distance / distance_per_pixel\n",
    "    return return_pixels_closest_to_value(array, central_value, tolerance, buffer_pixels, bathymetry_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(gbr_a_data[0:10000, 0:10000])\n",
    "plt.imshow(gbr_a_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = np.isclose(data_array[0], 0, atol=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum(binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "# Perform a morphological dilation operation\n",
    "buffer_size = 10  # Define the buffer size\n",
    "struct_elem = np.ones((buffer_size, buffer_size))  # Define the structuring element\n",
    "dilated = binary_dilation(binary, iterations=buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.imshow(dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.imshow(shoreline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = return_pixels_closest_to_value(data_array[0].values, 0, buffer_pixels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out\n",
    "shallow_out = out[out > -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(out,100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot histogram of values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xa.plot.hist(data_array, ax=ax, bins=100)\n",
    "ax.set_xlabel(\"depth\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "ax.set_title(\"Histogram of DEM counts for selected area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = xa.open_rasterio(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array[0]\n",
    "# rename coordinate and value fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name_dict = {'y': 'latitude', 'x': 'longitude'}\n",
    "\n",
    "data_array = data_array.rename(new_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array[0, 0:5000, 0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## module import error\n",
    "import gdal\n",
    "# ds = gdal.Open('/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/datasets/bathymetry/GBR_30m/Great_Barrier_Reef_A_2020_30m_MSL_cog.tif')\n",
    "# channel = np.array(ds.GetRasterBand(1).ReadAsArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array[0, :1000, :1000].plot(x='longitude', y='latitude', figsize=(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data_array[0].to_dataframe(name='asdf').reset_index()\n",
    "# gdf = gpd.GeoDataFrame(df.value_column, geometry=gpd.points_from_xy(df.y,df.x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.gdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.bbox_gdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot – TODO: update with custom bounds\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the raster on the GeoDataFrame extent\n",
    "rasterio.plot.show(bbox_gdf, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to line tif files up with world map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_dir = '/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/datasets/bathymetry/ETOPO22'\n",
    "name = 'ETOPO_2022_v1_15s_N00E000_geoid.nc'\n",
    "\n",
    "Path(nc_dir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nc_files(nc_dir: Path | str, file_names: list[str]) -> xa.Dataset:\n",
    "\tfiles = [Path(nc_dir, file_name) for file_name in file_names]\n",
    "\tmerged_ncs = xa.open_mfdataset(files)\n",
    "\treturn merged_ncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\"ETOPO_2022_v1_15s_N00E000_geoid.nc\", \"ETOPO_2022_v1_15s_N00E015_geoid.nc\", \"ETOPO_2022_v1_15s_N00E030_geoid.nc\"]\n",
    "# bathy_xa = xa.open_dataset('/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/datasets/bathymetry/ETOPO22/ETOPO_2022_v1_15s_N00E000_geoid.nc')\n",
    "out = merge_nc_files(nc_dir, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "# Add a global map background\n",
    "ax.stock_img()\n",
    "\n",
    "out['z'].plot(ax=ax, x='lon', y='lat')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping data: really not a priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up the Selenium driver with Chrome\n",
    "driver = webdriver.Chrome('/path/to/chromedriver')\n",
    "\n",
    "# Navigate to the webpage with the download button\n",
    "driver.get('https://example.com/download-page')\n",
    "\n",
    "# Wait for the page to fully load\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the download button using its text or other identifying feature\n",
    "download_button = driver.find_element_by_xpath('//button[text()=\"Download\"]')\n",
    "\n",
    "# Click the button to trigger the download link generation\n",
    "download_button.click()\n",
    "\n",
    "# Wait for the download link to be generated\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the page source with the download link\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Parse the page source with BeautifulSoup to extract the download link\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "download_link = soup.find('a', {'class': 'download-link'})['href']\n",
    "\n",
    "# Download the file using the extracted download link\n",
    "# ... (your code to download the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rich progress bar I couldn't get working\n",
    "# import urllib.request\n",
    "# from rich.progress import Progress, BarColumn, DownloadColumn, TransferSpeedColumn, TimeRemainingColumn\n",
    "\n",
    "\n",
    "# class DownloadProgressBar:\n",
    "#     def __init__(self, unit='B'):\n",
    "#         self.progress = Progress(\n",
    "#             \"{task.description}\",\n",
    "#             BarColumn(),\n",
    "#             DownloadColumn(),\n",
    "#             TransferSpeedColumn(),\n",
    "#             TimeRemainingColumn(),\n",
    "#         )\n",
    "#         self.unit = unit\n",
    "\n",
    "#     def __enter__(self):\n",
    "#         self.task_id = self.progress.add_task(\"\", start=False)\n",
    "#         self.progress.start()\n",
    "#         return self\n",
    "\n",
    "#     def __exit__(self, *exc_info):\n",
    "#         self.progress.stop()\n",
    "\n",
    "#     def update_to(self, b=1, bsize=1, tsize=None):\n",
    "#         if tsize is not None:\n",
    "#             # Convert the total size to the specified unit\n",
    "#             total_size = tsize / self.unit_size\n",
    "#             self.progress.update(self.task_id, total=total_size)\n",
    "#         self.progress.update(self.task_id, advance=b * bsize / self.unit_size)\n",
    "\n",
    "#     @property\n",
    "#     def unit_size(self):\n",
    "#         # Return the size of one unit in bytes\n",
    "#         if self.unit == 'B':\n",
    "#             return 1\n",
    "#         elif self.unit == 'KB':\n",
    "#             return 1024\n",
    "#         elif self.unit == 'MB':\n",
    "#             return 1024 * 1024\n",
    "#         elif self.unit == 'GB':\n",
    "#             return 1024 * 1024 * 1024\n",
    "#         else:\n",
    "#             raise ValueError(f\"Invalid unit: {self.unit}\")\n",
    "\n",
    "# def download_url(url, output_path, progress_units: str = 'MB'):\n",
    "#     print(\"\\n\")\n",
    "#     with DownloadProgressBar(progress_units) as t:\n",
    "#         urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coralshift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82f0322cbbfe2118df7ac5a169fc6f9a126c1c0fca1798dd82a93c390122bed8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "import xarray as xa\n",
    "import rioxarray as rxr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import geopandas as gpd\n",
    "\n",
    "from coralshift.utils import file_ops, directories\n",
    "from coralshift.dataloading import bathymetry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure necessary data present: if not, install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Great_Barrier_Reef_A_2020_30m_MSL_cog.tif: 0.00B [00:00, ?B/s]0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Great_Barrier_Reef_A_2020_30m_MSL_cog.tif:   2%|‚ñè         | 24.1M/989M [00:12<08:10, 1.97MB/s]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 30m GBR bathymetry (can visualise ETOPO later if necessary)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m gbr_30_dir \u001b[39m=\u001b[39m directories\u001b[39m.\u001b[39mget_gbr_bathymetry_data_dir()\n\u001b[0;32m----> 3\u001b[0m bathymetry\u001b[39m.\u001b[39;49mdownload_30m_gbr_bathymetry(download_dest_dir\u001b[39m=\u001b[39;49mgbr_30_dir)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/notebooks/../coralshift/dataloading/bathymetry.py:120\u001b[0m, in \u001b[0;36mdownload_30m_gbr_bathymetry\u001b[0;34m(download_dest_dir, areas)\u001b[0m\n\u001b[1;32m    118\u001b[0m filepath \u001b[39m=\u001b[39m Path(download_dest_dir, area_filename)\n\u001b[1;32m    119\u001b[0m \u001b[39m# check whether file already downloaded: if not, download\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m file_ops\u001b[39m.\u001b[39;49mcheck_exists_download_url(filepath, area_url)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/notebooks/../coralshift/utils/file_ops.py:57\u001b[0m, in \u001b[0;36mcheck_exists_download_url\u001b[0;34m(filepath, url, loading_bar)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Path(filepath)\u001b[39m.\u001b[39mis_file():\n\u001b[1;32m     55\u001b[0m     \u001b[39m# download with loading bar\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[39mif\u001b[39;00m loading_bar:\n\u001b[0;32m---> 57\u001b[0m         download_url(url, \u001b[39mstr\u001b[39;49m(filepath))\n\u001b[1;32m     58\u001b[0m     \u001b[39m# download without loading bar for some reason...\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m         urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlretrieve(url, filename\u001b[39m=\u001b[39mfilepath)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/notebooks/../coralshift/utils/file_ops.py:36\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, output_path, loading_bar)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[39mwith\u001b[39;00m DownloadProgressBar(unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m, unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m                          miniters\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, desc\u001b[39m=\u001b[39murl\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39mas\u001b[39;00m t:\n\u001b[0;32m---> 36\u001b[0m     urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlretrieve(url, filename\u001b[39m=\u001b[39;49moutput_path, reporthook\u001b[39m=\u001b[39;49mt\u001b[39m.\u001b[39;49mupdate_to)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/coralshift/lib/python3.11/urllib/request.py:270\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    267\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m    269\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     block \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(bs)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m block:\n\u001b[1;32m    272\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/coralshift/lib/python3.11/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/coralshift/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/coralshift/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/coralshift/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 30m GBR bathymetry (can visualise ETOPO later if necessary)\n",
    "gbr_30_dir = directories.get_gbr_bathymetry_data_dir()\n",
    "# apparently not checking existing files properly\n",
    "bathymetry.download_30m_gbr_bathymetry(download_dest_dir=gbr_30_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tif\n",
    "\n",
    "src = rasterio.open('/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/datasets/bathymetry/GBR_30m/Great_Barrier_Reef_A_2020_30m_MSL_cog.tif')\n",
    "gbr_a_data = src.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = file_ops.return_list_filepaths(\"/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/coralshift/datasets/bathymetry/GBR_30m\", \"tif\")\n",
    "dict_out = open_tifs_to_dict(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a = dict_out['Great_Barrier_Reef_A_2020_30m_MSL_cog.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coralshift.processing import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gbr_a_coarse.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_xa_array(gbr_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a_coarse.plot(cmap='gist_earth', vmin=min_val, vmax=max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a_coarse[0, -50:, -50:].plot(cmap='gist_earth', vmin=min_val, vmax=max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a[0, -5000:, -5000:].plot(cmap='gist_earth', vmin=min_val, vmax=max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.add_feature(cfeature.LAND.with_scale(\"10m\"))\n",
    "ax.add_feature(cfeature.OCEAN.with_scale(\"10m\"))\n",
    "\n",
    "gbr_a.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['Great_Barrier_Reef_A_2020_30m_MSL_cog.tif'].bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_a_coarse.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_xarray(gbr_a, {\"x\": 10, \"y\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def align_tifs_to_worldmap(tifs_dict: dict) -> gpd.GeoDataFrame:\n",
    "    \"\"\"TODO: docstring\"\"\"\n",
    "    \n",
    "    gdf_list = []\n",
    "    for tif_name, tif_array in tifs_dict:\n",
    "        bbox_gdf = align_tifs_to_worldmap(tif_array)\n",
    "        gdf_list.append(bbox_gdf)\n",
    "\n",
    "    all_gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True), crs=gdf_list[0].crs)\t\n",
    "    return all_gdf\n",
    "\n",
    "\n",
    "def tif_to_gdf(xa_array) -> gpd.GeoDataFrame:\n",
    "    \"\"\"TODO: function to line tif files up with world map\"\"\"\n",
    "\n",
    "    # Create GeoDataFrame with extent of the raster\n",
    "    xmin, ymin, xmax, ymax = xa_array.bounds\n",
    "    bbox_gdf = gpd.GeoDataFrame({'geometry': gpd.box(xmin, ymin, xmax, ymax)}, index=[0], crs=xa_array.crs)\n",
    "\n",
    "    # Reproject the GeoDataFrame to Web Mercator\n",
    "    bbox_gdf = bbox_gdf.to_crs(epsg=3857)\n",
    "\n",
    "    return bbox_gdf\n",
    "\n",
    "\n",
    "# def display_gdf_on_worldmap(gdf: gpd.GeoDataFrame) -> None:\n",
    "    \n",
    "\n",
    "# function to return pixel values closest to the shoreline\n",
    "def return_pixels_closest_to_value(\n",
    "    array: np.ndarray, \n",
    "    central_value: float, \n",
    "    tolerance: float = .5, \n",
    "    buffer_pixels: int = 10,\n",
    "    bathymetry_only: bool = True\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"Returns a 1D array of all the pixels in the input array that are closest to a specified central value within a \n",
    "    given tolerance and within a pixel buffer zone.\n",
    "\n",
    "       Parameters\n",
    "    ----------\n",
    "    array (np.ndarray): The input array of pixel values.\n",
    "    central_value (float): The central value to which the pixels should be compared.\n",
    "    tolerance (float, optional): The tolerance within which the pixels are considered to be \"close\" to the central \n",
    "        value. Defaults to 0.5.\n",
    "    buffer_pixels (int, optional): The size of the buffer zone around the pixels. Defaults to 10.\n",
    "    bathymetry_only (bool, optional): Whether to only consider bathymetric data, i.e., values less than zero. \n",
    "        Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray: A 1D array of all the pixels in the input array that are closest to the specified central value within \n",
    "        the given tolerance and within the pixel buffer zone.\n",
    "    \"\"\"\n",
    "    binary = np.isclose(array, central_value, atol=0.5)\n",
    "    # morphological dilation operation\n",
    "    dilated = binary_dilation(binary, iterations=buffer_pixels)\n",
    "\n",
    "    array_vals = array[dilated]\n",
    "    # if specifying only bathymetric data\n",
    "    if bathymetry_only:\n",
    "        array_vals = array_vals[array_vals < 0]\n",
    "    \n",
    "    #¬†return only non-zero values as 1d array\n",
    "    return array_vals[np.nonzero(array_vals)]\n",
    "\n",
    "\n",
    "def return_distance_closest_to_value(\n",
    "    array: np.ndarray, \n",
    "    central_value: float, \n",
    "    tolerance: float = .5, \n",
    "    buffer_distance: float = 300,\n",
    "    distance_per_pixel: float = 30,\n",
    "    bathymetry_only: bool = True,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Wrapper for return_pixels_closest_to_value() allowing specification by distance from thresholded values rather \n",
    "    than number of pixels\n",
    "    \n",
    "    Returns a 1D array of all the pixels in the input array that are closest to a specified central value within a \n",
    "    given tolerance and within a distance buffer zone.\n",
    "\n",
    "       Parameters\n",
    "    ----------\n",
    "    array (np.ndarray): The input array of pixel values.\n",
    "    central_value (float): The central value to which the pixels should be compared.\n",
    "    tolerance (float, optional): The tolerance within which the pixels are considered to be \"close\" to the central \n",
    "        value. Defaults to 0.5.\n",
    "    buffer_distance (float, optional): The size of the buffer zone around the pixels. Defaults to 300.\n",
    "    bathymetry_only (bool, optional): Whether to only consider bathymetric data, i.e., values less than zero. \n",
    "        Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray: A 1D array of all the pixels in the input array that are closest to the specified central value within \n",
    "        the given tolerance and within the distance buffer zone.\n",
    "    \"\"\"\n",
    "    buffer_pixels = buffer_distance / distance_per_pixel\n",
    "    return return_pixels_closest_to_value(array, central_value, tolerance, buffer_pixels, bathymetry_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(gbr_a_data[0:10000, 0:10000])\n",
    "plt.imshow(gbr_a_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = np.isclose(data_array[0], 0, atol=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum(binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "# Perform a morphological dilation operation\n",
    "buffer_size = 10  # Define the buffer size\n",
    "struct_elem = np.ones((buffer_size, buffer_size))  # Define the structuring element\n",
    "dilated = binary_dilation(binary, iterations=buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.imshow(dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.imshow(shoreline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = return_pixels_closest_to_value(data_array[0].values, 0, buffer_pixels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out\n",
    "shallow_out = out[out > -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(out,100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot histogram of values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xa.plot.hist(data_array, ax=ax, bins=100)\n",
    "ax.set_xlabel(\"depth\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "ax.set_title(\"Histogram of DEM counts for selected area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = xa.open_rasterio(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array[0]\n",
    "# rename coordinate and value fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name_dict = {'y': 'latitude', 'x': 'longitude'}\n",
    "\n",
    "data_array = data_array.rename(new_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array[0, 0:5000, 0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## module import error\n",
    "import gdal\n",
    "# ds = gdal.Open('/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/datasets/bathymetry/GBR_30m/Great_Barrier_Reef_A_2020_30m_MSL_cog.tif')\n",
    "# channel = np.array(ds.GetRasterBand(1).ReadAsArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array[0, :1000, :1000].plot(x='longitude', y='latitude', figsize=(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data_array[0].to_dataframe(name='asdf').reset_index()\n",
    "# gdf = gpd.GeoDataFrame(df.value_column, geometry=gpd.points_from_xy(df.y,df.x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.gdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.bbox_gdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot ‚Äì¬†TODO: update with custom bounds\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the raster on the GeoDataFrame extent\n",
    "rasterio.plot.show(bbox_gdf, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to line tif files up with world map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_dir = '/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/datasets/bathymetry/ETOPO22'\n",
    "name = 'ETOPO_2022_v1_15s_N00E000_geoid.nc'\n",
    "\n",
    "Path(nc_dir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nc_files(nc_dir: Path | str, file_names: list[str]) -> xa.Dataset:\n",
    "\tfiles = [Path(nc_dir, file_name) for file_name in file_names]\n",
    "\tmerged_ncs = xa.open_mfdataset(files)\n",
    "\treturn merged_ncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\"ETOPO_2022_v1_15s_N00E000_geoid.nc\", \"ETOPO_2022_v1_15s_N00E015_geoid.nc\", \"ETOPO_2022_v1_15s_N00E030_geoid.nc\"]\n",
    "# bathy_xa = xa.open_dataset('/Users/orlandotimmerman/Library/CloudStorage/OneDrive-UniversityofCambridge/cambridge/mres/mres_project/coralshift/datasets/bathymetry/ETOPO22/ETOPO_2022_v1_15s_N00E000_geoid.nc')\n",
    "out = merge_nc_files(nc_dir, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "# Add a global map background\n",
    "ax.stock_img()\n",
    "\n",
    "out['z'].plot(ax=ax, x='lon', y='lat')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping data: really not a priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up the Selenium driver with Chrome\n",
    "driver = webdriver.Chrome('/path/to/chromedriver')\n",
    "\n",
    "# Navigate to the webpage with the download button\n",
    "driver.get('https://example.com/download-page')\n",
    "\n",
    "# Wait for the page to fully load\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the download button using its text or other identifying feature\n",
    "download_button = driver.find_element_by_xpath('//button[text()=\"Download\"]')\n",
    "\n",
    "# Click the button to trigger the download link generation\n",
    "download_button.click()\n",
    "\n",
    "# Wait for the download link to be generated\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the page source with the download link\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Parse the page source with BeautifulSoup to extract the download link\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "download_link = soup.find('a', {'class': 'download-link'})['href']\n",
    "\n",
    "# Download the file using the extracted download link\n",
    "# ... (your code to download the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rich progress bar I couldn't get working\n",
    "# import urllib.request\n",
    "# from rich.progress import Progress, BarColumn, DownloadColumn, TransferSpeedColumn, TimeRemainingColumn\n",
    "\n",
    "\n",
    "# class DownloadProgressBar:\n",
    "#     def __init__(self, unit='B'):\n",
    "#         self.progress = Progress(\n",
    "#             \"{task.description}\",\n",
    "#             BarColumn(),\n",
    "#             DownloadColumn(),\n",
    "#             TransferSpeedColumn(),\n",
    "#             TimeRemainingColumn(),\n",
    "#         )\n",
    "#         self.unit = unit\n",
    "\n",
    "#     def __enter__(self):\n",
    "#         self.task_id = self.progress.add_task(\"\", start=False)\n",
    "#         self.progress.start()\n",
    "#         return self\n",
    "\n",
    "#     def __exit__(self, *exc_info):\n",
    "#         self.progress.stop()\n",
    "\n",
    "#     def update_to(self, b=1, bsize=1, tsize=None):\n",
    "#         if tsize is not None:\n",
    "#             # Convert the total size to the specified unit\n",
    "#             total_size = tsize / self.unit_size\n",
    "#             self.progress.update(self.task_id, total=total_size)\n",
    "#         self.progress.update(self.task_id, advance=b * bsize / self.unit_size)\n",
    "\n",
    "#     @property\n",
    "#     def unit_size(self):\n",
    "#         # Return the size of one unit in bytes\n",
    "#         if self.unit == 'B':\n",
    "#             return 1\n",
    "#         elif self.unit == 'KB':\n",
    "#             return 1024\n",
    "#         elif self.unit == 'MB':\n",
    "#             return 1024 * 1024\n",
    "#         elif self.unit == 'GB':\n",
    "#             return 1024 * 1024 * 1024\n",
    "#         else:\n",
    "#             raise ValueError(f\"Invalid unit: {self.unit}\")\n",
    "\n",
    "# def download_url(url, output_path, progress_units: str = 'MB'):\n",
    "#     print(\"\\n\")\n",
    "#     with DownloadProgressBar(progress_units) as t:\n",
    "#         urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coralshift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82f0322cbbfe2118df7ac5a169fc6f9a126c1c0fca1798dd82a93c390122bed8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import xarray as xa\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from coralshift import functions_creche\n",
    "from coralshift.plotting import spatial_plots\n",
    "from coralshift.processing import spatial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "# relative path to data directory\n",
    "data_dir_p = Path('/home/rt582/rds/hpc-work/coralshift/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify data resolution\n",
    "resolution_lat, resolution_lon = 1., 1.\n",
    "# region of interest\n",
    "lats = [-30, -10]\n",
    "lons = [140, 160]\n",
    "depths = [0, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth – UNEP-WCMC data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in shapefile to geopandas dataframe\n",
    "unep_fp = data_dir_p / \"ground_truth/unep_wcmc/01_Data/WCMC008_CoralReef2021_Py_v4_1.shp\"\n",
    "unep_gdf = gpd.read_file(unep_fp)\n",
    "\n",
    "unep_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate gt raster\n",
    "unep_raster = functions_creche.rasterize_geodf(unep_gdf, resolution_lat=resolution_lat, resolution_lon=resolution_lon)\n",
    "# generate gt xarray\n",
    "xa_unep = functions_creche.raster_to_xarray(\n",
    "    unep_raster, x_y_limits=functions_creche.lat_lon_vals_from_geo_df(unep_gdf)[:4], \n",
    "    resolution_lat=resolution_lat, resolution_lon=resolution_lon, name=\"unep_coral_presence\")\n",
    "\n",
    "# Plot the xarray DataArray\n",
    "spatial_plots.plot_spatial(xa_unep, title=\"Rasterised UNEP Reef Presence\", orient_colorbar=\"horizontal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WOA 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_data_dir_p = data_dir_p / \"env_vars/woa/woa_2018/monthly_1981-2010_temp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant filepath\n",
    "env_data_p = env_data_dir_p / \"env_vars/woa/woa_2018/monthly_1981-2010_temp\"\n",
    "\n",
    "# TODO: expand to other variables. \n",
    "# Could also use open_mfdataset with a preprocess function to limit spatial range: https://docs.xarray.dev/en/stable/generated/xarray.open_mfdataset.html\n",
    "temp_list = []\n",
    "# iterate through files in dir ending .nc\n",
    "for file_p in tqdm(env_data_dir_p.glob(\"*.nc\"), desc=f\"Opening .nc files in {env_data_dir_p}\"):\n",
    "    # load in file as xarray dataarray\n",
    "    temp_array = xa.open_dataset(file_p, decode_times=False)    # TODO: can't understand time format\n",
    "    # select spatial region of interest\n",
    "    temp_array = temp_array.sel(lat=slice(*lats), lon=slice(*lons), depth=slice(*depths))   \n",
    "    # temp_array = temp_array.sel(lat=slice(*lats[::-1]), lon=slice(*lons)) \n",
    "    # append to list\n",
    "    temp_list.append(temp_array)\n",
    "\n",
    "# concat list of dataarrays into one dataarray. N.B. may not be this simple\n",
    "env_xa = spatial_data.process_xa_d(xa.concat(temp_list, dim=\"time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyinterp.backends import xarray\n",
    "from pyinterp import fill\n",
    "\n",
    "var_data = env_xa[\"t_an\"].isel(depth=0)\n",
    "grid = xarray.Grid2D(var_data.isel(time=0))\n",
    "filled = fill.loess(grid, nx=5, ny=5)\n",
    "\n",
    "plt.imshow(filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_ds = spatial_data.process_xa_d(\n",
    "    functions_creche.apply_fill_loess(env_xa.isel(depth=0), nx=2, ny=2))\n",
    "\n",
    "f, a =plt.subplots(ncols=2, figsize=(14,5), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "\n",
    "spatial_plots.plot_spatial(env_xa[\"t_an\"].isel(time=10,depth=0), fax=[f,a[0]])\n",
    "a[0].set_title(\"Original Data\")\n",
    "spatial_plots.plot_spatial(buffered_ds[\"t_an\"].isel(time=10), fax=[f,a[1]])\n",
    "a[1].set_title(\"Filled Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameterisation à la Couce et al. 2013\n",
    "\n",
    "# annual average: t_an\n",
    "buffered_ds[\"t_an\"].isel(latitude=19, longitude=19).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_data.process_xa_d(buffered_ds).coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_unep.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate comparable temporal parameterisations\n",
    "\n",
    "# load in other relevant environmental data\n",
    "\n",
    "# era5 irradiance\n",
    "\n",
    "# oras5 currents\n",
    "\n",
    "# nice-to-haves:\n",
    "# cyclones\n",
    "# population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORAS5 Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix this projection nightmare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oras5_var_dir_p = data_dir_p / \"env_vars/oras5/test/annual_sosaline\"\n",
    "\n",
    "# create subdirectory in file directory (if doesn't already exist) with info about region selection\n",
    "subdir_name = functions_creche.create_coord_subdir_name(oras5_var_dir_p, lats, lons, depths)\n",
    "create_subdirectory(oras5_var_dir_p, subdir_name)\n",
    "\n",
    "# for function in directory\n",
    "for file_p in oras5_var_dir_p.glob(\"*.nc\"):\n",
    "    # load into xarray\n",
    "    array = xa.open_dataset(file_p)\n",
    "    # convert x and y to lat lon\n",
    "    \n",
    "    # select region of interest (lats, lons, depths) from open xarray\n",
    "    # save as .nc file to subdirectory with original name\n",
    "    # delete original file from main directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xa = xa.open_dataarray(file_p)\n",
    "test_xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(ncols=2, figsize=(14,5))\n",
    "\n",
    "test_xa[\"nav_lat\"].plot(ax=ax[0])\n",
    "test_xa[\"nav_lon\"].plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "def polar_axis():\n",
    "    '''cartopy geoaxes centered at north pole'''\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=0))\n",
    "    ax.coastlines(linewidth=0.75, color='black', resolution='50m')\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linestyle='-')\n",
    "    ax.set_extent([-180, 180, 60, 90], crs=ccrs.PlateCarree())\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generates <cartopy.mpl.geocollection.GeoQuadMesh at 0x150b260a6ce0> doesn't plot\n",
    "# ax = polar_axis()\n",
    "# test_xa.plot.pcolormesh(ax=ax, x=\"nav_lat\", y=\"nav_lon\", transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xa_rename = test_xa.rename({\"nav_lat\": \"lat\", \"nav_lon\": \"lon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"ESMFMKFILE\"] = \"/home/rt582/rds/.conda/envs/pycoral/lib/esmf.mk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xesmf as xe\n",
    "\n",
    "ds_out = xe.util.grid_global(1, 1)\n",
    "ds_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder = xe.Regridder(test_xa_rename, ds_out, \"bilinear\", ignore_degenerate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove coordinate values of y for which values of nav_lat < 60\n",
    "test_xa[\"y\"].where(test_xa[\"nav_lat\"] > 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = polar_axis()\n",
    "test_xa.plot.pcolormesh(ax=ax, transform=ccrs.PlateCarree(), x='nav_lon', y='nav_lat', add_colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xa.open_dataarray(file_p).isel(deptht=0).plot()\n",
    "xa.open_dataarray(file_p).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bathymetry – GEBCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEBCO\n",
    "gebco_f_path = data_dir_p / \"bathymetry/gebco/gebco_2023_n-10.0_s-30.0_w140.0_e160.0.nc\"\n",
    "# TODO: processing not working properly e.g. wrt crs\n",
    "gebco_xa = spatial_data.process_xa_d(xa.open_dataarray(gebco_f_path))\n",
    "# gebco_nc[\"elevation\"].plot()\n",
    "spatial_plots.plot_spatial(gebco_xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate slopes. Look in bathymetry.py\n",
    "from coralshift.dataloading import bathymetry\n",
    "gebco_slopes_xa = bathymetry.calculate_gradient_magnitude(gebco_xa)\n",
    "spatial_plots.plot_spatial(gebco_slopes_xa, title=\"Seafloor gradients\")\n",
    "\n",
    "# save slopes to new file in data dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename lat and lon to latitude and longitude\n",
    "# spatially align xarrays\n",
    "input_dss = [spatial_data.process_xa_d(buffered_ds), spatial_data.process_xa_d(gebco_xa), \n",
    "    spatial_data.process_xa_d(xa_unep)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatially align datasets into a single xarray dataset\n",
    "common_dataset = functions_creche.spatially_combine_xa_d_list(input_dss, lats, lons, resolution_lat, resolution_lon) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "# initialise subplots with crs = PlateCarree projection\n",
    "f, ax = plt.subplots(nrows=3, figsize=(40,8), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "vars_to_plot = [\"t_gp\", \"elevation\", \"unep_coral_presence\"]\n",
    "\n",
    "# for i, var in tqdm(enumerate(vars_to_plot), desc=f\"Plotting {var}\"):\n",
    "for i, var in (enumerate(tqdm(vars_to_plot, desc=\"Plotting...\"))):\n",
    "    array_to_plot = common_dataset[var]\n",
    "    # if time, select first\n",
    "    if \"time\" in array_to_plot.dims:\n",
    "        array_to_plot = array_to_plot.isel(time=0)\n",
    "        \n",
    "    spatial_plots.plot_spatial(array_to_plot, fax=[f,ax[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(ncols=2, figsize=(14,5))\n",
    "\n",
    "common_dataset[\"elevation\"].sel(latitude=slice(-30,-28), longitude=slice(155,157)).plot(ax=ax[0])\n",
    "ax[0].set_title(\"elevation\")\n",
    "common_dataset[\"t_an\"].sel(latitude=slice(-30,-28), longitude=slice(155,157)).isel(time=0).plot(ax=ax[1])\n",
    "ax[0].set_title(\"t_an\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables to keep\n",
    "predictors = [\"t_an\", \"t_mn\", \"t_dd\", \"t_sd\", \"t_se\", \"t_oa\", \"t_ma\", \"t_gp\", \"elevation\"]\n",
    "gt = \"unep_coral_presence\"\n",
    "# send to dataframe with selected variables\n",
    "combined_df = common_dataset[predictors + [gt]].to_dataframe()\n",
    "# train-test-val split: spatial/pixel-wise\n",
    "\n",
    "df_list = functions_creche.tvt_spatial_split(combined_df, [0.6, 0.2, 0.2])\n",
    "# generate and save scaling parameters, ignoring nans. Start with min-max scaling\n",
    "# one-hot encode nans\n",
    "# cast to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [\"train\", \"test\", \"val\"]\n",
    "\n",
    "f,ax = plt.subplots(nrows=3, figsize=(20,5), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "\n",
    "for i, df in enumerate(df_list):\n",
    "    ds = xa.Dataset.from_dataframe(df)\n",
    "    if \"depth\" in ds.dims:\n",
    "        ds = ds.isel(depth=0)\n",
    "    if \"time\" in ds.dims:\n",
    "        ds = ds.isel(time=0)\n",
    "    spatial_plots.plot_spatial(ds[\"t_an\"], title=f\"{order[i]} dataset\", fax=[f,ax[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X_train, y_train), (X_val, y_val), (X_test, y_test)), dfs_list = functions_creche.process_df_for_rfr(combined_df, predictors, gt)\n",
    "# vals= process_df_for_rfr(combined_df, predictors, gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model iteratively (using batching)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr_model = RandomForestRegressor(random_state=42, warm_start=True)\n",
    "\n",
    "def train_rf_model_iteratively(rf_model, train_X: np.ndarray, train_y: np.ndarray, batch_size: int=100):\n",
    "    train_points = len(train_X)\n",
    "    for batch in tqdm(range(0, len(train_X), batch_size), desc=f\"Batched training\"):\n",
    "        # if not enough data for a complete batch, use remaining data\n",
    "        if batch + batch_size > train_points:\n",
    "            batch_size = train_points - batch\n",
    "\n",
    "        X_batch = train_X[batch : batch + batch_size]\n",
    "        y_batch = train_y[batch : batch + batch_size]\n",
    "\n",
    "        rf_model.fit(X_batch, y_batch)\n",
    "        rf_model.n_estimators += 1\n",
    "\n",
    "    return rf_model\n",
    "\n",
    "basic_model = train_rf_model_iteratively(rfr_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coralshift.machine_learning import baselines\n",
    "\n",
    "\n",
    "random_model = baselines.train_tune(\n",
    "    X_train, y_train, \"rf_reg\", resolution = 1, name=\"first_random\", search_type=\"random\", n_jobs=-1, verbose=False)\n",
    "# rfr_grid = baselines.rf_search_grid()\n",
    "\n",
    "# grid_search_cv = baselines.initialise_grid_search(model_type=\"rf_reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "best_params_dict = random_model.best_params_\n",
    "\n",
    "grid_model = baselines.train_tune(\n",
    "    X_train, y_train, \"rf_reg\", resolution = 1, name=\"first_grid\", search_type=\"grid\", n_jobs=-1, verbose=0, best_params_dict=best_params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = random_model.predict(X_train)\n",
    "train_pred_df = functions_creche.reform_df(dfs_list[0], y_pred)\n",
    "\n",
    "# mean_squared_error(y_train, y_pred)\n",
    "mean_squared_error(train_pred_df[\"unep_coral_presence\"], train_pred_df[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(X_train)\n",
    "xa.Dataset.from_dataframe(functions_creche.reform_df(dfs_list[0], y_pred))\n",
    "\n",
    "# def xarray_from_df(df: pd.DataFrame, )\n",
    "# don't think it's necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_plots.plot_spatial_diffs(\n",
    "    pred_xa[\"unep_coral_presence\"].isel(time=0), \n",
    "    pred_xa[\"prediction\"].isel(time=0), \n",
    "    # title=\"Prediction/Ground Truth Residual\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(random_model, dfs_list[1], X_val, y_val)\n",
    "# evaluate_model(random_model, dfs_list[0], X_train, y_train)\n",
    "# functions_creche.evaluate_model(grid_model, dfs_list[0], X_train, y_train) \n",
    "# TODO: implement this (side-by-side spatial comparison, plot with mse)\n",
    "\n",
    "def evaluate_model(model, df: pd.DataFrame, X: np.ndarray, y: np.ndarray, figsize: tuple=[4,4]):\n",
    "    \"\"\"\n",
    "    Evaluate model (visually and mse) on a given dataset, returning an xarray with predictions and ground truth.\n",
    "\n",
    "    Args:\n",
    "        model (sklearn model): trained model\n",
    "        df (pd.DataFrame): dataframe with ground truth\n",
    "        X (np.ndarray): input data\n",
    "        y (np.ndarray): ground truth\n",
    "        figsize (tuple, optional): figure size. Defaults to [4,4].\n",
    "    \n",
    "    Returns:\n",
    "        pred_xa (xa.Dataset): xarray dataset with ground truth and predictions\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    pred_df = functions_creche.reform_df(df, y_pred)\n",
    "    mse = mean_squared_error(pred_df[\"unep_coral_presence\"], pred_df[\"prediction\"])\n",
    "\n",
    "    f,ax = plt.subplots(figsize=figsize)\n",
    "    ax.scatter(y, y_pred)\n",
    "    # y=x for comparison\n",
    "    ax.axline((0, 0), slope=1, c=\"k\")\n",
    "    ax.axis(\"equal\")\n",
    "    ax.set_xlabel(\"Ground Truth\")\n",
    "    ax.set_ylabel(\"Prediction\")\n",
    "    ax.set_xlim([0,1])\n",
    "\n",
    "    plt.suptitle(f\"MSE: {mse:.04f}\")\n",
    "\n",
    "    return pred_xa\n",
    "\n",
    "\n",
    "pred_xa = evaluate_model(grid_model, dfs_list[0], X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dataset[\"unep_coral_presence\"].values.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts_vals = common_dataset[\"unep_coral_presence\"].values.flatten()\n",
    "plt.hist(gts_vals, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].unep_coral_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].unep_coral_presence.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coralshift.machine_learning import transformer_utils\n",
    "from coralshift.machine_learning import run_transformer\n",
    "\n",
    "pyt_train_x, pyt_train_y = transformer_utils.create_dummy_data()\n",
    "dh = transformer_utils.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_transformer.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.torch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: visualise any differences in distributions between train and test/val datasets\n",
    "# # save scaling parameters to json\n",
    "# # N.B. this file saving might not be necessary\n",
    "# from coralshift.utils import file_ops\n",
    "# file_ops.save_json(scale_dict, data_dir_p / \"scaling_params.json\")\n",
    "# # TODO: include more metadata about the exact dataset used to generate the scaling parameters\n",
    "# # loading scaling data\n",
    "# import json\n",
    "# # TODO: smoother way to do this?\n",
    "# scaling_params_p = data_dir_p / \"scaling_params.json\"\n",
    "# f = open(scaling_params_p)\n",
    "# scale_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycoral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
